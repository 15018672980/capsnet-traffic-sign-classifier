<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<title>Traffic_Sign_Classifier</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    color: #000 !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.2.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.2.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.2.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.2.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.2.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.2.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=1);
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2);
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=3);
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1);
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1);
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
@media (max-width: 991px) {
  #ipython_notebook {
    margin-left: 10px;
  }
}
[dir="rtl"] #ipython_notebook {
  float: right !important;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#login_widget {
  float: right;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  text-align: center;
  vertical-align: middle;
  display: inline;
  opacity: 0;
  z-index: 2;
  width: 12ex;
  margin-right: -12ex;
}
.alternate_upload .btn-upload {
  height: 22px;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
[dir="rtl"] #tabs li {
  float: right;
}
ul#tabs {
  margin-bottom: 4px;
}
[dir="rtl"] ul#tabs {
  margin-right: 0px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons {
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-right {
  padding-top: 1px;
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-left {
  float: right !important;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: baseline;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
#tree-selector {
  padding-right: 0px;
}
[dir="rtl"] #tree-selector a {
  float: right;
}
#button-select-all {
  min-width: 50px;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
[dir="rtl"] #new-menu {
  text-align: right;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
[dir="rtl"] #running .col-sm-8 {
  float: right !important;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul {
  list-style: disc;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ul ul {
  list-style: square;
  margin: 0em 2em;
}
.rendered_html ul ul ul {
  list-style: circle;
  margin: 0em 2em;
}
.rendered_html ol {
  list-style: decimal;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
  margin: 0em 2em;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  background-color: #fff;
  color: #000;
  font-size: 100%;
  padding: 0px;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: 1px solid black;
  border-collapse: collapse;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  border: 1px solid black;
  border-collapse: collapse;
  margin: 1em 2em;
}
.rendered_html td,
.rendered_html th {
  text-align: left;
  vertical-align: middle;
  padding: 4px;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget {
  float: right !important;
  float: right;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  margin-top: 6px;
}
span.save_widget span.filename {
  height: 1em;
  line-height: 1em;
  padding: 3px;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  display: none;
}
.command-shortcut:before {
  content: "(command)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h2 id="Step-0:-Load-The-Data">Step 0: Load The Data<a class="anchor-link" href="#Step-0:-Load-The-Data">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Load pickled data</span>
<span class="kn">import</span> <span class="nn">pickle</span>

<span class="c1"># TODO: Fill this in based on where you saved the training and testing data</span>

<span class="n">training_file</span> <span class="o">=</span> <span class="s2">&quot;dataset/train.p&quot;</span>
<span class="n">validation_file</span><span class="o">=</span> <span class="s2">&quot;dataset/valid.p&quot;</span>
<span class="n">testing_file</span> <span class="o">=</span> <span class="s2">&quot;dataset/test.p&quot;</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">training_file</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">train</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">validation_file</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">valid</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">testing_file</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">test</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    
<span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s1">&#39;features&#39;</span><span class="p">],</span> <span class="n">train</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span>
<span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">valid</span><span class="p">[</span><span class="s1">&#39;features&#39;</span><span class="p">],</span> <span class="n">valid</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="s1">&#39;features&#39;</span><span class="p">],</span> <span class="n">test</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span>

<span class="c1"># Print the shape of variables</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>(34799, 32, 32, 3)
(34799,)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h2 id="Step-1:-Dataset-Summary-&amp;-Exploration">Step 1: Dataset Summary &amp; Exploration<a class="anchor-link" href="#Step-1:-Dataset-Summary-&amp;-Exploration">&#182;</a></h2><p>The pickled data is a dictionary with 4 key/value pairs:</p>
<ul>
<li><code>'features'</code> is a 4D array containing raw pixel data of the traffic sign images, (num examples, width, height, channels).</li>
<li><code>'labels'</code> is a 1D array containing the label/class id of the traffic sign. The file <code>signnames.csv</code> contains id -&gt; name mappings for each id.</li>
<li><code>'sizes'</code> is a list containing tuples, (width, height) representing the original width and height the image.</li>
<li><code>'coords'</code> is a list containing tuples, (x1, y1, x2, y2) representing coordinates of a bounding box around the sign in the image. <strong>THESE COORDINATES ASSUME THE ORIGINAL IMAGE. THE PICKLED DATA CONTAINS RESIZED VERSIONS (32 by 32) OF THESE IMAGES</strong></li>
</ul>
<p>Complete the basic data summary below. Use python, numpy and/or pandas methods to calculate the data summary rather than hard coding the results. For example, the <a href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.shape.html">pandas shape method</a> might be useful for calculating some of the summary results.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Provide-a-Basic-Summary-of-the-Data-Set-Using-Python,-Numpy-and/or-Pandas">Provide a Basic Summary of the Data Set Using Python, Numpy and/or Pandas<a class="anchor-link" href="#Provide-a-Basic-Summary-of-the-Data-Set-Using-Python,-Numpy-and/or-Pandas">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">### Replace each question mark with the appropriate value. </span>
<span class="c1">### Use python, pandas or numpy methods rather than hard coding the results</span>

<span class="c1"># TODO: Number of training example</span>
<span class="n">n_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># TODO: Number of validation example</span>
<span class="n">n_validation</span> <span class="o">=</span> <span class="n">X_valid</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># TODO: Number of testing example.</span>
<span class="n">n_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># TODO: What&#39;s the shape of an traffic sign image?</span>
<span class="n">image_shape</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>

<span class="c1"># TODO: How many unique classes/labels there are in the dataset.</span>
<span class="n">n_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">y_train</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of training examples =&quot;</span><span class="p">,</span> <span class="n">n_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of testing examples =&quot;</span><span class="p">,</span> <span class="n">n_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Image data shape =&quot;</span><span class="p">,</span> <span class="n">image_shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of classes =&quot;</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Number of training examples = 34799
Number of testing examples = 12630
Image data shape = (32, 32, 3)
Number of classes = 43
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Include-an-exploratory-visualization-of-the-dataset">Include an exploratory visualization of the dataset<a class="anchor-link" href="#Include-an-exploratory-visualization-of-the-dataset">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Visualize the German Traffic Signs Dataset using the pickled file(s). This is open ended, suggestions include: plotting traffic sign images, plotting the count of each sign, etc.</p>
<p>The <a href="http://matplotlib.org/">Matplotlib</a> <a href="http://matplotlib.org/examples/index.html">examples</a> and <a href="http://matplotlib.org/gallery.html">gallery</a> pages are a great resource for doing visualizations in Python.</p>
<p><strong>NOTE:</strong> It's recommended you start with something simple first. If you wish to do more, come back to it after you've completed the rest of the sections. It can be interesting to look at the distribution of classes in the training, validation and test set. Is the distribution the same? Are there more examples of some classes than others?</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">### Data exploration visualization code goes here.</span>
<span class="c1">### Feel free to use as many code cells as needed.</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="k">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="k">import</span> <span class="n">Image</span><span class="p">,</span> <span class="n">ImageEnhance</span>
<span class="c1"># Visualizations will be shown in the notebook.</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="c1"># Load name of id</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;signnames.csv&quot;</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">signnames</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="n">id_to_name</span> <span class="o">=</span> <span class="p">{</span> <span class="nb">int</span><span class="p">(</span><span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]):</span><span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">signnames</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">line</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">}</span>


<span class="n">graph_size</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">random_index_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">graph_size</span> <span class="o">*</span> <span class="n">graph_size</span><span class="p">)]</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">15</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">random_index_list</span><span class="p">):</span>
    <span class="n">a</span><span class="o">=</span><span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">graph_size</span><span class="p">,</span> <span class="n">graph_size</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1">#im = Image.fromarray(np.rollaxis(X_train[index] * 255, 0,3))</span>
    <span class="n">imgplot</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">index</span><span class="p">])</span>
    <span class="c1"># Plot some images</span>
    <span class="n">a</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">id_to_name</span><span class="p">[</span><span class="n">y_train</span><span class="p">[</span><span class="n">index</span><span class="p">]])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>



<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="c1"># the histogram of the data</span>
<span class="n">values</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">patches</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">,</span> <span class="n">normed</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># add a &#39;best fit&#39; line</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Smarts&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;Histogram of classess&#39;</span><span class="p">)</span>

<span class="c1"># Tweak spacing to prevent clipping of ylabel</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

<span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;Most common index&quot;</span><span class="p">)</span>
<span class="n">most_common_index</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">values</span><span class="p">)),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">k</span><span class="p">:</span> <span class="n">values</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">most_common_index</span><span class="p">[:</span><span class="mi">10</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;index: </span><span class="si">%s</span><span class="s2"> =&gt; </span><span class="si">%s</span><span class="s2"> = </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">id_to_name</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="n">values</span><span class="p">[</span><span class="n">index</span><span class="p">]))</span>

    
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA2QAAANeCAYAAAB9Cc0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Most common index
index: 2 =&gt; Speed limit (50km/h) = 0.0591355252409
index: 1 =&gt; Speed limit (30km/h) = 0.0582529054612
index: 13 =&gt; Yield = 0.0564876659017
index: 12 =&gt; Priority road = 0.055605046122
index: 38 =&gt; Keep right = 0.0547224263423
index: 10 =&gt; No passing for vehicles over 3.5 metric tons = 0.0529571867829
index: 4 =&gt; Speed limit (70km/h) = 0.0520745670032
index: 5 =&gt; Speed limit (80km/h) = 0.0485440878843
index: 25 =&gt; Road work = 0.0397178900872
index: 9 =&gt; No passing = 0.0388352703074
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h2 id="Step-2:-Design-and-Test-a-Model-Architecture">Step 2: Design and Test a Model Architecture<a class="anchor-link" href="#Step-2:-Design-and-Test-a-Model-Architecture">&#182;</a></h2><p>Design and implement a deep learning model that learns to recognize traffic signs. Train and test your model on the <a href="http://benchmark.ini.rub.de/?section=gtsrb&amp;subsection=dataset">German Traffic Sign Dataset</a>.</p>
<p>The LeNet-5 implementation shown in the <a href="https://classroom.udacity.com/nanodegrees/nd013/parts/fbf77062-5703-404e-b60c-95b78b2f3f9e/modules/6df7ae49-c61c-4bb2-a23e-6527e69209ec/lessons/601ae704-1035-4287-8b11-e2c2716217ad/concepts/d4aca031-508f-4e0b-b493-e7b706120f81">classroom</a> at the end of the CNN lesson is a solid starting point. You'll have to change the number of classes and possibly the preprocessing, but aside from that it's plug and play!</p>
<p>With the LeNet-5 solution from the lecture, you should expect a validation set accuracy of about 0.89. To meet specifications, the validation set accuracy will need to be at least 0.93. It is possible to get an even higher accuracy, but 0.93 is the minimum for a successful project submission.</p>
<p>There are various aspects to consider when thinking about this problem:</p>
<ul>
<li>Neural network architecture (is the network over or underfitting?)</li>
<li>Play around preprocessing techniques (normalization, rgb to grayscale, etc)</li>
<li>Number of examples per label (some have more than others).</li>
<li>Generate fake data.</li>
</ul>
<p>Here is an example of a <a href="http://yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf">published baseline model on this problem</a>. It's not required to be familiar with the approach used in the paper but, it's good practice to try to read papers like these.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Pre-process-the-Data-Set-(normalization,-grayscale,-etc.)">Pre-process the Data Set (normalization, grayscale, etc.)<a class="anchor-link" href="#Pre-process-the-Data-Set-(normalization,-grayscale,-etc.)">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Minimally, the image data should be normalized so that the data has mean zero and equal variance. For image data, <code>(pixel - 128)/ 128</code> is a quick way to approximately normalize the data and can be used in this project.</p>
<p>Other pre-processing steps are optional. You can try different techniques to see if it improves performance.</p>
<p>Use the code cell (or multiple code cells, if necessary) to implement the first step of your project.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">### Preprocess the data here. It is required to normalize the data. Other preprocessing steps could include </span>
<span class="c1">### converting to grayscale, etc.</span>
<span class="c1">### Feel free to use as many code cells as needed.</span>

<span class="c1">#  I used keras only for the ImageDataGenerator</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing.image</span> <span class="k">import</span> <span class="n">ImageDataGenerator</span>


<span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span> <span class="o">/</span> <span class="mi">255</span>
<span class="n">X_valid</span> <span class="o">=</span> <span class="n">X_valid</span> <span class="o">/</span> <span class="mi">255</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span> <span class="o">/</span> <span class="mi">255</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>Using TensorFlow backend.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">preprocessing_function</span><span class="p">(</span><span class="n">img</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Custom preprocessing_function</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">img</span> <span class="o">*</span> <span class="mi">255</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;uint8&#39;</span><span class="p">),</span> <span class="s1">&#39;RGB&#39;</span><span class="p">)</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">ImageEnhance</span><span class="o">.</span><span class="n">Brightness</span><span class="p">(</span><span class="n">img</span><span class="p">)</span><span class="o">.</span><span class="n">enhance</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">))</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">ImageEnhance</span><span class="o">.</span><span class="n">Contrast</span><span class="p">(</span><span class="n">img</span><span class="p">)</span><span class="o">.</span><span class="n">enhance</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">img</span><span class="p">)</span> <span class="o">/</span> <span class="mi">255</span>

<span class="n">train_datagen</span> <span class="o">=</span> <span class="n">ImageDataGenerator</span><span class="p">()</span>
<span class="n">train_datagen_augmented</span> <span class="o">=</span> <span class="n">ImageDataGenerator</span><span class="p">(</span>
    <span class="n">rotation_range</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="n">shear_range</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">width_shift_range</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">height_shift_range</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">horizontal_flip</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">preprocessing_function</span><span class="o">=</span><span class="n">preprocessing_function</span><span class="p">)</span>
<span class="n">inference_datagen</span> <span class="o">=</span> <span class="n">ImageDataGenerator</span><span class="p">()</span>
<span class="n">train_datagen</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">train_datagen_augmented</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">inference_datagen</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)</span>
<span class="n">inference_datagen</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Exemple-of-augmented-images">Exemple of augmented images<a class="anchor-link" href="#Exemple-of-augmented-images">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>

<span class="n">n</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">graph_size</span> <span class="o">=</span> <span class="mi">3</span>

<span class="k">for</span> <span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="ow">in</span> <span class="n">train_datagen_augmented</span><span class="o">.</span><span class="n">flow</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">a</span><span class="o">=</span><span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">graph_size</span><span class="p">,</span> <span class="n">graph_size</span><span class="p">,</span> <span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">imgplot</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">x_batch</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">&gt;</span> <span class="mi">8</span><span class="p">:</span>
        <span class="k">break</span>

    
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Model-Architecture">Model Architecture<a class="anchor-link" href="#Model-Architecture">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="CapsNet">CapsNet<a class="anchor-link" href="#CapsNet">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<span class="k">def</span> <span class="nf">conv_caps_layer</span><span class="p">(</span><span class="n">input_layer</span><span class="p">,</span> <span class="n">capsules_size</span><span class="p">,</span> <span class="n">nb_filters</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Capsule layer for the convolutional inputs</span>
<span class="sd">        **input:</span>
<span class="sd">            *input_layer: (Tensor)</span>
<span class="sd">            *capsule_numbers: (Integer) the number of capsule in this layer.</span>
<span class="sd">            *kernel_size: (Integer) Size of the kernel for each filter.</span>
<span class="sd">            *stride: (Integer) 2 by default</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># &quot;In convolutional capsule layers each unit in a capsule is a convolutional unit.</span>
    <span class="c1"># Therefore, each capsule will output a grid of vectors rather than a single vector output.&quot;</span>
    <span class="n">capsules</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span>
        <span class="n">input_layer</span><span class="p">,</span> <span class="n">nb_filters</span> <span class="o">*</span> <span class="n">capsules_size</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;VALID&quot;</span><span class="p">)</span>
    <span class="c1"># conv shape: [?, kernel, kernel, nb_filters]</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">capsules</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">as_list</span><span class="p">()</span>
    <span class="n">capsules</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">capsules</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">])</span> <span class="o">*</span> <span class="n">nb_filters</span><span class="p">,</span> <span class="n">capsules_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="c1"># capsules shape: [?, nb_capsules, capsule_size, 1]</span>
    <span class="k">return</span> <span class="n">squash</span><span class="p">(</span><span class="n">capsules</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">routing</span><span class="p">(</span><span class="n">u_hat</span><span class="p">,</span> <span class="n">b_ij</span><span class="p">,</span> <span class="n">nb_capsules</span><span class="p">,</span> <span class="n">nb_capsules_p</span><span class="p">,</span> <span class="n">iterations</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Routing algorithm</span>

<span class="sd">        **input:</span>
<span class="sd">            *u_hat: Dot product (weights between previous capsule and current capsule)</span>
<span class="sd">            *b_ij: the log prior probabilities that capsule i should be coupled to capsule j</span>
<span class="sd">            *nb_capsules_p: Number of capsule in the previous layer</span>
<span class="sd">            *nb_capsules: Number of capsule in this layer</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Start the routing algorithm</span>
    <span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iterations</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;routing_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">it</span><span class="p">)):</span>
            <span class="c1"># Line 4 of algo</span>
            <span class="c1"># probabilities that capsule i should be coupled to capsule j.</span>
            <span class="c1"># c_ij:  [nb_capsules_p, nb_capsules, 1, 1]</span>
            <span class="n">c_ij</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">b_ij</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

            <span class="c1"># Line 5 of algo</span>
            <span class="c1"># c_ij:  [      nb_capsules_p, nb_capsules, 1,         1]</span>
            <span class="c1"># u_hat: [?,    nb_capsules_p, nb_capsules, len_v_j,   1]</span>
            <span class="n">s_j</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">c_ij</span><span class="p">,</span> <span class="n">u_hat</span><span class="p">)</span>
            <span class="c1"># s_j: [?, nb_capsules_p, nb_capsules, len_v_j, 1]</span>
            <span class="n">s_j</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">s_j</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="c1"># s_j: [?, 1, nb_capsules, len_v_j, 1)</span>

            <span class="c1"># line 6:</span>
            <span class="c1"># squash using Eq.1,</span>
            <span class="n">v_j</span> <span class="o">=</span> <span class="n">squash</span><span class="p">(</span><span class="n">s_j</span><span class="p">)</span>
            <span class="c1"># v_j: [1, 1, nb_capsules, len_v_j, 1)</span>

            <span class="c1"># line 7:</span>
            <span class="c1"># Frist reshape &amp; tile v_j</span>
            <span class="c1"># [? ,  1,              nb_capsules,    len_v_j, 1] -&gt;</span>
            <span class="c1"># [?,   nb_capsules_p,  nb_capsules,    len_v_j, 1]</span>
            <span class="n">v_j_tiled</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">v_j</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">nb_capsules_p</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
            <span class="c1"># u_hat:    [?,             nb_capsules_p, nb_capsules, len_v_j, 1]</span>
            <span class="c1"># v_j_tiled [1,             nb_capsules_p, nb_capsules, len_v_j, 1]</span>
            <span class="n">u_dot_v</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">u_hat</span><span class="p">,</span> <span class="n">v_j_tiled</span><span class="p">,</span> <span class="n">transpose_a</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="c1"># u_produce_v: [?, nb_capsules_p, nb_capsules, 1, 1]</span>
            <span class="n">b_ij</span> <span class="o">+=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">u_dot_v</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="c1">#b_ih: [1, nb_capsules_p, nb_capsules, 1, 1]</span>

    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">v_j</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">fully_connected_caps_layer</span><span class="p">(</span><span class="n">input_layer</span><span class="p">,</span> <span class="n">capsules_size</span><span class="p">,</span> <span class="n">nb_capsules</span><span class="p">,</span> <span class="n">iterations</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Second layer receiving inputs from all capsules of the layer below</span>
<span class="sd">            **input:</span>
<span class="sd">                *input_layer: (Tensor)</span>
<span class="sd">                *capsules_size: (Integer) Size of each capsule</span>
<span class="sd">                *nb_capsules: (Integer) Number of capsule</span>
<span class="sd">                *iterations: (Integer) Number of iteration for the routing algorithm</span>

<span class="sd">            i refer to the layer below.</span>
<span class="sd">            j refer to the layer above (the current layer).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">input_layer</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">as_list</span><span class="p">()</span>
    <span class="c1"># Get the size of each capsule in the previous layer and the current layer.</span>
    <span class="n">len_u_i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
    <span class="n">len_v_j</span> <span class="o">=</span> <span class="n">capsules_size</span>
    <span class="c1"># Get the number of capsule in the layer bellow.</span>
    <span class="n">nb_capsules_p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

    <span class="c1"># w_ij: Used to compute u_hat by multiplying the output ui of a capsule in the layer below</span>
    <span class="c1"># with this matrix</span>
    <span class="c1"># [nb_capsules_p, nb_capsules, len_v_j, len_u_i]</span>
    <span class="n">_init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random_normal_initializer</span><span class="p">(</span><span class="n">stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">nb_capsules_p</span><span class="p">,</span> <span class="n">nb_capsules</span><span class="p">,</span> <span class="n">len_v_j</span><span class="p">,</span> <span class="n">len_u_i</span><span class="p">)</span>
    <span class="n">w_ij</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s1">&#39;weight&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">_init</span><span class="p">)</span>

    <span class="c1"># Adding one dimension to the input [batch_size, nb_capsules_p,    length(u_i), 1] -&gt;</span>
    <span class="c1">#                                   [batch_size, nb_capsules_p, 1, length(u_i), 1]</span>
    <span class="c1"># To allow the next dot product</span>
    <span class="n">input_layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">input_layer</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">nb_capsules_p</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">len_u_i</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">input_layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">input_layer</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">nb_capsules</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

    <span class="c1"># Eq.2, calc u_hat</span>
    <span class="c1"># Prediction uj|i made by capsule i</span>
    <span class="c1"># w_ij:  [              nb_capsules_p, nb_capsules, len_v_j,  len_u_i, ]</span>
    <span class="c1"># input: [batch_size,   nb_capsules_p, nb_capsules, len_ui,   1]</span>
    <span class="c1"># u_hat: [batch_size,   nb_capsules_p, nb_capsules, len_v_j, 1]</span>
    <span class="c1"># Each capsule of the previous layer capsule layer is associated to a capsule of this layer</span>
    <span class="n">u_hat</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;abdc,iabcf-&gt;iabdf&#39;</span><span class="p">,</span> <span class="n">w_ij</span><span class="p">,</span> <span class="n">input_layer</span><span class="p">)</span>

    <span class="c1"># bij are the log prior probabilities that capsule i should be coupled to capsule j</span>
    <span class="c1"># [nb_capsules_p, nb_capsules, 1, 1]</span>
    <span class="n">b_ij</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">nb_capsules_p</span><span class="p">,</span> <span class="n">nb_capsules</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">routing</span><span class="p">(</span><span class="n">u_hat</span><span class="p">,</span> <span class="n">b_ij</span><span class="p">,</span> <span class="n">nb_capsules</span><span class="p">,</span> <span class="n">nb_capsules_p</span><span class="p">,</span> <span class="n">iterations</span><span class="o">=</span><span class="n">iterations</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">squash</span><span class="p">(</span><span class="n">vector</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Squashing function corresponding to Eq. 1</span>
<span class="sd">        **input: **</span>
<span class="sd">            *vector</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">vector</span> <span class="o">+=</span> <span class="mf">0.00001</span> <span class="c1"># Workaround for the squashing function ...</span>
    <span class="n">vec_squared_norm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">vector</span><span class="p">),</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">scalar_factor</span> <span class="o">=</span> <span class="n">vec_squared_norm</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">vec_squared_norm</span><span class="p">)</span> <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">vec_squared_norm</span><span class="p">)</span>
    <span class="n">vec_squashed</span> <span class="o">=</span> <span class="n">scalar_factor</span> <span class="o">*</span> <span class="n">vector</span>  <span class="c1"># element-wise</span>
    <span class="k">return</span><span class="p">(</span><span class="n">vec_squashed</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Main-Model">Main Model<a class="anchor-link" href="#Main-Model">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="ch">#!/usr/bin/python3</span>
<span class="c1"># -*- coding: utf-8 -*-</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">model_base</span> <span class="k">import</span> <span class="n">ModelBase</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="k">class</span> <span class="nc">ModelTrafficSign</span><span class="p">(</span><span class="n">ModelBase</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        ModelTrafficSign.</span>
<span class="sd">        This class is used to create the conv graph using:</span>
<span class="sd">            Dynamic Routing Between Capsules</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Numbers of label to predict</span>
    <span class="n">NB_LABELS</span> <span class="o">=</span> <span class="mi">43</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">output_folder</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            **input:</span>
<span class="sd">                *model_name: (Integer) Name of this model</span>
<span class="sd">                *output_folder: Output folder to saved data (tensorboard, checkpoints)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ModelBase</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">output_folder</span><span class="o">=</span><span class="n">output_folder</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_build_inputs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Build tensorflow inputs</span>
<span class="sd">            (Placeholder)</span>
<span class="sd">            **return: **</span>
<span class="sd">                *tf_images: Images Placeholder</span>
<span class="sd">                *tf_labels: Labels Placeholder</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Images 32*32*3</span>
        <span class="n">tf_images</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;images&#39;</span><span class="p">)</span>
        <span class="c1"># Labels: [0, 1, 6, 20, ...]</span>
        <span class="n">tf_labels</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;labels&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tf_images</span><span class="p">,</span> <span class="n">tf_labels</span>

    <span class="k">def</span> <span class="nf">_build_main_network</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">conv_2_dropout</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            This method is used to create the two convolutions and the CapsNet on the top</span>
<span class="sd">            **input:</span>
<span class="sd">                *images: Image PLaceholder</span>
<span class="sd">                *conv_2_dropout: Dropout value placeholder</span>
<span class="sd">            **return: **</span>
<span class="sd">                *Caps1: Output of first Capsule layer</span>
<span class="sd">                *Caps2: Output of second Capsule layer</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># First BLock:</span>
        <span class="c1"># Layer 1: Convolution.</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="o">.</span><span class="n">conv_1_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="o">.</span><span class="n">conv_1_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="o">.</span><span class="n">conv_1_nb</span><span class="p">)</span>
        <span class="n">conv1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_conv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tf_images</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">relu</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_pooling</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;VALID&#39;</span><span class="p">)</span>
        <span class="c1"># Layer 2: Convolution.</span>
        <span class="c1">#shape = (self.h.conv_2_size, self.h.conv_2_size, self.h.conv_1_nb, self.h.conv_2_nb)</span>
        <span class="c1">#conv2 = self._create_conv(conv1, shape, relu=True, max_pooling=False, padding=&#39;VALID&#39;)</span>
        <span class="n">conv1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">conv1</span><span class="p">,</span> <span class="n">keep_prob</span><span class="o">=</span><span class="n">conv_2_dropout</span><span class="p">)</span>

        <span class="c1"># Create the first capsules layer</span>
        <span class="n">caps1</span> <span class="o">=</span> <span class="n">conv_caps_layer</span><span class="p">(</span>
            <span class="n">input_layer</span><span class="o">=</span><span class="n">conv1</span><span class="p">,</span>
            <span class="n">capsules_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="o">.</span><span class="n">caps_1_vec_len</span><span class="p">,</span>
            <span class="n">nb_filters</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="o">.</span><span class="n">caps_1_nb_filter</span><span class="p">,</span>
            <span class="n">kernel</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="o">.</span><span class="n">caps_1_size</span><span class="p">)</span>
        <span class="c1"># Create the second capsules layer used to predict the output</span>
        <span class="n">caps2</span> <span class="o">=</span> <span class="n">fully_connected_caps_layer</span><span class="p">(</span>
            <span class="n">input_layer</span><span class="o">=</span><span class="n">caps1</span><span class="p">,</span>
            <span class="n">capsules_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="o">.</span><span class="n">caps_2_vec_len</span><span class="p">,</span>
            <span class="n">nb_capsules</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">NB_LABELS</span><span class="p">,</span>
            <span class="n">iterations</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="o">.</span><span class="n">routing_steps</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">caps1</span><span class="p">,</span> <span class="n">caps2</span>

    <span class="k">def</span> <span class="nf">_build_decoder</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">caps2</span><span class="p">,</span> <span class="n">one_hot_labels</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Build the decoder part from the last capsule layer</span>
<span class="sd">            **input:</span>
<span class="sd">                *Caps2:  Output of second Capsule layer</span>
<span class="sd">                *one_hot_labels</span>
<span class="sd">                *batch_size</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">one_hot_labels</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">NB_LABELS</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="c1"># squeeze(caps2):   [?, len_v_j,    capsules_nb]</span>
        <span class="c1"># labels:           [?, NB_LABELS,  1] with capsules_nb == NB_LABELS</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">caps2</span><span class="p">),</span> <span class="n">labels</span><span class="p">,</span> <span class="n">transpose_a</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># Select the good capsule vector</span>
        <span class="n">capsule_vector</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="o">.</span><span class="n">caps_2_vec_len</span><span class="p">))</span>
        <span class="c1"># capsule_vector: [?, len_v_j]</span>

        <span class="c1"># Reconstruct image</span>
        <span class="n">fc1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">fully_connected</span><span class="p">(</span><span class="n">capsule_vector</span><span class="p">,</span> <span class="n">num_outputs</span><span class="o">=</span><span class="mi">400</span><span class="p">)</span>
        <span class="n">fc1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">fc1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">16</span><span class="p">))</span>
        <span class="n">upsample1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">resize_nearest_neighbor</span><span class="p">(</span><span class="n">fc1</span><span class="p">,</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
        <span class="n">conv1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">upsample1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>

        <span class="n">upsample2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">resize_nearest_neighbor</span><span class="p">(</span><span class="n">conv1</span><span class="p">,</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">))</span>
        <span class="n">conv2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">upsample2</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>

        <span class="n">upsample3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">resize_nearest_neighbor</span><span class="p">(</span><span class="n">conv2</span><span class="p">,</span> <span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>
        <span class="n">conv6</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">upsample3</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>

        <span class="c1"># 3 channel for RGG</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">conv6</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">decoded</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;decoded&#39;</span><span class="p">)</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">image</span><span class="p">(</span><span class="s1">&#39;reconstruction_img&#39;</span><span class="p">,</span> <span class="n">decoded</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">decoded</span>

    <span class="k">def</span> <span class="nf">init</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Init the graph</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Get graph inputs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tf_images</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tf_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_inputs</span><span class="p">()</span>
        <span class="c1"># Dropout inputs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tf_conv_2_dropout</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv_2_dropout&#39;</span><span class="p">)</span>
        <span class="c1"># Dynamic batch size</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tf_images</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># Translate labels to one hot array</span>
        <span class="n">one_hot_labels</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tf_labels</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">NB_LABELS</span><span class="p">)</span>
        <span class="c1"># Create the first convolution and the CapsNet</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tf_caps1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tf_caps2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_main_network</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tf_images</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tf_conv_2_dropout</span><span class="p">)</span>

        <span class="c1"># Build the images reconstruction</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tf_decoded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_decoder</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tf_caps2</span><span class="p">,</span> <span class="n">one_hot_labels</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>

        <span class="c1"># Build the loss</span>
        <span class="n">_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_loss</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tf_caps2</span><span class="p">,</span> <span class="n">one_hot_labels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tf_labels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tf_decoded</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tf_images</span><span class="p">)</span>
        <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tf_loss_squared_rec</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tf_margin_loss_sum</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tf_predicted_class</span><span class="p">,</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">tf_correct_prediction</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tf_accuracy</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tf_loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tf_margin_loss</span><span class="p">,</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">tf_reconstruction_loss</span><span class="p">)</span> <span class="o">=</span> <span class="n">_loss</span>

        <span class="c1"># Build optimizer</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tf_optimizer</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tf_loss</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>

        <span class="c1"># Log value into tensorboard</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;margin_loss&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tf_margin_loss</span><span class="p">)</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tf_accuracy</span><span class="p">)</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;total_loss&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tf_loss</span><span class="p">)</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;reconstruction_loss&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tf_reconstruction_loss</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">tf_test</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span> <span class="n">minval</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">maxval</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;tf_test&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">init_session</span><span class="p">()</span>


    <span class="k">def</span> <span class="nf">_build_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">caps2</span><span class="p">,</span> <span class="n">one_hot_labels</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">decoded</span><span class="p">,</span> <span class="n">images</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Build the loss of the graph</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Get the length of each capsule</span>
        <span class="n">capsules_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">caps2</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>

        <span class="n">max_l</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.9</span> <span class="o">-</span> <span class="n">capsules_length</span><span class="p">))</span>
        <span class="n">max_l</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">max_l</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">NB_LABELS</span><span class="p">))</span>
        <span class="n">max_r</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="n">capsules_length</span> <span class="o">-</span> <span class="mf">0.1</span><span class="p">))</span>
        <span class="n">max_r</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">max_r</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">NB_LABELS</span><span class="p">))</span>
        <span class="n">t_c</span> <span class="o">=</span> <span class="n">one_hot_labels</span>
        <span class="n">m_loss</span> <span class="o">=</span> <span class="n">t_c</span> <span class="o">*</span> <span class="n">max_l</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">t_c</span><span class="p">)</span> <span class="o">*</span> <span class="n">max_r</span>
        <span class="n">margin_loss_sum</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">m_loss</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">margin_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">margin_loss_sum</span><span class="p">)</span>

        <span class="c1"># Reconstruction loss</span>
        <span class="n">loss_squared_rec</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">decoded</span> <span class="o">-</span> <span class="n">images</span><span class="p">)</span>
        <span class="n">reconstruction_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">loss_squared_rec</span><span class="p">)</span>

        <span class="c1"># 3. Total loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">margin_loss</span> <span class="o">+</span> <span class="p">(</span><span class="mf">0.0005</span> <span class="o">*</span> <span class="n">reconstruction_loss</span><span class="p">)</span>

        <span class="c1"># Accuracy</span>
        <span class="n">predicted_class</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">capsules_length</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">predicted_class</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">predicted_class</span><span class="p">,</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">capsules_length</span><span class="p">)[</span><span class="mi">0</span><span class="p">]])</span>
        <span class="n">correct_prediction</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">predicted_class</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">correct_prediction</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

        <span class="k">return</span> <span class="p">(</span><span class="n">loss_squared_rec</span><span class="p">,</span> <span class="n">margin_loss_sum</span><span class="p">,</span> <span class="n">predicted_class</span><span class="p">,</span> <span class="n">correct_prediction</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span>
                <span class="n">loss</span><span class="p">,</span> <span class="n">margin_loss</span><span class="p">,</span> <span class="n">reconstruction_loss</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">optimize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">tb_save</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Train the model</span>
<span class="sd">            **input: **</span>
<span class="sd">                *images: Image to train the model on</span>
<span class="sd">                *labels: True classes</span>
<span class="sd">                *tb_save: (Boolean) Log this optimization in tensorboard</span>
<span class="sd">            **return: **</span>
<span class="sd">                Loss: The loss of the model on this batch</span>
<span class="sd">                Acc: Accuracy of the model on this batch</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">tensors</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tf_optimizer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tf_margin_loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tf_accuracy</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tf_tensorboard</span><span class="p">]</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="n">summary</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span>
            <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tf_images</span><span class="p">:</span> <span class="n">images</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tf_labels</span><span class="p">:</span> <span class="n">labels</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tf_conv_2_dropout</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="o">.</span><span class="n">conv_2_dropout</span>
        <span class="p">})</span>

        <span class="k">if</span> <span class="n">tb_save</span><span class="p">:</span>
            <span class="c1"># Write data to tensorboard</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_writer</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span><span class="n">summary</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_writer_it</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_writer_it</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">acc</span>

    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">tb_train_save</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">tb_test_save</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Evaluate dataset</span>
<span class="sd">            **input: **</span>
<span class="sd">                *images: Image to train the model on</span>
<span class="sd">                *labels: True classes</span>
<span class="sd">                *tb_train_save: (Boolean) Log this optimization in tensorboard under the train part</span>
<span class="sd">                *tb_test_save: (Boolean) Log this optimization in tensorboard under the test part</span>
<span class="sd">            **return: **</span>
<span class="sd">                Loss: The loss of the model on this batch</span>
<span class="sd">                Acc: Accuracy of the model on this batch</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">tensors</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tf_margin_loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tf_accuracy</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tf_tensorboard</span><span class="p">]</span>
        <span class="n">loss</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="n">summary</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span>
                <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tf_images</span><span class="p">:</span> <span class="n">images</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tf_labels</span><span class="p">:</span> <span class="n">labels</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tf_conv_2_dropout</span><span class="p">:</span> <span class="mf">1.</span>
            <span class="p">})</span>

        <span class="k">if</span> <span class="n">tb_test_save</span><span class="p">:</span>
            <span class="c1"># Write data to tensorboard</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">test_writer</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span><span class="n">summary</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_writer_it</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">test_writer_it</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="n">tb_train_save</span><span class="p">:</span>
            <span class="c1"># Write data to tensorboard</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_writer</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span><span class="n">summary</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_writer_it</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_writer_it</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">acc</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">images</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Method used to predict a class</span>
<span class="sd">            Return a softmax</span>
<span class="sd">            **input: **</span>
<span class="sd">                *images: Image to train the model on</span>
<span class="sd">            **return:</span>
<span class="sd">                *softmax: Softmax between all capsules</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">tensors</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tf_caps2</span><span class="p">]</span>

        <span class="n">caps2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span>
            <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tf_images</span><span class="p">:</span> <span class="n">images</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tf_conv_2_dropout</span><span class="p">:</span> <span class="mf">1.</span>
        <span class="p">})[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># tf.sqrt(tf.reduce_sum(tf.square(caps2), axis=2, keep_dims=True))</span>
        <span class="n">caps2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">caps2</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
        <span class="n">caps2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">caps2</span><span class="p">,</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">images</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">NB_LABELS</span><span class="p">))</span>
        <span class="c1"># softmax</span>
        <span class="n">softmax</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">caps2</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">caps2</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">softmax</span>

    <span class="k">def</span> <span class="nf">reconstruction</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Method used to get the reconstructions given a batch</span>
<span class="sd">            Return the result as a softmax</span>
<span class="sd">            **input: **</span>
<span class="sd">                *images: Image to train the model on</span>
<span class="sd">                *labels: True classes</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">tensors</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tf_decoded</span><span class="p">]</span>

        <span class="n">decoded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span>
            <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tf_images</span><span class="p">:</span> <span class="n">images</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tf_labels</span><span class="p">:</span> <span class="n">labels</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tf_conv_2_dropout</span><span class="p">:</span> <span class="mf">1.</span>
        <span class="p">})[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">decoded</span>

    <span class="k">def</span> <span class="nf">evaluate_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Evaluate a full dataset</span>
<span class="sd">            This method is used to fully evaluate the dataset batch per batch. Useful when</span>
<span class="sd">            the dataset can&#39;t be fit inside to the GPU.</span>
<span class="sd">            *input: **</span>
<span class="sd">                *images: Image to train the model on</span>
<span class="sd">                *labels: True classes</span>
<span class="sd">            *return: **</span>
<span class="sd">                *loss: Loss overall your dataset</span>
<span class="sd">                *accuracy: Accuracy overall your dataset</span>
<span class="sd">                *predicted_class: Predicted class</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">tensors</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tf_loss_squared_rec</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tf_margin_loss_sum</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tf_correct_prediction</span><span class="p">,</span>
                   <span class="bp">self</span><span class="o">.</span><span class="n">tf_predicted_class</span><span class="p">]</span>

        <span class="n">loss_squared_rec_list</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">margin_loss_sum_list</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">correct_prediction_list</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">predicted_class</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">b</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_batches</span><span class="p">([</span><span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">],</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
            <span class="n">images_batch</span><span class="p">,</span> <span class="n">labels_batch</span> <span class="o">=</span> <span class="n">batch</span>
            <span class="n">loss_squared_rec</span><span class="p">,</span> <span class="n">margin_loss_sum</span><span class="p">,</span> <span class="n">correct_prediction</span><span class="p">,</span> <span class="n">classes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span>
                <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tf_images</span><span class="p">:</span> <span class="n">images_batch</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tf_labels</span><span class="p">:</span> <span class="n">labels_batch</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tf_conv_2_dropout</span><span class="p">:</span> <span class="mf">1.</span>
            <span class="p">})</span>
            <span class="k">if</span> <span class="n">loss_squared_rec_list</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">predicted_class</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">predicted_class</span><span class="p">,</span> <span class="n">classes</span><span class="p">))</span>
                <span class="n">loss_squared_rec_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">loss_squared_rec_list</span><span class="p">,</span> <span class="n">loss_squared_rec</span><span class="p">))</span>
                <span class="n">margin_loss_sum_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">margin_loss_sum_list</span><span class="p">,</span> <span class="n">margin_loss_sum</span><span class="p">))</span>
                <span class="n">correct_prediction_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">correct_prediction_list</span><span class="p">,</span> <span class="n">correct_prediction</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">predicted_class</span> <span class="o">=</span> <span class="n">classes</span>
                <span class="n">loss_squared_rec_list</span> <span class="o">=</span> <span class="n">loss_squared_rec</span>
                <span class="n">margin_loss_sum_list</span> <span class="o">=</span> <span class="n">margin_loss_sum</span>
                <span class="n">correct_prediction_list</span> <span class="o">=</span> <span class="n">correct_prediction</span>
            <span class="n">b</span> <span class="o">+=</span> <span class="n">batch_size</span>

        <span class="n">margin_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">margin_loss_sum_list</span><span class="p">)</span>
        <span class="n">reconstruction_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">loss_squared_rec_list</span><span class="p">)</span>
        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">correct_prediction_list</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">margin_loss</span>

        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">predicted_class</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Train,-Validate-and-Test-the-Model">Train, Validate and Test the Model<a class="anchor-link" href="#Train,-Validate-and-Test-the-Model">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>A validation set can be used to assess how well the model is performing. A low accuracy on the training and validation
sets imply underfitting. A high accuracy on the training set but low accuracy on the validation set implies overfitting.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Init model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ModelTrafficSign</span><span class="p">(</span><span class="s2">&quot;TrafficSign&quot;</span><span class="p">,</span> <span class="n">output_folder</span><span class="o">=</span><span class="s2">&quot;outputs&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">### Train your model here.</span>
<span class="c1">### Calculate and report the accuracy on the training and validation set.</span>
<span class="c1">### Once a final model architecture is selected, </span>
<span class="c1">### the accuracy on the test set should be calculated and reported as well.</span>
<span class="c1">### Feel free to use as many code cells as needed.</span>

<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">50</span>

<span class="c1"># Utils method to print the current progression</span>
<span class="k">def</span> <span class="nf">plot_progression</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span> <span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;[</span><span class="si">%s</span><span class="s2">] Batch ID = </span><span class="si">%s</span><span class="s2">, loss = </span><span class="si">%s</span><span class="s2">, acc = </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">acc</span><span class="p">))</span>

<span class="c1"># Training pipeline</span>
<span class="n">b</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">valid_batch</span> <span class="o">=</span> <span class="n">inference_datagen</span><span class="o">.</span><span class="n">flow</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
<span class="n">best_validation_loss</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">augmented_factor</span> <span class="o">=</span> <span class="mf">0.99</span>
<span class="n">decrease_factor</span> <span class="o">=</span> <span class="mf">0.90</span>
<span class="n">train_batches</span> <span class="o">=</span> <span class="n">train_datagen</span><span class="o">.</span><span class="n">flow</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
<span class="n">augmented_train_batches</span> <span class="o">=</span> <span class="n">train_datagen_augmented</span><span class="o">.</span><span class="n">flow</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">)</span>

<span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
    <span class="n">next_batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span>
        <span class="n">augmented_train_batches</span> <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">augmented_factor</span> <span class="k">else</span> <span class="n">train_batches</span><span class="p">)</span>
    <span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="o">=</span> <span class="n">next_batch</span>

    <span class="c1">### Training</span>
    <span class="n">cost</span><span class="p">,</span> <span class="n">acc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>
    <span class="c1">### Validation</span>
    <span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">valid_batch</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="c1"># Retrieve the cost and acc on this validation batch and save it in tensorboard</span>
    <span class="n">cost_val</span><span class="p">,</span> <span class="n">acc_val</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">,</span> <span class="n">tb_test_save</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">b</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># Plot the last results</span>
        <span class="n">plot_progression</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="s2">&quot;Train&quot;</span><span class="p">)</span>
        <span class="n">plot_progression</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">cost_val</span><span class="p">,</span> <span class="n">acc_val</span><span class="p">,</span> <span class="s2">&quot;Validation&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">b</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># Test the model on all the validation</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Evaluate full validation dataset ...&quot;</span><span class="p">)</span>
        <span class="n">loss</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate_dataset</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Current loss: </span><span class="si">%s</span><span class="s2"> Best loss: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">best_validation_loss</span><span class="p">))</span>
        <span class="n">plot_progression</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="s2">&quot;TOTAL Validation&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">best_validation_loss</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">loss</span> <span class="o">&lt;</span> <span class="n">best_validation_loss</span><span class="p">:</span>
            <span class="n">best_validation_loss</span> <span class="o">=</span> <span class="n">loss</span>
            <span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>
        <span class="n">augmented_factor</span> <span class="o">=</span> <span class="n">augmented_factor</span> <span class="o">*</span> <span class="n">decrease_factor</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Augmented Factor = </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">augmented_factor</span><span class="p">)</span>

    <span class="n">b</span> <span class="o">+=</span> <span class="mi">1</span>


  
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[Train] Batch ID = 0, loss = 2.42539, acc = 0.02
[Validation] Batch ID = 0, loss = 0.800529, acc = 0.04
Evaluate full validation dataset ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Saving model ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Current loss: 0.781535 Best loss: None
[TOTAL Validation] Batch ID = 0, loss = 0.781535, acc = 0.0185941043084
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Model successfully saved here: outputs/checkpoints/c1s_9_c1n_256_c2s_6_c2n_64_c2d_0.7_c1vl_16_c1s_5_c1nf_16_c2vl_32_lr_0.0001_rs_1--TrafficSign--1510487290.423481
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Augmented Factor = 0.891
[Train] Batch ID = 10, loss = 0.754666, acc = 0.04
[Validation] Batch ID = 10, loss = 0.753758, acc = 0.04
[Train] Batch ID = 20, loss = 0.690922, acc = 0.06
[Validation] Batch ID = 20, loss = 0.702244, acc = 0.06
[Train] Batch ID = 30, loss = 0.6284, acc = 0.1
[Validation] Batch ID = 30, loss = 0.659595, acc = 0.06
[Train] Batch ID = 40, loss = 0.63592, acc = 0.1
[Validation] Batch ID = 40, loss = 0.659709, acc = 0.04
[Train] Batch ID = 50, loss = 0.616082, acc = 0.16
[Validation] Batch ID = 50, loss = 0.599504, acc = 0.06
[Train] Batch ID = 60, loss = 0.621295, acc = 0.1
[Validation] Batch ID = 60, loss = 0.604651, acc = 0.1
[Train] Batch ID = 70, loss = 0.617128, acc = 0.06
[Validation] Batch ID = 70, loss = 0.597139, acc = 0.1
[Train] Batch ID = 80, loss = 0.590053, acc = 0.14
[Validation] Batch ID = 80, loss = 0.579464, acc = 0.1
[Train] Batch ID = 90, loss = 0.596748, acc = 0.06
[Validation] Batch ID = 90, loss = 0.590638, acc = 0.16
[Train] Batch ID = 100, loss = 0.571133, acc = 0.16
[Validation] Batch ID = 100, loss = 0.593388, acc = 0.16
[Train] Batch ID = 110, loss = 0.584303, acc = 0.12
[Validation] Batch ID = 110, loss = 0.593405, acc = 0.08
[Train] Batch ID = 120, loss = 0.591267, acc = 0.14
[Validation] Batch ID = 120, loss = 0.570968, acc = 0.18
[Train] Batch ID = 130, loss = 0.576181, acc = 0.16
[Validation] Batch ID = 130, loss = 0.559474, acc = 0.18
[Train] Batch ID = 140, loss = 0.571011, acc = 0.1
[Validation] Batch ID = 140, loss = 0.537225, acc = 0.22
[Train] Batch ID = 150, loss = 0.571272, acc = 0.12
[Validation] Batch ID = 150, loss = 0.543216, acc = 0.24
[Train] Batch ID = 160, loss = 0.550595, acc = 0.18
[Validation] Batch ID = 160, loss = 0.581442, acc = 0.12
[Train] Batch ID = 170, loss = 0.58082, acc = 0.1
[Validation] Batch ID = 170, loss = 0.576819, acc = 0.16
[Train] Batch ID = 180, loss = 0.566915, acc = 0.2
[Validation] Batch ID = 180, loss = 0.57347, acc = 0.1
[Train] Batch ID = 190, loss = 0.576022, acc = 0.16
[Validation] Batch ID = 190, loss = 0.567339, acc = 0.2
[Train] Batch ID = 200, loss = 0.536268, acc = 0.22
[Validation] Batch ID = 200, loss = 0.521454, acc = 0.24
[Train] Batch ID = 210, loss = 0.59091, acc = 0.06
[Validation] Batch ID = 210, loss = 0.535439, acc = 0.26
[Train] Batch ID = 220, loss = 0.563106, acc = 0.14
[Validation] Batch ID = 220, loss = 0.496016, acc = 0.28
[Train] Batch ID = 230, loss = 0.572187, acc = 0.2
[Validation] Batch ID = 230, loss = 0.55189, acc = 0.22
[Train] Batch ID = 240, loss = 0.579677, acc = 0.16
[Validation] Batch ID = 240, loss = 0.503579, acc = 0.26
[Train] Batch ID = 250, loss = 0.54702, acc = 0.18
[Validation] Batch ID = 250, loss = 0.545198, acc = 0.18
[Train] Batch ID = 260, loss = 0.565367, acc = 0.16
[Validation] Batch ID = 260, loss = 0.544931, acc = 0.24
[Train] Batch ID = 270, loss = 0.550182, acc = 0.24
[Validation] Batch ID = 270, loss = 0.518467, acc = 0.2
[Train] Batch ID = 280, loss = 0.502248, acc = 0.28
[Validation] Batch ID = 280, loss = 0.516729, acc = 0.22
[Train] Batch ID = 290, loss = 0.592575, acc = 0.14
[Validation] Batch ID = 290, loss = 0.533068, acc = 0.26
[Train] Batch ID = 300, loss = 0.526132, acc = 0.24
[Validation] Batch ID = 300, loss = 0.50696, acc = 0.34
[Train] Batch ID = 310, loss = 0.560534, acc = 0.2
[Validation] Batch ID = 310, loss = 0.555453, acc = 0.24
[Train] Batch ID = 320, loss = 0.490622, acc = 0.34
[Validation] Batch ID = 320, loss = 0.541549, acc = 0.24
[Train] Batch ID = 330, loss = 0.544868, acc = 0.28
[Validation] Batch ID = 330, loss = 0.551774, acc = 0.26
[Train] Batch ID = 340, loss = 0.544464, acc = 0.12
[Validation] Batch ID = 340, loss = 0.49482, acc = 0.42
[Train] Batch ID = 350, loss = 0.575958, acc = 0.14
[Validation] Batch ID = 350, loss = 0.493718, acc = 0.3
[Train] Batch ID = 360, loss = 0.54912, acc = 0.22
[Validation] Batch ID = 360, loss = 0.531574, acc = 0.3
[Train] Batch ID = 370, loss = 0.540033, acc = 0.2
[Validation] Batch ID = 370, loss = 0.505985, acc = 0.4
[Train] Batch ID = 380, loss = 0.525236, acc = 0.24
[Validation] Batch ID = 380, loss = 0.516121, acc = 0.3
[Train] Batch ID = 390, loss = 0.555539, acc = 0.18
[Validation] Batch ID = 390, loss = 0.548367, acc = 0.16
[Train] Batch ID = 400, loss = 0.568358, acc = 0.12
[Validation] Batch ID = 400, loss = 0.50561, acc = 0.32
[Train] Batch ID = 410, loss = 0.52281, acc = 0.2
[Validation] Batch ID = 410, loss = 0.510524, acc = 0.3
[Train] Batch ID = 420, loss = 0.498897, acc = 0.32
[Validation] Batch ID = 420, loss = 0.489266, acc = 0.38
[Train] Batch ID = 430, loss = 0.528072, acc = 0.2
[Validation] Batch ID = 430, loss = 0.492686, acc = 0.3
[Train] Batch ID = 440, loss = 0.533394, acc = 0.24
[Validation] Batch ID = 440, loss = 0.522744, acc = 0.18
[Train] Batch ID = 450, loss = 0.519317, acc = 0.22
[Validation] Batch ID = 450, loss = 0.502148, acc = 0.28
[Train] Batch ID = 460, loss = 0.532956, acc = 0.22
[Validation] Batch ID = 460, loss = 0.496181, acc = 0.28
[Train] Batch ID = 470, loss = 0.554523, acc = 0.16
[Validation] Batch ID = 470, loss = 0.489495, acc = 0.34
[Train] Batch ID = 480, loss = 0.543094, acc = 0.16
[Validation] Batch ID = 480, loss = 0.513759, acc = 0.26
[Train] Batch ID = 490, loss = 0.552911, acc = 0.14
[Validation] Batch ID = 490, loss = 0.528018, acc = 0.22
[Train] Batch ID = 500, loss = 0.547266, acc = 0.2
[Validation] Batch ID = 500, loss = 0.491217, acc = 0.32
[Train] Batch ID = 510, loss = 0.548772, acc = 0.24
[Validation] Batch ID = 510, loss = 0.476296, acc = 0.36
[Train] Batch ID = 520, loss = 0.521309, acc = 0.18
[Validation] Batch ID = 520, loss = 0.487757, acc = 0.26
[Train] Batch ID = 530, loss = 0.494148, acc = 0.3
[Validation] Batch ID = 530, loss = 0.472203, acc = 0.38
[Train] Batch ID = 540, loss = 0.556524, acc = 0.22
[Validation] Batch ID = 540, loss = 0.511071, acc = 0.24
[Train] Batch ID = 550, loss = 0.515253, acc = 0.26
[Validation] Batch ID = 550, loss = 0.472468, acc = 0.32
[Train] Batch ID = 560, loss = 0.516666, acc = 0.24
[Validation] Batch ID = 560, loss = 0.483363, acc = 0.3
[Train] Batch ID = 570, loss = 0.524725, acc = 0.28
[Validation] Batch ID = 570, loss = 0.468372, acc = 0.42
[Train] Batch ID = 580, loss = 0.505188, acc = 0.26
[Validation] Batch ID = 580, loss = 0.427392, acc = 0.5
[Train] Batch ID = 590, loss = 0.516176, acc = 0.24
[Validation] Batch ID = 590, loss = 0.464795, acc = 0.4
[Train] Batch ID = 600, loss = 0.480228, acc = 0.36
[Validation] Batch ID = 600, loss = 0.467607, acc = 0.38
[Train] Batch ID = 610, loss = 0.519255, acc = 0.28
[Validation] Batch ID = 610, loss = 0.480409, acc = 0.3
[Train] Batch ID = 620, loss = 0.45362, acc = 0.38
[Validation] Batch ID = 620, loss = 0.479688, acc = 0.32
[Train] Batch ID = 630, loss = 0.505263, acc = 0.36
[Validation] Batch ID = 630, loss = 0.43897, acc = 0.48
[Train] Batch ID = 640, loss = 0.524474, acc = 0.2
[Validation] Batch ID = 640, loss = 0.434479, acc = 0.5
[Train] Batch ID = 650, loss = 0.532827, acc = 0.18
[Validation] Batch ID = 650, loss = 0.470422, acc = 0.4
[Train] Batch ID = 660, loss = 0.540052, acc = 0.2
[Validation] Batch ID = 660, loss = 0.468874, acc = 0.38
[Train] Batch ID = 670, loss = 0.507133, acc = 0.34
[Validation] Batch ID = 670, loss = 0.471876, acc = 0.38
[Train] Batch ID = 680, loss = 0.507654, acc = 0.26
[Validation] Batch ID = 680, loss = 0.472959, acc = 0.36
[Train] Batch ID = 690, loss = 0.510228, acc = 0.24
[Validation] Batch ID = 690, loss = 0.454647, acc = 0.46
[Train] Batch ID = 700, loss = 0.539066, acc = 0.2
[Validation] Batch ID = 700, loss = 0.475782, acc = 0.42
[Train] Batch ID = 710, loss = 0.478445, acc = 0.36
[Validation] Batch ID = 710, loss = 0.548267, acc = 0.18
[Train] Batch ID = 720, loss = 0.531311, acc = 0.22
[Validation] Batch ID = 720, loss = 0.469229, acc = 0.32
[Train] Batch ID = 730, loss = 0.538671, acc = 0.16
[Validation] Batch ID = 730, loss = 0.45337, acc = 0.36
[Train] Batch ID = 740, loss = 0.486048, acc = 0.3
[Validation] Batch ID = 740, loss = 0.447456, acc = 0.34
[Train] Batch ID = 750, loss = 0.47318, acc = 0.32
[Validation] Batch ID = 750, loss = 0.45879, acc = 0.32
[Train] Batch ID = 760, loss = 0.492232, acc = 0.34
[Validation] Batch ID = 760, loss = 0.427461, acc = 0.36
[Train] Batch ID = 770, loss = 0.480728, acc = 0.32
[Validation] Batch ID = 770, loss = 0.491949, acc = 0.34
[Train] Batch ID = 780, loss = 0.538773, acc = 0.22
[Validation] Batch ID = 780, loss = 0.467119, acc = 0.36
[Train] Batch ID = 790, loss = 0.494922, acc = 0.38
[Validation] Batch ID = 790, loss = 0.453295, acc = 0.34
[Train] Batch ID = 800, loss = 0.403864, acc = 0.54
[Validation] Batch ID = 800, loss = 0.457517, acc = 0.4
[Train] Batch ID = 810, loss = 0.481897, acc = 0.4
[Validation] Batch ID = 810, loss = 0.464976, acc = 0.34
[Train] Batch ID = 820, loss = 0.479418, acc = 0.34
[Validation] Batch ID = 820, loss = 0.388256, acc = 0.52
[Train] Batch ID = 830, loss = 0.523011, acc = 0.22
[Validation] Batch ID = 830, loss = 0.424948, acc = 0.48
[Train] Batch ID = 840, loss = 0.50887, acc = 0.28
[Validation] Batch ID = 840, loss = 0.440439, acc = 0.4
[Train] Batch ID = 850, loss = 0.410404, acc = 0.5
[Validation] Batch ID = 850, loss = 0.496405, acc = 0.36
[Train] Batch ID = 860, loss = 0.516683, acc = 0.3
[Validation] Batch ID = 860, loss = 0.392151, acc = 0.44
[Train] Batch ID = 870, loss = 0.497217, acc = 0.28
[Validation] Batch ID = 870, loss = 0.448474, acc = 0.28
[Train] Batch ID = 880, loss = 0.500635, acc = 0.3
[Validation] Batch ID = 880, loss = 0.408743, acc = 0.44
[Train] Batch ID = 890, loss = 0.500936, acc = 0.26
[Validation] Batch ID = 890, loss = 0.442819, acc = 0.32
[Train] Batch ID = 900, loss = 0.468844, acc = 0.38
[Validation] Batch ID = 900, loss = 0.427008, acc = 0.44
[Train] Batch ID = 910, loss = 0.46857, acc = 0.42
[Validation] Batch ID = 910, loss = 0.417586, acc = 0.44
[Train] Batch ID = 920, loss = 0.472717, acc = 0.34
[Validation] Batch ID = 920, loss = 0.467422, acc = 0.36
[Train] Batch ID = 930, loss = 0.469254, acc = 0.36
[Validation] Batch ID = 930, loss = 0.376776, acc = 0.54
[Train] Batch ID = 940, loss = 0.434811, acc = 0.44
[Validation] Batch ID = 940, loss = 0.467765, acc = 0.38
[Train] Batch ID = 950, loss = 0.483722, acc = 0.3
[Validation] Batch ID = 950, loss = 0.417313, acc = 0.42
[Train] Batch ID = 960, loss = 0.375907, acc = 0.54
[Validation] Batch ID = 960, loss = 0.452141, acc = 0.4
[Train] Batch ID = 970, loss = 0.47038, acc = 0.36
[Validation] Batch ID = 970, loss = 0.407389, acc = 0.4
[Train] Batch ID = 980, loss = 0.442751, acc = 0.34
[Validation] Batch ID = 980, loss = 0.406002, acc = 0.48
[Train] Batch ID = 990, loss = 0.506468, acc = 0.26
[Validation] Batch ID = 990, loss = 0.434915, acc = 0.42
[Train] Batch ID = 1000, loss = 0.497463, acc = 0.26
[Validation] Batch ID = 1000, loss = 0.4204, acc = 0.4
Evaluate full validation dataset ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Saving model ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Current loss: 0.420879 Best loss: 0.781535
[TOTAL Validation] Batch ID = 1000, loss = 0.420879, acc = 0.470975056689
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Model successfully saved here: outputs/checkpoints/c1s_9_c1n_256_c2s_6_c2n_64_c2d_0.7_c1vl_16_c1s_5_c1nf_16_c2vl_32_lr_0.0001_rs_1--TrafficSign--1510487290.423481
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Augmented Factor = 0.8019000000000001
[Train] Batch ID = 1010, loss = 0.496853, acc = 0.24
[Validation] Batch ID = 1010, loss = 0.409362, acc = 0.62
[Train] Batch ID = 1020, loss = 0.471861, acc = 0.34
[Validation] Batch ID = 1020, loss = 0.427412, acc = 0.44
[Train] Batch ID = 1030, loss = 0.514602, acc = 0.22
[Validation] Batch ID = 1030, loss = 0.416222, acc = 0.5
[Train] Batch ID = 1040, loss = 0.460027, acc = 0.42
[Validation] Batch ID = 1040, loss = 0.392695, acc = 0.52
[Train] Batch ID = 1050, loss = 0.468029, acc = 0.34
[Validation] Batch ID = 1050, loss = 0.369591, acc = 0.52
[Train] Batch ID = 1060, loss = 0.492225, acc = 0.26
[Validation] Batch ID = 1060, loss = 0.420142, acc = 0.44
[Train] Batch ID = 1070, loss = 0.364011, acc = 0.54
[Validation] Batch ID = 1070, loss = 0.445401, acc = 0.38
[Train] Batch ID = 1080, loss = 0.504283, acc = 0.3
[Validation] Batch ID = 1080, loss = 0.456438, acc = 0.4
[Train] Batch ID = 1090, loss = 0.465189, acc = 0.34
[Validation] Batch ID = 1090, loss = 0.428296, acc = 0.46
[Train] Batch ID = 1100, loss = 0.478776, acc = 0.32
[Validation] Batch ID = 1100, loss = 0.395044, acc = 0.4
[Train] Batch ID = 1110, loss = 0.451158, acc = 0.46
[Validation] Batch ID = 1110, loss = 0.432168, acc = 0.42
[Train] Batch ID = 1120, loss = 0.458794, acc = 0.48
[Validation] Batch ID = 1120, loss = 0.359051, acc = 0.6
[Train] Batch ID = 1130, loss = 0.50207, acc = 0.28
[Validation] Batch ID = 1130, loss = 0.398094, acc = 0.46
[Train] Batch ID = 1140, loss = 0.44812, acc = 0.42
[Validation] Batch ID = 1140, loss = 0.405418, acc = 0.4
[Train] Batch ID = 1150, loss = 0.347661, acc = 0.58
[Validation] Batch ID = 1150, loss = 0.405562, acc = 0.44
[Train] Batch ID = 1160, loss = 0.462926, acc = 0.3
[Validation] Batch ID = 1160, loss = 0.397567, acc = 0.46
[Train] Batch ID = 1170, loss = 0.491247, acc = 0.32
[Validation] Batch ID = 1170, loss = 0.355188, acc = 0.56
[Train] Batch ID = 1180, loss = 0.459735, acc = 0.4
[Validation] Batch ID = 1180, loss = 0.37437, acc = 0.54
[Train] Batch ID = 1190, loss = 0.446793, acc = 0.38
[Validation] Batch ID = 1190, loss = 0.341955, acc = 0.52
[Train] Batch ID = 1200, loss = 0.468472, acc = 0.38
[Validation] Batch ID = 1200, loss = 0.340791, acc = 0.62
[Train] Batch ID = 1210, loss = 0.484371, acc = 0.34
[Validation] Batch ID = 1210, loss = 0.360404, acc = 0.54
[Train] Batch ID = 1220, loss = 0.310755, acc = 0.68
[Validation] Batch ID = 1220, loss = 0.413266, acc = 0.48
[Train] Batch ID = 1230, loss = 0.473296, acc = 0.38
[Validation] Batch ID = 1230, loss = 0.360279, acc = 0.54
[Train] Batch ID = 1240, loss = 0.34034, acc = 0.62
[Validation] Batch ID = 1240, loss = 0.35162, acc = 0.6
[Train] Batch ID = 1250, loss = 0.278886, acc = 0.7
[Validation] Batch ID = 1250, loss = 0.396671, acc = 0.48
[Train] Batch ID = 1260, loss = 0.449707, acc = 0.38
[Validation] Batch ID = 1260, loss = 0.381212, acc = 0.54
[Train] Batch ID = 1270, loss = 0.376544, acc = 0.48
[Validation] Batch ID = 1270, loss = 0.390168, acc = 0.38
[Train] Batch ID = 1280, loss = 0.451085, acc = 0.44
[Validation] Batch ID = 1280, loss = 0.359862, acc = 0.64
[Train] Batch ID = 1290, loss = 0.456261, acc = 0.28
[Validation] Batch ID = 1290, loss = 0.355488, acc = 0.6
[Train] Batch ID = 1300, loss = 0.436061, acc = 0.42
[Validation] Batch ID = 1300, loss = 0.355017, acc = 0.56
[Train] Batch ID = 1310, loss = 0.433736, acc = 0.44
[Validation] Batch ID = 1310, loss = 0.384685, acc = 0.5
[Train] Batch ID = 1320, loss = 0.456236, acc = 0.44
[Validation] Batch ID = 1320, loss = 0.326546, acc = 0.58
[Train] Batch ID = 1330, loss = 0.452049, acc = 0.34
[Validation] Batch ID = 1330, loss = 0.346212, acc = 0.64
[Train] Batch ID = 1340, loss = 0.490594, acc = 0.32
[Validation] Batch ID = 1340, loss = 0.367138, acc = 0.54
[Train] Batch ID = 1350, loss = 0.427571, acc = 0.42
[Validation] Batch ID = 1350, loss = 0.405136, acc = 0.5
[Train] Batch ID = 1360, loss = 0.457444, acc = 0.4
[Validation] Batch ID = 1360, loss = 0.34277, acc = 0.68
[Train] Batch ID = 1370, loss = 0.427655, acc = 0.46
[Validation] Batch ID = 1370, loss = 0.401085, acc = 0.44
[Train] Batch ID = 1380, loss = 0.331077, acc = 0.62
[Validation] Batch ID = 1380, loss = 0.34276, acc = 0.58
[Train] Batch ID = 1390, loss = 0.448891, acc = 0.38
[Validation] Batch ID = 1390, loss = 0.352252, acc = 0.62
[Train] Batch ID = 1400, loss = 0.323489, acc = 0.58
[Validation] Batch ID = 1400, loss = 0.346049, acc = 0.58
[Train] Batch ID = 1410, loss = 0.460835, acc = 0.32
[Validation] Batch ID = 1410, loss = 0.320473, acc = 0.64
[Train] Batch ID = 1420, loss = 0.441399, acc = 0.46
[Validation] Batch ID = 1420, loss = 0.356037, acc = 0.6
[Train] Batch ID = 1430, loss = 0.42792, acc = 0.4
[Validation] Batch ID = 1430, loss = 0.372609, acc = 0.5
[Train] Batch ID = 1440, loss = 0.421128, acc = 0.46
[Validation] Batch ID = 1440, loss = 0.338345, acc = 0.48
[Train] Batch ID = 1450, loss = 0.413183, acc = 0.44
[Validation] Batch ID = 1450, loss = 0.27971, acc = 0.72
[Train] Batch ID = 1460, loss = 0.25103, acc = 0.8
[Validation] Batch ID = 1460, loss = 0.319824, acc = 0.74
[Train] Batch ID = 1470, loss = 0.2984, acc = 0.68
[Validation] Batch ID = 1470, loss = 0.343686, acc = 0.58
[Train] Batch ID = 1480, loss = 0.415059, acc = 0.48
[Validation] Batch ID = 1480, loss = 0.395304, acc = 0.46
[Train] Batch ID = 1490, loss = 0.446148, acc = 0.46
[Validation] Batch ID = 1490, loss = 0.318186, acc = 0.62
[Train] Batch ID = 1500, loss = 0.265598, acc = 0.78
[Validation] Batch ID = 1500, loss = 0.358759, acc = 0.62
[Train] Batch ID = 1510, loss = 0.459229, acc = 0.34
[Validation] Batch ID = 1510, loss = 0.323201, acc = 0.64
[Train] Batch ID = 1520, loss = 0.294999, acc = 0.68
[Validation] Batch ID = 1520, loss = 0.344207, acc = 0.58
[Train] Batch ID = 1530, loss = 0.457452, acc = 0.4
[Validation] Batch ID = 1530, loss = 0.352485, acc = 0.56
[Train] Batch ID = 1540, loss = 0.453467, acc = 0.26
[Validation] Batch ID = 1540, loss = 0.344013, acc = 0.6
[Train] Batch ID = 1550, loss = 0.450082, acc = 0.42
[Validation] Batch ID = 1550, loss = 0.32179, acc = 0.6
[Train] Batch ID = 1560, loss = 0.400382, acc = 0.52
[Validation] Batch ID = 1560, loss = 0.315771, acc = 0.68
[Train] Batch ID = 1570, loss = 0.39355, acc = 0.56
[Validation] Batch ID = 1570, loss = 0.33907, acc = 0.6
[Train] Batch ID = 1580, loss = 0.445468, acc = 0.48
[Validation] Batch ID = 1580, loss = 0.298213, acc = 0.74
[Train] Batch ID = 1590, loss = 0.435894, acc = 0.48
[Validation] Batch ID = 1590, loss = 0.336447, acc = 0.56
[Train] Batch ID = 1600, loss = 0.425818, acc = 0.46
[Validation] Batch ID = 1600, loss = 0.301797, acc = 0.62
[Train] Batch ID = 1610, loss = 0.439953, acc = 0.38
[Validation] Batch ID = 1610, loss = 0.295448, acc = 0.64
[Train] Batch ID = 1620, loss = 0.229374, acc = 0.82
[Validation] Batch ID = 1620, loss = 0.287782, acc = 0.62
[Train] Batch ID = 1630, loss = 0.276425, acc = 0.7
[Validation] Batch ID = 1630, loss = 0.333368, acc = 0.58
[Train] Batch ID = 1640, loss = 0.387417, acc = 0.44
[Validation] Batch ID = 1640, loss = 0.270235, acc = 0.68
[Train] Batch ID = 1650, loss = 0.458957, acc = 0.28
[Validation] Batch ID = 1650, loss = 0.318385, acc = 0.54
[Train] Batch ID = 1660, loss = 0.444638, acc = 0.44
[Validation] Batch ID = 1660, loss = 0.31394, acc = 0.64
[Train] Batch ID = 1670, loss = 0.472951, acc = 0.28
[Validation] Batch ID = 1670, loss = 0.35642, acc = 0.58
[Train] Batch ID = 1680, loss = 0.434045, acc = 0.38
[Validation] Batch ID = 1680, loss = 0.306302, acc = 0.7
[Train] Batch ID = 1690, loss = 0.411147, acc = 0.48
[Validation] Batch ID = 1690, loss = 0.286524, acc = 0.8
[Train] Batch ID = 1700, loss = 0.440254, acc = 0.48
[Validation] Batch ID = 1700, loss = 0.312365, acc = 0.7
[Train] Batch ID = 1710, loss = 0.295739, acc = 0.7
[Validation] Batch ID = 1710, loss = 0.298856, acc = 0.7
[Train] Batch ID = 1720, loss = 0.424864, acc = 0.38
[Validation] Batch ID = 1720, loss = 0.317582, acc = 0.68
[Train] Batch ID = 1730, loss = 0.262031, acc = 0.8
[Validation] Batch ID = 1730, loss = 0.342855, acc = 0.66
[Train] Batch ID = 1740, loss = 0.365308, acc = 0.58
[Validation] Batch ID = 1740, loss = 0.285149, acc = 0.66
[Train] Batch ID = 1750, loss = 0.283401, acc = 0.7
[Validation] Batch ID = 1750, loss = 0.29662, acc = 0.74
[Train] Batch ID = 1760, loss = 0.410071, acc = 0.52
[Validation] Batch ID = 1760, loss = 0.31923, acc = 0.56
[Train] Batch ID = 1770, loss = 0.435369, acc = 0.42
[Validation] Batch ID = 1770, loss = 0.242582, acc = 0.84
[Train] Batch ID = 1780, loss = 0.463449, acc = 0.36
[Validation] Batch ID = 1780, loss = 0.315357, acc = 0.66
[Train] Batch ID = 1790, loss = 0.387501, acc = 0.52
[Validation] Batch ID = 1790, loss = 0.325985, acc = 0.5
[Train] Batch ID = 1800, loss = 0.377839, acc = 0.52
[Validation] Batch ID = 1800, loss = 0.293942, acc = 0.7
[Train] Batch ID = 1810, loss = 0.411971, acc = 0.48
[Validation] Batch ID = 1810, loss = 0.306874, acc = 0.64
[Train] Batch ID = 1820, loss = 0.423058, acc = 0.44
[Validation] Batch ID = 1820, loss = 0.30385, acc = 0.7
[Train] Batch ID = 1830, loss = 0.441479, acc = 0.34
[Validation] Batch ID = 1830, loss = 0.276286, acc = 0.74
[Train] Batch ID = 1840, loss = 0.410661, acc = 0.52
[Validation] Batch ID = 1840, loss = 0.355448, acc = 0.54
[Train] Batch ID = 1850, loss = 0.433524, acc = 0.44
[Validation] Batch ID = 1850, loss = 0.276556, acc = 0.76
[Train] Batch ID = 1860, loss = 0.262997, acc = 0.8
[Validation] Batch ID = 1860, loss = 0.280793, acc = 0.7
[Train] Batch ID = 1870, loss = 0.424091, acc = 0.46
[Validation] Batch ID = 1870, loss = 0.262786, acc = 0.74
[Train] Batch ID = 1880, loss = 0.35354, acc = 0.54
[Validation] Batch ID = 1880, loss = 0.305498, acc = 0.68
[Train] Batch ID = 1890, loss = 0.416785, acc = 0.48
[Validation] Batch ID = 1890, loss = 0.305132, acc = 0.56
[Train] Batch ID = 1900, loss = 0.431304, acc = 0.5
[Validation] Batch ID = 1900, loss = 0.290395, acc = 0.72
[Train] Batch ID = 1910, loss = 0.395793, acc = 0.54
[Validation] Batch ID = 1910, loss = 0.285612, acc = 0.84
[Train] Batch ID = 1920, loss = 0.466263, acc = 0.32
[Validation] Batch ID = 1920, loss = 0.313731, acc = 0.62
[Train] Batch ID = 1930, loss = 0.392385, acc = 0.48
[Validation] Batch ID = 1930, loss = 0.301737, acc = 0.68
[Train] Batch ID = 1940, loss = 0.424688, acc = 0.36
[Validation] Batch ID = 1940, loss = 0.281302, acc = 0.72
[Train] Batch ID = 1950, loss = 0.400775, acc = 0.52
[Validation] Batch ID = 1950, loss = 0.281192, acc = 0.7
[Train] Batch ID = 1960, loss = 0.226825, acc = 0.9
[Validation] Batch ID = 1960, loss = 0.262478, acc = 0.8
[Train] Batch ID = 1970, loss = 0.403778, acc = 0.52
[Validation] Batch ID = 1970, loss = 0.289501, acc = 0.74
[Train] Batch ID = 1980, loss = 0.407642, acc = 0.5
[Validation] Batch ID = 1980, loss = 0.288932, acc = 0.66
[Train] Batch ID = 1990, loss = 0.236559, acc = 0.78
[Validation] Batch ID = 1990, loss = 0.289652, acc = 0.66
[Train] Batch ID = 2000, loss = 0.402175, acc = 0.44
[Validation] Batch ID = 2000, loss = 0.292529, acc = 0.68
Evaluate full validation dataset ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Saving model ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Current loss: 0.287766 Best loss: 0.420879
[TOTAL Validation] Batch ID = 2000, loss = 0.287766, acc = 0.714285714286
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Model successfully saved here: outputs/checkpoints/c1s_9_c1n_256_c2s_6_c2n_64_c2d_0.7_c1vl_16_c1s_5_c1nf_16_c2vl_32_lr_0.0001_rs_1--TrafficSign--1510487290.423481
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Augmented Factor = 0.7217100000000001
[Train] Batch ID = 2010, loss = 0.424638, acc = 0.46
[Validation] Batch ID = 2010, loss = 0.315895, acc = 0.64
[Train] Batch ID = 2020, loss = 0.417981, acc = 0.5
[Validation] Batch ID = 2020, loss = 0.294751, acc = 0.64
[Train] Batch ID = 2030, loss = 0.391561, acc = 0.52
[Validation] Batch ID = 2030, loss = 0.266273, acc = 0.76
[Train] Batch ID = 2040, loss = 0.398861, acc = 0.48
[Validation] Batch ID = 2040, loss = 0.262126, acc = 0.66
[Train] Batch ID = 2050, loss = 0.437229, acc = 0.36
[Validation] Batch ID = 2050, loss = 0.225945, acc = 0.78
[Train] Batch ID = 2060, loss = 0.256552, acc = 0.74
[Validation] Batch ID = 2060, loss = 0.284124, acc = 0.7
[Train] Batch ID = 2070, loss = 0.449687, acc = 0.32
[Validation] Batch ID = 2070, loss = 0.299305, acc = 0.6
[Train] Batch ID = 2080, loss = 0.39845, acc = 0.52
[Validation] Batch ID = 2080, loss = 0.302878, acc = 0.66
[Train] Batch ID = 2090, loss = 0.43506, acc = 0.46
[Validation] Batch ID = 2090, loss = 0.291238, acc = 0.76
[Train] Batch ID = 2100, loss = 0.36886, acc = 0.54
[Validation] Batch ID = 2100, loss = 0.2914, acc = 0.66
[Train] Batch ID = 2110, loss = 0.360184, acc = 0.56
[Validation] Batch ID = 2110, loss = 0.267114, acc = 0.74
[Train] Batch ID = 2120, loss = 0.230002, acc = 0.74
[Validation] Batch ID = 2120, loss = 0.287399, acc = 0.76
[Train] Batch ID = 2130, loss = 0.421706, acc = 0.44
[Validation] Batch ID = 2130, loss = 0.32106, acc = 0.6
[Train] Batch ID = 2140, loss = 0.234205, acc = 0.78
[Validation] Batch ID = 2140, loss = 0.27168, acc = 0.72
[Train] Batch ID = 2150, loss = 0.407281, acc = 0.46
[Validation] Batch ID = 2150, loss = 0.23138, acc = 0.76
[Train] Batch ID = 2160, loss = 0.247937, acc = 0.82
[Validation] Batch ID = 2160, loss = 0.245743, acc = 0.78
[Train] Batch ID = 2170, loss = 0.410929, acc = 0.58
[Validation] Batch ID = 2170, loss = 0.302407, acc = 0.76
[Train] Batch ID = 2180, loss = 0.390121, acc = 0.5
[Validation] Batch ID = 2180, loss = 0.259604, acc = 0.78
[Train] Batch ID = 2190, loss = 0.455198, acc = 0.32
[Validation] Batch ID = 2190, loss = 0.253516, acc = 0.74
[Train] Batch ID = 2200, loss = 0.413657, acc = 0.5
[Validation] Batch ID = 2200, loss = 0.229672, acc = 0.88
[Train] Batch ID = 2210, loss = 0.447304, acc = 0.4
[Validation] Batch ID = 2210, loss = 0.228827, acc = 0.76
[Train] Batch ID = 2220, loss = 0.401778, acc = 0.46
[Validation] Batch ID = 2220, loss = 0.252305, acc = 0.68
[Train] Batch ID = 2230, loss = 0.397193, acc = 0.44
[Validation] Batch ID = 2230, loss = 0.216504, acc = 0.8
[Train] Batch ID = 2240, loss = 0.229553, acc = 0.8
[Validation] Batch ID = 2240, loss = 0.260911, acc = 0.82
[Train] Batch ID = 2250, loss = 0.385352, acc = 0.5
[Validation] Batch ID = 2250, loss = 0.258119, acc = 0.76
[Train] Batch ID = 2260, loss = 0.413041, acc = 0.38
[Validation] Batch ID = 2260, loss = 0.258962, acc = 0.76
[Train] Batch ID = 2270, loss = 0.442316, acc = 0.38
[Validation] Batch ID = 2270, loss = 0.231853, acc = 0.82
[Train] Batch ID = 2280, loss = 0.420389, acc = 0.46
[Validation] Batch ID = 2280, loss = 0.273525, acc = 0.78
[Train] Batch ID = 2290, loss = 0.431131, acc = 0.54
[Validation] Batch ID = 2290, loss = 0.267348, acc = 0.8
[Train] Batch ID = 2300, loss = 0.209498, acc = 0.86
[Validation] Batch ID = 2300, loss = 0.284436, acc = 0.64
[Train] Batch ID = 2310, loss = 0.38133, acc = 0.54
[Validation] Batch ID = 2310, loss = 0.266011, acc = 0.72
[Train] Batch ID = 2320, loss = 0.381111, acc = 0.54
[Validation] Batch ID = 2320, loss = 0.287741, acc = 0.68
[Train] Batch ID = 2330, loss = 0.193757, acc = 0.88
[Validation] Batch ID = 2330, loss = 0.252142, acc = 0.76
[Train] Batch ID = 2340, loss = 0.363587, acc = 0.54
[Validation] Batch ID = 2340, loss = 0.239207, acc = 0.76
[Train] Batch ID = 2350, loss = 0.408757, acc = 0.46
[Validation] Batch ID = 2350, loss = 0.260313, acc = 0.74
[Train] Batch ID = 2360, loss = 0.359984, acc = 0.6
[Validation] Batch ID = 2360, loss = 0.256528, acc = 0.76
[Train] Batch ID = 2370, loss = 0.403567, acc = 0.42
[Validation] Batch ID = 2370, loss = 0.229592, acc = 0.78
[Train] Batch ID = 2380, loss = 0.191505, acc = 0.88
[Validation] Batch ID = 2380, loss = 0.259362, acc = 0.72
[Train] Batch ID = 2390, loss = 0.215533, acc = 0.88
[Validation] Batch ID = 2390, loss = 0.278083, acc = 0.68
[Train] Batch ID = 2400, loss = 0.264087, acc = 0.78
[Validation] Batch ID = 2400, loss = 0.266879, acc = 0.68
[Train] Batch ID = 2410, loss = 0.383975, acc = 0.52
[Validation] Batch ID = 2410, loss = 0.23264, acc = 0.74
[Train] Batch ID = 2420, loss = 0.422329, acc = 0.38
[Validation] Batch ID = 2420, loss = 0.2484, acc = 0.78
[Train] Batch ID = 2430, loss = 0.374205, acc = 0.6
[Validation] Batch ID = 2430, loss = 0.204559, acc = 0.82
[Train] Batch ID = 2440, loss = 0.438642, acc = 0.4
[Validation] Batch ID = 2440, loss = 0.264294, acc = 0.8
[Train] Batch ID = 2450, loss = 0.375316, acc = 0.62
[Validation] Batch ID = 2450, loss = 0.239244, acc = 0.78
[Train] Batch ID = 2460, loss = 0.223293, acc = 0.84
[Validation] Batch ID = 2460, loss = 0.234116, acc = 0.8
[Train] Batch ID = 2470, loss = 0.188692, acc = 0.92
[Validation] Batch ID = 2470, loss = 0.285622, acc = 0.66
[Train] Batch ID = 2480, loss = 0.177206, acc = 0.82
[Validation] Batch ID = 2480, loss = 0.213275, acc = 0.84
[Train] Batch ID = 2490, loss = 0.39774, acc = 0.48
[Validation] Batch ID = 2490, loss = 0.244553, acc = 0.78
[Train] Batch ID = 2500, loss = 0.404168, acc = 0.5
[Validation] Batch ID = 2500, loss = 0.257854, acc = 0.64
[Train] Batch ID = 2510, loss = 0.406717, acc = 0.42
[Validation] Batch ID = 2510, loss = 0.213871, acc = 0.84
[Train] Batch ID = 2520, loss = 0.204979, acc = 0.82
[Validation] Batch ID = 2520, loss = 0.213771, acc = 0.82
[Train] Batch ID = 2530, loss = 0.393296, acc = 0.54
[Validation] Batch ID = 2530, loss = 0.222768, acc = 0.84
[Train] Batch ID = 2540, loss = 0.387103, acc = 0.42
[Validation] Batch ID = 2540, loss = 0.234062, acc = 0.76
[Train] Batch ID = 2550, loss = 0.201806, acc = 0.9
[Validation] Batch ID = 2550, loss = 0.272591, acc = 0.74
[Train] Batch ID = 2560, loss = 0.428081, acc = 0.48
[Validation] Batch ID = 2560, loss = 0.233086, acc = 0.76
[Train] Batch ID = 2570, loss = 0.402639, acc = 0.46
[Validation] Batch ID = 2570, loss = 0.200388, acc = 0.84
[Train] Batch ID = 2580, loss = 0.197115, acc = 0.84
[Validation] Batch ID = 2580, loss = 0.327447, acc = 0.8
[Train] Batch ID = 2590, loss = 0.41173, acc = 0.42
[Validation] Batch ID = 2590, loss = 0.225098, acc = 0.74
[Train] Batch ID = 2600, loss = 0.194261, acc = 0.88
[Validation] Batch ID = 2600, loss = 0.239055, acc = 0.82
[Train] Batch ID = 2610, loss = 0.399961, acc = 0.48
[Validation] Batch ID = 2610, loss = 0.248689, acc = 0.76
[Train] Batch ID = 2620, loss = 0.370846, acc = 0.5
[Validation] Batch ID = 2620, loss = 0.252983, acc = 0.82
[Train] Batch ID = 2630, loss = 0.353472, acc = 0.56
[Validation] Batch ID = 2630, loss = 0.284357, acc = 0.64
[Train] Batch ID = 2640, loss = 0.390562, acc = 0.48
[Validation] Batch ID = 2640, loss = 0.266341, acc = 0.8
[Train] Batch ID = 2650, loss = 0.405542, acc = 0.54
[Validation] Batch ID = 2650, loss = 0.221173, acc = 0.78
[Train] Batch ID = 2660, loss = 0.348745, acc = 0.58
[Validation] Batch ID = 2660, loss = 0.266088, acc = 0.76
[Train] Batch ID = 2670, loss = 0.377527, acc = 0.52
[Validation] Batch ID = 2670, loss = 0.236292, acc = 0.78
[Train] Batch ID = 2680, loss = 0.204437, acc = 0.98
[Validation] Batch ID = 2680, loss = 0.224975, acc = 0.84
[Train] Batch ID = 2690, loss = 0.334522, acc = 0.56
[Validation] Batch ID = 2690, loss = 0.243066, acc = 0.8
[Train] Batch ID = 2700, loss = 0.392206, acc = 0.54
[Validation] Batch ID = 2700, loss = 0.217563, acc = 0.82
[Train] Batch ID = 2710, loss = 0.348645, acc = 0.6
[Validation] Batch ID = 2710, loss = 0.236927, acc = 0.78
[Train] Batch ID = 2720, loss = 0.377078, acc = 0.54
[Validation] Batch ID = 2720, loss = 0.210027, acc = 0.82
[Train] Batch ID = 2730, loss = 0.345776, acc = 0.6
[Validation] Batch ID = 2730, loss = 0.255834, acc = 0.78
[Train] Batch ID = 2740, loss = 0.178067, acc = 0.86
[Validation] Batch ID = 2740, loss = 0.221936, acc = 0.78
[Train] Batch ID = 2750, loss = 0.192231, acc = 0.9
[Validation] Batch ID = 2750, loss = 0.218081, acc = 0.8
[Train] Batch ID = 2760, loss = 0.424044, acc = 0.48
[Validation] Batch ID = 2760, loss = 0.210341, acc = 0.86
[Train] Batch ID = 2770, loss = 0.418441, acc = 0.36
[Validation] Batch ID = 2770, loss = 0.221309, acc = 0.84
[Train] Batch ID = 2780, loss = 0.167826, acc = 0.92
[Validation] Batch ID = 2780, loss = 0.224829, acc = 0.76
[Train] Batch ID = 2790, loss = 0.404088, acc = 0.52
[Validation] Batch ID = 2790, loss = 0.299466, acc = 0.72
[Train] Batch ID = 2800, loss = 0.171814, acc = 0.94
[Validation] Batch ID = 2800, loss = 0.237057, acc = 0.78
[Train] Batch ID = 2810, loss = 0.385781, acc = 0.46
[Validation] Batch ID = 2810, loss = 0.185864, acc = 0.84
[Train] Batch ID = 2820, loss = 0.366355, acc = 0.52
[Validation] Batch ID = 2820, loss = 0.233345, acc = 0.76
[Train] Batch ID = 2830, loss = 0.365549, acc = 0.6
[Validation] Batch ID = 2830, loss = 0.213654, acc = 0.82
[Train] Batch ID = 2840, loss = 0.341989, acc = 0.58
[Validation] Batch ID = 2840, loss = 0.223267, acc = 0.72
[Train] Batch ID = 2850, loss = 0.385229, acc = 0.52
[Validation] Batch ID = 2850, loss = 0.241343, acc = 0.74
[Train] Batch ID = 2860, loss = 0.41385, acc = 0.48
[Validation] Batch ID = 2860, loss = 0.220821, acc = 0.84
[Train] Batch ID = 2870, loss = 0.378469, acc = 0.58
[Validation] Batch ID = 2870, loss = 0.207036, acc = 0.88
[Train] Batch ID = 2880, loss = 0.313315, acc = 0.66
[Validation] Batch ID = 2880, loss = 0.232811, acc = 0.78
[Train] Batch ID = 2890, loss = 0.394595, acc = 0.54
[Validation] Batch ID = 2890, loss = 0.245848, acc = 0.7
[Train] Batch ID = 2900, loss = 0.36514, acc = 0.56
[Validation] Batch ID = 2900, loss = 0.218638, acc = 0.88
[Train] Batch ID = 2910, loss = 0.401657, acc = 0.46
[Validation] Batch ID = 2910, loss = 0.22682, acc = 0.82
[Train] Batch ID = 2920, loss = 0.383167, acc = 0.52
[Validation] Batch ID = 2920, loss = 0.246558, acc = 0.78
[Train] Batch ID = 2930, loss = 0.41228, acc = 0.42
[Validation] Batch ID = 2930, loss = 0.207516, acc = 0.86
[Train] Batch ID = 2940, loss = 0.162175, acc = 0.9
[Validation] Batch ID = 2940, loss = 0.238631, acc = 0.76
[Train] Batch ID = 2950, loss = 0.351987, acc = 0.52
[Validation] Batch ID = 2950, loss = 0.229763, acc = 0.78
[Train] Batch ID = 2960, loss = 0.379678, acc = 0.5
[Validation] Batch ID = 2960, loss = 0.24098, acc = 0.72
[Train] Batch ID = 2970, loss = 0.187697, acc = 0.88
[Validation] Batch ID = 2970, loss = 0.250802, acc = 0.76
[Train] Batch ID = 2980, loss = 0.396072, acc = 0.42
[Validation] Batch ID = 2980, loss = 0.196173, acc = 0.84
[Train] Batch ID = 2990, loss = 0.40528, acc = 0.5
[Validation] Batch ID = 2990, loss = 0.214772, acc = 0.9
[Train] Batch ID = 3000, loss = 0.384336, acc = 0.56
[Validation] Batch ID = 3000, loss = 0.261725, acc = 0.66
Evaluate full validation dataset ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Saving model ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Current loss: 0.21994 Best loss: 0.287766
[TOTAL Validation] Batch ID = 3000, loss = 0.21994, acc = 0.790249433107
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Model successfully saved here: outputs/checkpoints/c1s_9_c1n_256_c2s_6_c2n_64_c2d_0.7_c1vl_16_c1s_5_c1nf_16_c2vl_32_lr_0.0001_rs_1--TrafficSign--1510487290.423481
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Augmented Factor = 0.6495390000000001
[Train] Batch ID = 3010, loss = 0.445161, acc = 0.34
[Validation] Batch ID = 3010, loss = 0.21014, acc = 0.86
[Train] Batch ID = 3020, loss = 0.164797, acc = 0.92
[Validation] Batch ID = 3020, loss = 0.181296, acc = 0.84
[Train] Batch ID = 3030, loss = 0.198305, acc = 0.8
[Validation] Batch ID = 3030, loss = 0.256097, acc = 0.72
[Train] Batch ID = 3040, loss = 0.164917, acc = 0.94
[Validation] Batch ID = 3040, loss = 0.192148, acc = 0.84
[Train] Batch ID = 3050, loss = 0.343142, acc = 0.6
[Validation] Batch ID = 3050, loss = 0.181722, acc = 0.8
[Train] Batch ID = 3060, loss = 0.400218, acc = 0.46
[Validation] Batch ID = 3060, loss = 0.187976, acc = 0.8
[Train] Batch ID = 3070, loss = 0.145437, acc = 0.92
[Validation] Batch ID = 3070, loss = 0.197524, acc = 0.9
[Train] Batch ID = 3080, loss = 0.372067, acc = 0.56
[Validation] Batch ID = 3080, loss = 0.16884, acc = 0.9
[Train] Batch ID = 3090, loss = 0.159641, acc = 0.92
[Validation] Batch ID = 3090, loss = 0.222574, acc = 0.8
[Train] Batch ID = 3100, loss = 0.358212, acc = 0.62
[Validation] Batch ID = 3100, loss = 0.192208, acc = 0.9
[Train] Batch ID = 3110, loss = 0.347611, acc = 0.58
[Validation] Batch ID = 3110, loss = 0.220475, acc = 0.76
[Train] Batch ID = 3120, loss = 0.178815, acc = 0.86
[Validation] Batch ID = 3120, loss = 0.20312, acc = 0.74
[Train] Batch ID = 3130, loss = 0.170885, acc = 0.92
[Validation] Batch ID = 3130, loss = 0.15722, acc = 0.92
[Train] Batch ID = 3140, loss = 0.175007, acc = 0.92
[Validation] Batch ID = 3140, loss = 0.197012, acc = 0.86
[Train] Batch ID = 3150, loss = 0.155249, acc = 0.92
[Validation] Batch ID = 3150, loss = 0.20313, acc = 0.82
[Train] Batch ID = 3160, loss = 0.35287, acc = 0.6
[Validation] Batch ID = 3160, loss = 0.19416, acc = 0.88
[Train] Batch ID = 3170, loss = 0.153096, acc = 0.96
[Validation] Batch ID = 3170, loss = 0.200089, acc = 0.86
[Train] Batch ID = 3180, loss = 0.330091, acc = 0.66
[Validation] Batch ID = 3180, loss = 0.193321, acc = 0.88
[Train] Batch ID = 3190, loss = 0.386201, acc = 0.54
[Validation] Batch ID = 3190, loss = 0.201889, acc = 0.84
[Train] Batch ID = 3200, loss = 0.34666, acc = 0.58
[Validation] Batch ID = 3200, loss = 0.189414, acc = 0.84
[Train] Batch ID = 3210, loss = 0.17919, acc = 0.88
[Validation] Batch ID = 3210, loss = 0.172466, acc = 0.88
[Train] Batch ID = 3220, loss = 0.37063, acc = 0.54
[Validation] Batch ID = 3220, loss = 0.181054, acc = 0.92
[Train] Batch ID = 3230, loss = 0.353636, acc = 0.52
[Validation] Batch ID = 3230, loss = 0.170902, acc = 0.88
[Train] Batch ID = 3240, loss = 0.391059, acc = 0.44
[Validation] Batch ID = 3240, loss = 0.172318, acc = 0.88
[Train] Batch ID = 3250, loss = 0.312763, acc = 0.72
[Validation] Batch ID = 3250, loss = 0.214634, acc = 0.82
[Train] Batch ID = 3260, loss = 0.343761, acc = 0.6
[Validation] Batch ID = 3260, loss = 0.192077, acc = 0.82
[Train] Batch ID = 3270, loss = 0.127589, acc = 0.98
[Validation] Batch ID = 3270, loss = 0.213788, acc = 0.84
[Train] Batch ID = 3280, loss = 0.13216, acc = 1.0
[Validation] Batch ID = 3280, loss = 0.180105, acc = 0.84
[Train] Batch ID = 3290, loss = 0.341555, acc = 0.64
[Validation] Batch ID = 3290, loss = 0.202181, acc = 0.8
[Train] Batch ID = 3300, loss = 0.379554, acc = 0.6
[Validation] Batch ID = 3300, loss = 0.185371, acc = 0.92
[Train] Batch ID = 3310, loss = 0.13695, acc = 0.92
[Validation] Batch ID = 3310, loss = 0.156135, acc = 0.88
[Train] Batch ID = 3320, loss = 0.373571, acc = 0.54
[Validation] Batch ID = 3320, loss = 0.22387, acc = 0.76
[Train] Batch ID = 3330, loss = 0.153527, acc = 0.9
[Validation] Batch ID = 3330, loss = 0.180107, acc = 0.88
[Train] Batch ID = 3340, loss = 0.381981, acc = 0.48
[Validation] Batch ID = 3340, loss = 0.204016, acc = 0.74
[Train] Batch ID = 3350, loss = 0.346182, acc = 0.56
[Validation] Batch ID = 3350, loss = 0.215601, acc = 0.8
[Train] Batch ID = 3360, loss = 0.152886, acc = 0.9
[Validation] Batch ID = 3360, loss = 0.154653, acc = 0.92
[Train] Batch ID = 3370, loss = 0.388474, acc = 0.6
[Validation] Batch ID = 3370, loss = 0.16135, acc = 0.84
[Train] Batch ID = 3380, loss = 0.364568, acc = 0.6
[Validation] Batch ID = 3380, loss = 0.205586, acc = 0.82
[Train] Batch ID = 3390, loss = 0.356776, acc = 0.52
[Validation] Batch ID = 3390, loss = 0.209366, acc = 0.8
[Train] Batch ID = 3400, loss = 0.13818, acc = 0.96
[Validation] Batch ID = 3400, loss = 0.174891, acc = 0.92
[Train] Batch ID = 3410, loss = 0.385156, acc = 0.46
[Validation] Batch ID = 3410, loss = 0.158915, acc = 0.94
[Train] Batch ID = 3420, loss = 0.100106, acc = 1.0
[Validation] Batch ID = 3420, loss = 0.183602, acc = 0.8
[Train] Batch ID = 3430, loss = 0.39617, acc = 0.46
[Validation] Batch ID = 3430, loss = 0.195676, acc = 0.84
[Train] Batch ID = 3440, loss = 0.363371, acc = 0.58
[Validation] Batch ID = 3440, loss = 0.148295, acc = 0.84
[Train] Batch ID = 3450, loss = 0.355273, acc = 0.58
[Validation] Batch ID = 3450, loss = 0.21295, acc = 0.88
[Train] Batch ID = 3460, loss = 0.379746, acc = 0.48
[Validation] Batch ID = 3460, loss = 0.180013, acc = 0.84
[Train] Batch ID = 3470, loss = 0.335323, acc = 0.6
[Validation] Batch ID = 3470, loss = 0.114517, acc = 0.9
[Train] Batch ID = 3480, loss = 0.325833, acc = 0.68
[Validation] Batch ID = 3480, loss = 0.169348, acc = 0.84
[Train] Batch ID = 3490, loss = 0.136607, acc = 0.9
[Validation] Batch ID = 3490, loss = 0.190627, acc = 0.86
[Train] Batch ID = 3500, loss = 0.368675, acc = 0.5
[Validation] Batch ID = 3500, loss = 0.175382, acc = 0.84
[Train] Batch ID = 3510, loss = 0.145697, acc = 0.92
[Validation] Batch ID = 3510, loss = 0.193606, acc = 0.84
[Train] Batch ID = 3520, loss = 0.364332, acc = 0.5
[Validation] Batch ID = 3520, loss = 0.149738, acc = 0.92
[Train] Batch ID = 3530, loss = 0.350502, acc = 0.6
[Validation] Batch ID = 3530, loss = 0.179333, acc = 0.82
[Train] Batch ID = 3540, loss = 0.131797, acc = 0.94
[Validation] Batch ID = 3540, loss = 0.180903, acc = 0.94
[Train] Batch ID = 3550, loss = 0.395838, acc = 0.48
[Validation] Batch ID = 3550, loss = 0.14815, acc = 0.88
[Train] Batch ID = 3560, loss = 0.320512, acc = 0.64
[Validation] Batch ID = 3560, loss = 0.14834, acc = 0.94
[Train] Batch ID = 3570, loss = 0.159056, acc = 0.94
[Validation] Batch ID = 3570, loss = 0.181972, acc = 0.84
[Train] Batch ID = 3580, loss = 0.128954, acc = 0.94
[Validation] Batch ID = 3580, loss = 0.190294, acc = 0.82
[Train] Batch ID = 3590, loss = 0.33268, acc = 0.68
[Validation] Batch ID = 3590, loss = 0.160293, acc = 0.8
[Train] Batch ID = 3600, loss = 0.382119, acc = 0.5
[Validation] Batch ID = 3600, loss = 0.204905, acc = 0.78
[Train] Batch ID = 3610, loss = 0.133848, acc = 0.96
[Validation] Batch ID = 3610, loss = 0.175962, acc = 0.94
[Train] Batch ID = 3620, loss = 0.125686, acc = 0.94
[Validation] Batch ID = 3620, loss = 0.214269, acc = 0.8
[Train] Batch ID = 3630, loss = 0.115695, acc = 0.96
[Validation] Batch ID = 3630, loss = 0.213975, acc = 0.8
[Train] Batch ID = 3640, loss = 0.126236, acc = 0.92
[Validation] Batch ID = 3640, loss = 0.192529, acc = 0.8
[Train] Batch ID = 3650, loss = 0.388462, acc = 0.52
[Validation] Batch ID = 3650, loss = 0.165436, acc = 0.82
[Train] Batch ID = 3660, loss = 0.359403, acc = 0.56
[Validation] Batch ID = 3660, loss = 0.192993, acc = 0.8
[Train] Batch ID = 3670, loss = 0.320491, acc = 0.6
[Validation] Batch ID = 3670, loss = 0.152648, acc = 0.88
[Train] Batch ID = 3680, loss = 0.342737, acc = 0.6
[Validation] Batch ID = 3680, loss = 0.213149, acc = 0.78
[Train] Batch ID = 3690, loss = 0.342219, acc = 0.7
[Validation] Batch ID = 3690, loss = 0.181833, acc = 0.84
[Train] Batch ID = 3700, loss = 0.380888, acc = 0.44
[Validation] Batch ID = 3700, loss = 0.182251, acc = 0.84
[Train] Batch ID = 3710, loss = 0.121941, acc = 0.96
[Validation] Batch ID = 3710, loss = 0.179244, acc = 0.86
[Train] Batch ID = 3720, loss = 0.364062, acc = 0.5
[Validation] Batch ID = 3720, loss = 0.217208, acc = 0.78
[Train] Batch ID = 3730, loss = 0.367069, acc = 0.62
[Validation] Batch ID = 3730, loss = 0.154614, acc = 0.9
[Train] Batch ID = 3740, loss = 0.129264, acc = 0.96
[Validation] Batch ID = 3740, loss = 0.180565, acc = 0.88
[Train] Batch ID = 3750, loss = 0.152761, acc = 0.92
[Validation] Batch ID = 3750, loss = 0.184382, acc = 0.84
[Train] Batch ID = 3760, loss = 0.348866, acc = 0.58
[Validation] Batch ID = 3760, loss = 0.185455, acc = 0.8
[Train] Batch ID = 3770, loss = 0.32255, acc = 0.64
[Validation] Batch ID = 3770, loss = 0.185539, acc = 0.82
[Train] Batch ID = 3780, loss = 0.356236, acc = 0.56
[Validation] Batch ID = 3780, loss = 0.198148, acc = 0.88
[Train] Batch ID = 3790, loss = 0.377577, acc = 0.54
[Validation] Batch ID = 3790, loss = 0.210579, acc = 0.84
[Train] Batch ID = 3800, loss = 0.351091, acc = 0.52
[Validation] Batch ID = 3800, loss = 0.200057, acc = 0.84
[Train] Batch ID = 3810, loss = 0.340158, acc = 0.58
[Validation] Batch ID = 3810, loss = 0.177234, acc = 0.84
[Train] Batch ID = 3820, loss = 0.116837, acc = 0.98
[Validation] Batch ID = 3820, loss = 0.148749, acc = 0.9
[Train] Batch ID = 3830, loss = 0.113573, acc = 1.0
[Validation] Batch ID = 3830, loss = 0.17946, acc = 0.9
[Train] Batch ID = 3840, loss = 0.358943, acc = 0.58
[Validation] Batch ID = 3840, loss = 0.165624, acc = 0.82
[Train] Batch ID = 3850, loss = 0.336287, acc = 0.6
[Validation] Batch ID = 3850, loss = 0.1866, acc = 0.8
[Train] Batch ID = 3860, loss = 0.38031, acc = 0.48
[Validation] Batch ID = 3860, loss = 0.153643, acc = 0.9
[Train] Batch ID = 3870, loss = 0.377857, acc = 0.52
[Validation] Batch ID = 3870, loss = 0.177445, acc = 0.84
[Train] Batch ID = 3880, loss = 0.101431, acc = 0.96
[Validation] Batch ID = 3880, loss = 0.1583, acc = 0.9
[Train] Batch ID = 3890, loss = 0.130648, acc = 0.96
[Validation] Batch ID = 3890, loss = 0.171675, acc = 0.88
[Train] Batch ID = 3900, loss = 0.37803, acc = 0.58
[Validation] Batch ID = 3900, loss = 0.156381, acc = 0.86
[Train] Batch ID = 3910, loss = 0.092333, acc = 0.98
[Validation] Batch ID = 3910, loss = 0.194253, acc = 0.82
[Train] Batch ID = 3920, loss = 0.116671, acc = 0.96
[Validation] Batch ID = 3920, loss = 0.16635, acc = 0.94
[Train] Batch ID = 3930, loss = 0.34316, acc = 0.56
[Validation] Batch ID = 3930, loss = 0.177922, acc = 0.86
[Train] Batch ID = 3940, loss = 0.123078, acc = 0.94
[Validation] Batch ID = 3940, loss = 0.131239, acc = 0.92
[Train] Batch ID = 3950, loss = 0.342191, acc = 0.6
[Validation] Batch ID = 3950, loss = 0.177488, acc = 0.9
[Train] Batch ID = 3960, loss = 0.335259, acc = 0.64
[Validation] Batch ID = 3960, loss = 0.136452, acc = 0.96
[Train] Batch ID = 3970, loss = 0.135189, acc = 0.94
[Validation] Batch ID = 3970, loss = 0.139566, acc = 0.9
[Train] Batch ID = 3980, loss = 0.0979463, acc = 0.96
[Validation] Batch ID = 3980, loss = 0.150806, acc = 0.88
[Train] Batch ID = 3990, loss = 0.376017, acc = 0.5
[Validation] Batch ID = 3990, loss = 0.168038, acc = 0.86
[Train] Batch ID = 4000, loss = 0.111328, acc = 0.98
[Validation] Batch ID = 4000, loss = 0.144933, acc = 0.9
Evaluate full validation dataset ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Saving model ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Current loss: 0.168757 Best loss: 0.21994
[TOTAL Validation] Batch ID = 4000, loss = 0.168757, acc = 0.870975056689
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Model successfully saved here: outputs/checkpoints/c1s_9_c1n_256_c2s_6_c2n_64_c2d_0.7_c1vl_16_c1s_5_c1nf_16_c2vl_32_lr_0.0001_rs_1--TrafficSign--1510487290.423481
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Augmented Factor = 0.5845851000000001
[Train] Batch ID = 4010, loss = 0.12251, acc = 0.92
[Validation] Batch ID = 4010, loss = 0.16558, acc = 0.84
[Train] Batch ID = 4020, loss = 0.112086, acc = 0.92
[Validation] Batch ID = 4020, loss = 0.15856, acc = 0.88
[Train] Batch ID = 4030, loss = 0.313121, acc = 0.68
[Validation] Batch ID = 4030, loss = 0.15399, acc = 0.9
[Train] Batch ID = 4040, loss = 0.367862, acc = 0.54
[Validation] Batch ID = 4040, loss = 0.145397, acc = 0.86
[Train] Batch ID = 4050, loss = 0.271752, acc = 0.74
[Validation] Batch ID = 4050, loss = 0.141684, acc = 0.9
[Train] Batch ID = 4060, loss = 0.333086, acc = 0.58
[Validation] Batch ID = 4060, loss = 0.174225, acc = 0.86
[Train] Batch ID = 4070, loss = 0.107873, acc = 0.96
[Validation] Batch ID = 4070, loss = 0.165873, acc = 0.82
[Train] Batch ID = 4080, loss = 0.100479, acc = 0.98
[Validation] Batch ID = 4080, loss = 0.148699, acc = 0.88
[Train] Batch ID = 4090, loss = 0.123076, acc = 0.9
[Validation] Batch ID = 4090, loss = 0.166938, acc = 0.88
[Train] Batch ID = 4100, loss = 0.105591, acc = 0.98
[Validation] Batch ID = 4100, loss = 0.15512, acc = 0.92
[Train] Batch ID = 4110, loss = 0.109869, acc = 0.96
[Validation] Batch ID = 4110, loss = 0.168539, acc = 0.88
[Train] Batch ID = 4120, loss = 0.288437, acc = 0.7
[Validation] Batch ID = 4120, loss = 0.148167, acc = 0.9
[Train] Batch ID = 4130, loss = 0.0879073, acc = 0.98
[Validation] Batch ID = 4130, loss = 0.180345, acc = 0.82
[Train] Batch ID = 4140, loss = 0.38728, acc = 0.52
[Validation] Batch ID = 4140, loss = 0.116299, acc = 0.98
[Train] Batch ID = 4150, loss = 0.101743, acc = 1.0
[Validation] Batch ID = 4150, loss = 0.168443, acc = 0.86
[Train] Batch ID = 4160, loss = 0.325794, acc = 0.62
[Validation] Batch ID = 4160, loss = 0.151297, acc = 0.96
[Train] Batch ID = 4170, loss = 0.138752, acc = 0.94
[Validation] Batch ID = 4170, loss = 0.162053, acc = 0.86
[Train] Batch ID = 4180, loss = 0.106906, acc = 0.94
[Validation] Batch ID = 4180, loss = 0.137521, acc = 0.94
[Train] Batch ID = 4190, loss = 0.125377, acc = 0.96
[Validation] Batch ID = 4190, loss = 0.142781, acc = 0.9
[Train] Batch ID = 4200, loss = 0.35877, acc = 0.52
[Validation] Batch ID = 4200, loss = 0.115913, acc = 0.9
[Train] Batch ID = 4210, loss = 0.10824, acc = 0.98
[Validation] Batch ID = 4210, loss = 0.130416, acc = 0.96
[Train] Batch ID = 4220, loss = 0.120083, acc = 0.94
[Validation] Batch ID = 4220, loss = 0.173238, acc = 0.82
[Train] Batch ID = 4230, loss = 0.0997008, acc = 0.98
[Validation] Batch ID = 4230, loss = 0.141225, acc = 0.88
[Train] Batch ID = 4240, loss = 0.105464, acc = 0.98
[Validation] Batch ID = 4240, loss = 0.15865, acc = 0.86
[Train] Batch ID = 4250, loss = 0.117515, acc = 0.94
[Validation] Batch ID = 4250, loss = 0.129476, acc = 0.94
[Train] Batch ID = 4260, loss = 0.293512, acc = 0.68
[Validation] Batch ID = 4260, loss = 0.120032, acc = 0.86
[Train] Batch ID = 4270, loss = 0.132608, acc = 0.92
[Validation] Batch ID = 4270, loss = 0.198343, acc = 0.82
[Train] Batch ID = 4280, loss = 0.355035, acc = 0.52
[Validation] Batch ID = 4280, loss = 0.150256, acc = 0.9
[Train] Batch ID = 4290, loss = 0.0856165, acc = 0.98
[Validation] Batch ID = 4290, loss = 0.125858, acc = 0.88
[Train] Batch ID = 4300, loss = 0.326571, acc = 0.62
[Validation] Batch ID = 4300, loss = 0.183298, acc = 0.8
[Train] Batch ID = 4310, loss = 0.087663, acc = 1.0
[Validation] Batch ID = 4310, loss = 0.141948, acc = 0.94
[Train] Batch ID = 4320, loss = 0.311787, acc = 0.66
[Validation] Batch ID = 4320, loss = 0.147342, acc = 0.88
[Train] Batch ID = 4330, loss = 0.350933, acc = 0.54
[Validation] Batch ID = 4330, loss = 0.166106, acc = 0.88
[Train] Batch ID = 4340, loss = 0.29115, acc = 0.7
[Validation] Batch ID = 4340, loss = 0.132236, acc = 0.88
[Train] Batch ID = 4350, loss = 0.096425, acc = 0.96
[Validation] Batch ID = 4350, loss = 0.156412, acc = 0.86
[Train] Batch ID = 4360, loss = 0.358088, acc = 0.64
[Validation] Batch ID = 4360, loss = 0.0942102, acc = 1.0
[Train] Batch ID = 4370, loss = 0.09986, acc = 0.98
[Validation] Batch ID = 4370, loss = 0.156277, acc = 0.94
[Train] Batch ID = 4380, loss = 0.314932, acc = 0.7
[Validation] Batch ID = 4380, loss = 0.158205, acc = 0.88
[Train] Batch ID = 4390, loss = 0.318108, acc = 0.7
[Validation] Batch ID = 4390, loss = 0.140715, acc = 0.94
[Train] Batch ID = 4400, loss = 0.154926, acc = 0.94
[Validation] Batch ID = 4400, loss = 0.149455, acc = 0.88
[Train] Batch ID = 4410, loss = 0.299541, acc = 0.64
[Validation] Batch ID = 4410, loss = 0.166591, acc = 0.9
[Train] Batch ID = 4420, loss = 0.323751, acc = 0.6
[Validation] Batch ID = 4420, loss = 0.14958, acc = 0.92
[Train] Batch ID = 4430, loss = 0.310917, acc = 0.64
[Validation] Batch ID = 4430, loss = 0.152547, acc = 0.9
[Train] Batch ID = 4440, loss = 0.332348, acc = 0.54
[Validation] Batch ID = 4440, loss = 0.161528, acc = 0.86
[Train] Batch ID = 4450, loss = 0.0944807, acc = 0.96
[Validation] Batch ID = 4450, loss = 0.150604, acc = 0.94
[Train] Batch ID = 4460, loss = 0.368933, acc = 0.56
[Validation] Batch ID = 4460, loss = 0.131017, acc = 0.92
[Train] Batch ID = 4470, loss = 0.342016, acc = 0.6
[Validation] Batch ID = 4470, loss = 0.147478, acc = 0.88
[Train] Batch ID = 4480, loss = 0.320409, acc = 0.6
[Validation] Batch ID = 4480, loss = 0.134133, acc = 0.96
[Train] Batch ID = 4490, loss = 0.304917, acc = 0.7
[Validation] Batch ID = 4490, loss = 0.142356, acc = 0.9
[Train] Batch ID = 4500, loss = 0.109634, acc = 0.92
[Validation] Batch ID = 4500, loss = 0.12882, acc = 0.94
[Train] Batch ID = 4510, loss = 0.0996826, acc = 1.0
[Validation] Batch ID = 4510, loss = 0.129809, acc = 0.88
[Train] Batch ID = 4520, loss = 0.121544, acc = 0.94
[Validation] Batch ID = 4520, loss = 0.130525, acc = 0.94
[Train] Batch ID = 4530, loss = 0.360275, acc = 0.56
[Validation] Batch ID = 4530, loss = 0.141703, acc = 0.88
[Train] Batch ID = 4540, loss = 0.0986371, acc = 1.0
[Validation] Batch ID = 4540, loss = 0.12708, acc = 0.86
[Train] Batch ID = 4550, loss = 0.341225, acc = 0.56
[Validation] Batch ID = 4550, loss = 0.145131, acc = 0.94
[Train] Batch ID = 4560, loss = 0.327365, acc = 0.62
[Validation] Batch ID = 4560, loss = 0.112628, acc = 0.98
[Train] Batch ID = 4570, loss = 0.34423, acc = 0.62
[Validation] Batch ID = 4570, loss = 0.149863, acc = 0.9
[Train] Batch ID = 4580, loss = 0.36482, acc = 0.54
[Validation] Batch ID = 4580, loss = 0.155882, acc = 0.9
[Train] Batch ID = 4590, loss = 0.302437, acc = 0.66
[Validation] Batch ID = 4590, loss = 0.158615, acc = 0.84
[Train] Batch ID = 4600, loss = 0.363364, acc = 0.52
[Validation] Batch ID = 4600, loss = 0.140821, acc = 0.94
[Train] Batch ID = 4610, loss = 0.295002, acc = 0.74
[Validation] Batch ID = 4610, loss = 0.137501, acc = 0.92
[Train] Batch ID = 4620, loss = 0.101326, acc = 0.98
[Validation] Batch ID = 4620, loss = 0.094082, acc = 0.98
[Train] Batch ID = 4630, loss = 0.109986, acc = 0.98
[Validation] Batch ID = 4630, loss = 0.13181, acc = 0.88
[Train] Batch ID = 4640, loss = 0.319446, acc = 0.6
[Validation] Batch ID = 4640, loss = 0.153565, acc = 0.86
[Train] Batch ID = 4650, loss = 0.352978, acc = 0.6
[Validation] Batch ID = 4650, loss = 0.103432, acc = 0.94
[Train] Batch ID = 4660, loss = 0.323683, acc = 0.6
[Validation] Batch ID = 4660, loss = 0.152495, acc = 0.88
[Train] Batch ID = 4670, loss = 0.333538, acc = 0.56
[Validation] Batch ID = 4670, loss = 0.154009, acc = 0.86
[Train] Batch ID = 4680, loss = 0.345816, acc = 0.58
[Validation] Batch ID = 4680, loss = 0.132218, acc = 0.92
[Train] Batch ID = 4690, loss = 0.110378, acc = 0.94
[Validation] Batch ID = 4690, loss = 0.151243, acc = 0.88
[Train] Batch ID = 4700, loss = 0.337282, acc = 0.64
[Validation] Batch ID = 4700, loss = 0.160812, acc = 0.88
[Train] Batch ID = 4710, loss = 0.0941806, acc = 1.0
[Validation] Batch ID = 4710, loss = 0.122832, acc = 0.94
[Train] Batch ID = 4720, loss = 0.326719, acc = 0.6
[Validation] Batch ID = 4720, loss = 0.126283, acc = 0.94
[Train] Batch ID = 4730, loss = 0.0949816, acc = 0.98
[Validation] Batch ID = 4730, loss = 0.120558, acc = 0.94
[Train] Batch ID = 4740, loss = 0.0823444, acc = 0.98
[Validation] Batch ID = 4740, loss = 0.140595, acc = 0.82
[Train] Batch ID = 4750, loss = 0.338575, acc = 0.6
[Validation] Batch ID = 4750, loss = 0.129274, acc = 0.96
[Train] Batch ID = 4760, loss = 0.315897, acc = 0.58
[Validation] Batch ID = 4760, loss = 0.160935, acc = 0.88
[Train] Batch ID = 4770, loss = 0.318363, acc = 0.66
[Validation] Batch ID = 4770, loss = 0.153057, acc = 0.92
[Train] Batch ID = 4780, loss = 0.304167, acc = 0.7
[Validation] Batch ID = 4780, loss = 0.145133, acc = 0.9
[Train] Batch ID = 4790, loss = 0.339441, acc = 0.58
[Validation] Batch ID = 4790, loss = 0.144579, acc = 0.9
[Train] Batch ID = 4800, loss = 0.1131, acc = 0.98
[Validation] Batch ID = 4800, loss = 0.142645, acc = 0.88
[Train] Batch ID = 4810, loss = 0.0844815, acc = 1.0
[Validation] Batch ID = 4810, loss = 0.139451, acc = 0.92
[Train] Batch ID = 4820, loss = 0.106848, acc = 0.96
[Validation] Batch ID = 4820, loss = 0.191776, acc = 0.78
[Train] Batch ID = 4830, loss = 0.0896359, acc = 1.0
[Validation] Batch ID = 4830, loss = 0.131579, acc = 0.96
[Train] Batch ID = 4840, loss = 0.317988, acc = 0.64
[Validation] Batch ID = 4840, loss = 0.116118, acc = 0.94
[Train] Batch ID = 4850, loss = 0.27816, acc = 0.72
[Validation] Batch ID = 4850, loss = 0.11659, acc = 0.98
[Train] Batch ID = 4860, loss = 0.329745, acc = 0.6
[Validation] Batch ID = 4860, loss = 0.155557, acc = 0.88
[Train] Batch ID = 4870, loss = 0.317925, acc = 0.58
[Validation] Batch ID = 4870, loss = 0.105741, acc = 0.98
[Train] Batch ID = 4880, loss = 0.307696, acc = 0.72
[Validation] Batch ID = 4880, loss = 0.12623, acc = 0.96
[Train] Batch ID = 4890, loss = 0.319589, acc = 0.6
[Validation] Batch ID = 4890, loss = 0.129447, acc = 0.94
[Train] Batch ID = 4900, loss = 0.103417, acc = 0.96
[Validation] Batch ID = 4900, loss = 0.158337, acc = 0.86
[Train] Batch ID = 4910, loss = 0.118155, acc = 0.96
[Validation] Batch ID = 4910, loss = 0.13251, acc = 0.92
[Train] Batch ID = 4920, loss = 0.0829715, acc = 0.96
[Validation] Batch ID = 4920, loss = 0.160648, acc = 0.84
[Train] Batch ID = 4930, loss = 0.369658, acc = 0.46
[Validation] Batch ID = 4930, loss = 0.141349, acc = 0.88
[Train] Batch ID = 4940, loss = 0.0951467, acc = 0.98
[Validation] Batch ID = 4940, loss = 0.172178, acc = 0.9
[Train] Batch ID = 4950, loss = 0.291958, acc = 0.7
[Validation] Batch ID = 4950, loss = 0.113408, acc = 0.98
[Train] Batch ID = 4960, loss = 0.0743741, acc = 0.98
[Validation] Batch ID = 4960, loss = 0.154108, acc = 0.92
[Train] Batch ID = 4970, loss = 0.327996, acc = 0.64
[Validation] Batch ID = 4970, loss = 0.121926, acc = 0.9
[Train] Batch ID = 4980, loss = 0.088781, acc = 1.0
[Validation] Batch ID = 4980, loss = 0.0940469, acc = 0.96
[Train] Batch ID = 4990, loss = 0.296505, acc = 0.68
[Validation] Batch ID = 4990, loss = 0.132791, acc = 0.9
[Train] Batch ID = 5000, loss = 0.0781333, acc = 0.98
[Validation] Batch ID = 5000, loss = 0.0992442, acc = 0.98
Evaluate full validation dataset ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Saving model ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Current loss: 0.129008 Best loss: 0.168757
[TOTAL Validation] Batch ID = 5000, loss = 0.129008, acc = 0.910657596372
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Model successfully saved here: outputs/checkpoints/c1s_9_c1n_256_c2s_6_c2n_64_c2d_0.7_c1vl_16_c1s_5_c1nf_16_c2vl_32_lr_0.0001_rs_1--TrafficSign--1510487290.423481
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Augmented Factor = 0.5261265900000001
[Train] Batch ID = 5010, loss = 0.111215, acc = 0.96
[Validation] Batch ID = 5010, loss = 0.13073, acc = 0.9
[Train] Batch ID = 5020, loss = 0.0828358, acc = 0.98
[Validation] Batch ID = 5020, loss = 0.176762, acc = 0.84
[Train] Batch ID = 5030, loss = 0.34669, acc = 0.56
[Validation] Batch ID = 5030, loss = 0.130959, acc = 0.92
[Train] Batch ID = 5040, loss = 0.100185, acc = 0.96
[Validation] Batch ID = 5040, loss = 0.1493, acc = 0.9
[Train] Batch ID = 5050, loss = 0.317041, acc = 0.64
[Validation] Batch ID = 5050, loss = 0.137818, acc = 0.9
[Train] Batch ID = 5060, loss = 0.356594, acc = 0.58
[Validation] Batch ID = 5060, loss = 0.0936363, acc = 0.98
[Train] Batch ID = 5070, loss = 0.0787617, acc = 0.98
[Validation] Batch ID = 5070, loss = 0.148696, acc = 0.86
[Train] Batch ID = 5080, loss = 0.310343, acc = 0.68
[Validation] Batch ID = 5080, loss = 0.147444, acc = 0.92
[Train] Batch ID = 5090, loss = 0.0722696, acc = 0.98
[Validation] Batch ID = 5090, loss = 0.134743, acc = 0.9
[Train] Batch ID = 5100, loss = 0.353991, acc = 0.5
[Validation] Batch ID = 5100, loss = 0.130985, acc = 0.94
[Train] Batch ID = 5110, loss = 0.0866396, acc = 0.96
[Validation] Batch ID = 5110, loss = 0.140926, acc = 0.88
[Train] Batch ID = 5120, loss = 0.103618, acc = 0.96
[Validation] Batch ID = 5120, loss = 0.118347, acc = 0.94
[Train] Batch ID = 5130, loss = 0.329409, acc = 0.58
[Validation] Batch ID = 5130, loss = 0.152502, acc = 0.86
[Train] Batch ID = 5140, loss = 0.0613165, acc = 1.0
[Validation] Batch ID = 5140, loss = 0.100246, acc = 0.92
[Train] Batch ID = 5150, loss = 0.332219, acc = 0.56
[Validation] Batch ID = 5150, loss = 0.120714, acc = 0.94
[Train] Batch ID = 5160, loss = 0.307165, acc = 0.66
[Validation] Batch ID = 5160, loss = 0.111961, acc = 0.96
[Train] Batch ID = 5170, loss = 0.366883, acc = 0.56
[Validation] Batch ID = 5170, loss = 0.142321, acc = 0.9
[Train] Batch ID = 5180, loss = 0.0937919, acc = 0.96
[Validation] Batch ID = 5180, loss = 0.12042, acc = 0.92
[Train] Batch ID = 5190, loss = 0.0587151, acc = 1.0
[Validation] Batch ID = 5190, loss = 0.141912, acc = 0.88
[Train] Batch ID = 5200, loss = 0.304431, acc = 0.64
[Validation] Batch ID = 5200, loss = 0.121083, acc = 0.92
[Train] Batch ID = 5210, loss = 0.0710953, acc = 1.0
[Validation] Batch ID = 5210, loss = 0.0856288, acc = 0.98
[Train] Batch ID = 5220, loss = 0.264006, acc = 0.7
[Validation] Batch ID = 5220, loss = 0.129856, acc = 0.9
[Train] Batch ID = 5230, loss = 0.0869962, acc = 0.98
[Validation] Batch ID = 5230, loss = 0.125766, acc = 0.94
[Train] Batch ID = 5240, loss = 0.276833, acc = 0.68
[Validation] Batch ID = 5240, loss = 0.121645, acc = 0.92
[Train] Batch ID = 5250, loss = 0.292972, acc = 0.74
[Validation] Batch ID = 5250, loss = 0.155781, acc = 0.9
[Train] Batch ID = 5260, loss = 0.235346, acc = 0.72
[Validation] Batch ID = 5260, loss = 0.120066, acc = 0.9
[Train] Batch ID = 5270, loss = 0.240143, acc = 0.74
[Validation] Batch ID = 5270, loss = 0.104147, acc = 0.94
[Train] Batch ID = 5280, loss = 0.307093, acc = 0.6
[Validation] Batch ID = 5280, loss = 0.131358, acc = 0.96
[Train] Batch ID = 5290, loss = 0.307349, acc = 0.68
[Validation] Batch ID = 5290, loss = 0.149336, acc = 0.94
[Train] Batch ID = 5300, loss = 0.292067, acc = 0.64
[Validation] Batch ID = 5300, loss = 0.117791, acc = 0.92
[Train] Batch ID = 5310, loss = 0.0751029, acc = 0.98
[Validation] Batch ID = 5310, loss = 0.128437, acc = 0.9
[Train] Batch ID = 5320, loss = 0.321307, acc = 0.6
[Validation] Batch ID = 5320, loss = 0.122624, acc = 0.88
[Train] Batch ID = 5330, loss = 0.0603813, acc = 0.98
[Validation] Batch ID = 5330, loss = 0.139735, acc = 0.9
[Train] Batch ID = 5340, loss = 0.0871119, acc = 0.98
[Validation] Batch ID = 5340, loss = 0.141848, acc = 0.9
[Train] Batch ID = 5350, loss = 0.318677, acc = 0.72
[Validation] Batch ID = 5350, loss = 0.143202, acc = 0.9
[Train] Batch ID = 5360, loss = 0.337012, acc = 0.58
[Validation] Batch ID = 5360, loss = 0.110489, acc = 0.96
[Train] Batch ID = 5370, loss = 0.345958, acc = 0.58
[Validation] Batch ID = 5370, loss = 0.127582, acc = 0.92
[Train] Batch ID = 5380, loss = 0.0907787, acc = 0.98
[Validation] Batch ID = 5380, loss = 0.134124, acc = 0.92
[Train] Batch ID = 5390, loss = 0.0778071, acc = 0.98
[Validation] Batch ID = 5390, loss = 0.0940381, acc = 0.96
[Train] Batch ID = 5400, loss = 0.0724872, acc = 0.98
[Validation] Batch ID = 5400, loss = 0.165746, acc = 0.88
[Train] Batch ID = 5410, loss = 0.0808271, acc = 0.96
[Validation] Batch ID = 5410, loss = 0.131666, acc = 0.9
[Train] Batch ID = 5420, loss = 0.285628, acc = 0.68
[Validation] Batch ID = 5420, loss = 0.126661, acc = 0.9
[Train] Batch ID = 5430, loss = 0.294499, acc = 0.78
[Validation] Batch ID = 5430, loss = 0.108683, acc = 0.96
[Train] Batch ID = 5440, loss = 0.0775346, acc = 0.96
[Validation] Batch ID = 5440, loss = 0.146591, acc = 0.86
[Train] Batch ID = 5450, loss = 0.0707724, acc = 0.96
[Validation] Batch ID = 5450, loss = 0.116385, acc = 0.9
[Train] Batch ID = 5460, loss = 0.36352, acc = 0.64
[Validation] Batch ID = 5460, loss = 0.0906814, acc = 0.94
[Train] Batch ID = 5470, loss = 0.298624, acc = 0.68
[Validation] Batch ID = 5470, loss = 0.109376, acc = 0.96
[Train] Batch ID = 5480, loss = 0.0820604, acc = 0.94
[Validation] Batch ID = 5480, loss = 0.13531, acc = 0.9
[Train] Batch ID = 5490, loss = 0.0823278, acc = 0.94
[Validation] Batch ID = 5490, loss = 0.130791, acc = 0.88
[Train] Batch ID = 5500, loss = 0.329085, acc = 0.58
[Validation] Batch ID = 5500, loss = 0.121925, acc = 0.9
[Train] Batch ID = 5510, loss = 0.0695104, acc = 1.0
[Validation] Batch ID = 5510, loss = 0.126822, acc = 0.94
[Train] Batch ID = 5520, loss = 0.0577884, acc = 0.98
[Validation] Batch ID = 5520, loss = 0.134006, acc = 0.88
[Train] Batch ID = 5530, loss = 0.0800976, acc = 1.0
[Validation] Batch ID = 5530, loss = 0.118168, acc = 0.94
[Train] Batch ID = 5540, loss = 0.0855858, acc = 0.98
[Validation] Batch ID = 5540, loss = 0.150196, acc = 0.88
[Train] Batch ID = 5550, loss = 0.0940248, acc = 0.98
[Validation] Batch ID = 5550, loss = 0.0852951, acc = 1.0
[Train] Batch ID = 5560, loss = 0.0627295, acc = 1.0
[Validation] Batch ID = 5560, loss = 0.105115, acc = 0.96
[Train] Batch ID = 5570, loss = 0.0574958, acc = 1.0
[Validation] Batch ID = 5570, loss = 0.127381, acc = 0.9
[Train] Batch ID = 5580, loss = 0.0768132, acc = 1.0
[Validation] Batch ID = 5580, loss = 0.114554, acc = 0.98
[Train] Batch ID = 5590, loss = 0.355402, acc = 0.6
[Validation] Batch ID = 5590, loss = 0.0858995, acc = 1.0
[Train] Batch ID = 5600, loss = 0.307554, acc = 0.78
[Validation] Batch ID = 5600, loss = 0.121961, acc = 0.94
[Train] Batch ID = 5610, loss = 0.294391, acc = 0.62
[Validation] Batch ID = 5610, loss = 0.136189, acc = 0.9
[Train] Batch ID = 5620, loss = 0.319063, acc = 0.68
[Validation] Batch ID = 5620, loss = 0.148721, acc = 0.84
[Train] Batch ID = 5630, loss = 0.30883, acc = 0.68
[Validation] Batch ID = 5630, loss = 0.104458, acc = 0.96
[Train] Batch ID = 5640, loss = 0.0963946, acc = 0.92
[Validation] Batch ID = 5640, loss = 0.0959355, acc = 0.94
[Train] Batch ID = 5650, loss = 0.0865533, acc = 0.96
[Validation] Batch ID = 5650, loss = 0.113857, acc = 0.98
[Train] Batch ID = 5660, loss = 0.0898589, acc = 0.94
[Validation] Batch ID = 5660, loss = 0.131204, acc = 0.92
[Train] Batch ID = 5670, loss = 0.300514, acc = 0.74
[Validation] Batch ID = 5670, loss = 0.122702, acc = 0.96
[Train] Batch ID = 5680, loss = 0.29318, acc = 0.64
[Validation] Batch ID = 5680, loss = 0.141626, acc = 0.86
[Train] Batch ID = 5690, loss = 0.315339, acc = 0.66
[Validation] Batch ID = 5690, loss = 0.0804729, acc = 0.94
[Train] Batch ID = 5700, loss = 0.284438, acc = 0.74
[Validation] Batch ID = 5700, loss = 0.161431, acc = 0.88
[Train] Batch ID = 5710, loss = 0.242291, acc = 0.8
[Validation] Batch ID = 5710, loss = 0.0999018, acc = 0.94
[Train] Batch ID = 5720, loss = 0.0674115, acc = 1.0
[Validation] Batch ID = 5720, loss = 0.106594, acc = 0.94
[Train] Batch ID = 5730, loss = 0.0758679, acc = 0.92
[Validation] Batch ID = 5730, loss = 0.126265, acc = 0.88
[Train] Batch ID = 5740, loss = 0.0687217, acc = 1.0
[Validation] Batch ID = 5740, loss = 0.117947, acc = 0.9
[Train] Batch ID = 5750, loss = 0.30507, acc = 0.7
[Validation] Batch ID = 5750, loss = 0.10795, acc = 0.92
[Train] Batch ID = 5760, loss = 0.0643996, acc = 1.0
[Validation] Batch ID = 5760, loss = 0.154922, acc = 0.86
[Train] Batch ID = 5770, loss = 0.306526, acc = 0.62
[Validation] Batch ID = 5770, loss = 0.136512, acc = 0.86
[Train] Batch ID = 5780, loss = 0.0815369, acc = 0.96
[Validation] Batch ID = 5780, loss = 0.140355, acc = 0.96
[Train] Batch ID = 5790, loss = 0.0655566, acc = 1.0
[Validation] Batch ID = 5790, loss = 0.0999896, acc = 0.94
[Train] Batch ID = 5800, loss = 0.0731483, acc = 1.0
[Validation] Batch ID = 5800, loss = 0.108109, acc = 0.94
[Train] Batch ID = 5810, loss = 0.275999, acc = 0.68
[Validation] Batch ID = 5810, loss = 0.0988505, acc = 0.98
[Train] Batch ID = 5820, loss = 0.310483, acc = 0.68
[Validation] Batch ID = 5820, loss = 0.101192, acc = 0.92
[Train] Batch ID = 5830, loss = 0.314994, acc = 0.62
[Validation] Batch ID = 5830, loss = 0.128592, acc = 0.9
[Train] Batch ID = 5840, loss = 0.329252, acc = 0.64
[Validation] Batch ID = 5840, loss = 0.103497, acc = 0.98
[Train] Batch ID = 5850, loss = 0.0869699, acc = 0.98
[Validation] Batch ID = 5850, loss = 0.104129, acc = 0.94
[Train] Batch ID = 5860, loss = 0.336528, acc = 0.56
[Validation] Batch ID = 5860, loss = 0.131669, acc = 0.92
[Train] Batch ID = 5870, loss = 0.0766701, acc = 0.98
[Validation] Batch ID = 5870, loss = 0.0950392, acc = 0.96
[Train] Batch ID = 5880, loss = 0.0594488, acc = 0.98
[Validation] Batch ID = 5880, loss = 0.0852148, acc = 0.96
[Train] Batch ID = 5890, loss = 0.0635626, acc = 0.98
[Validation] Batch ID = 5890, loss = 0.146261, acc = 0.88
[Train] Batch ID = 5900, loss = 0.0832616, acc = 0.94
[Validation] Batch ID = 5900, loss = 0.0723635, acc = 1.0
[Train] Batch ID = 5910, loss = 0.295888, acc = 0.64
[Validation] Batch ID = 5910, loss = 0.0838609, acc = 0.98
[Train] Batch ID = 5920, loss = 0.0430435, acc = 1.0
[Validation] Batch ID = 5920, loss = 0.113322, acc = 0.92
[Train] Batch ID = 5930, loss = 0.0716543, acc = 0.96
[Validation] Batch ID = 5930, loss = 0.141552, acc = 0.92
[Train] Batch ID = 5940, loss = 0.0737806, acc = 0.96
[Validation] Batch ID = 5940, loss = 0.118766, acc = 0.92
[Train] Batch ID = 5950, loss = 0.292045, acc = 0.62
[Validation] Batch ID = 5950, loss = 0.10995, acc = 0.96
[Train] Batch ID = 5960, loss = 0.0665943, acc = 1.0
[Validation] Batch ID = 5960, loss = 0.11419, acc = 0.94
[Train] Batch ID = 5970, loss = 0.0669147, acc = 1.0
[Validation] Batch ID = 5970, loss = 0.076357, acc = 0.96
[Train] Batch ID = 5980, loss = 0.0652864, acc = 0.98
[Validation] Batch ID = 5980, loss = 0.117701, acc = 0.88
[Train] Batch ID = 5990, loss = 0.301814, acc = 0.6
[Validation] Batch ID = 5990, loss = 0.0847288, acc = 0.96
[Train] Batch ID = 6000, loss = 0.0683455, acc = 1.0
[Validation] Batch ID = 6000, loss = 0.105057, acc = 0.92
Evaluate full validation dataset ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Saving model ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Current loss: 0.109951 Best loss: 0.129008
[TOTAL Validation] Batch ID = 6000, loss = 0.109951, acc = 0.933106575964
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Model successfully saved here: outputs/checkpoints/c1s_9_c1n_256_c2s_6_c2n_64_c2d_0.7_c1vl_16_c1s_5_c1nf_16_c2vl_32_lr_0.0001_rs_1--TrafficSign--1510487290.423481
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Augmented Factor = 0.47351393100000005
[Train] Batch ID = 6010, loss = 0.353551, acc = 0.58
[Validation] Batch ID = 6010, loss = 0.105717, acc = 0.98
[Train] Batch ID = 6020, loss = 0.0663784, acc = 1.0
[Validation] Batch ID = 6020, loss = 0.105742, acc = 0.96
[Train] Batch ID = 6030, loss = 0.352534, acc = 0.7
[Validation] Batch ID = 6030, loss = 0.102683, acc = 0.98
[Train] Batch ID = 6040, loss = 0.262024, acc = 0.66
[Validation] Batch ID = 6040, loss = 0.0966711, acc = 0.92
[Train] Batch ID = 6050, loss = 0.345434, acc = 0.54
[Validation] Batch ID = 6050, loss = 0.137405, acc = 0.92
[Train] Batch ID = 6060, loss = 0.275484, acc = 0.74
[Validation] Batch ID = 6060, loss = 0.117571, acc = 0.94
[Train] Batch ID = 6070, loss = 0.297512, acc = 0.7
[Validation] Batch ID = 6070, loss = 0.103347, acc = 0.96
[Train] Batch ID = 6080, loss = 0.0734885, acc = 0.98
[Validation] Batch ID = 6080, loss = 0.124278, acc = 0.92
[Train] Batch ID = 6090, loss = 0.320392, acc = 0.56
[Validation] Batch ID = 6090, loss = 0.132537, acc = 0.9
[Train] Batch ID = 6100, loss = 0.0945441, acc = 0.96
[Validation] Batch ID = 6100, loss = 0.0982735, acc = 0.94
[Train] Batch ID = 6110, loss = 0.302992, acc = 0.7
[Validation] Batch ID = 6110, loss = 0.0907974, acc = 0.98
[Train] Batch ID = 6120, loss = 0.0602663, acc = 0.98
[Validation] Batch ID = 6120, loss = 0.096946, acc = 0.94
[Train] Batch ID = 6130, loss = 0.327098, acc = 0.5
[Validation] Batch ID = 6130, loss = 0.119332, acc = 0.94
[Train] Batch ID = 6140, loss = 0.0467502, acc = 1.0
[Validation] Batch ID = 6140, loss = 0.252479, acc = 0.8
[Train] Batch ID = 6150, loss = 0.290184, acc = 0.6
[Validation] Batch ID = 6150, loss = 0.103845, acc = 0.94
[Train] Batch ID = 6160, loss = 0.0745533, acc = 0.98
[Validation] Batch ID = 6160, loss = 0.0984035, acc = 0.98
[Train] Batch ID = 6170, loss = 0.267548, acc = 0.76
[Validation] Batch ID = 6170, loss = 0.0967519, acc = 0.92
[Train] Batch ID = 6180, loss = 0.0512226, acc = 1.0
[Validation] Batch ID = 6180, loss = 0.0991459, acc = 0.96
[Train] Batch ID = 6190, loss = 0.281571, acc = 0.74
[Validation] Batch ID = 6190, loss = 0.0905993, acc = 0.92
[Train] Batch ID = 6200, loss = 0.324071, acc = 0.6
[Validation] Batch ID = 6200, loss = 0.129145, acc = 0.9
[Train] Batch ID = 6210, loss = 0.0727794, acc = 1.0
[Validation] Batch ID = 6210, loss = 0.10921, acc = 0.92
[Train] Batch ID = 6220, loss = 0.0744024, acc = 0.98
[Validation] Batch ID = 6220, loss = 0.128591, acc = 0.9
[Train] Batch ID = 6230, loss = 0.272637, acc = 0.68
[Validation] Batch ID = 6230, loss = 0.0842886, acc = 0.96
[Train] Batch ID = 6240, loss = 0.0517748, acc = 1.0
[Validation] Batch ID = 6240, loss = 0.122566, acc = 0.92
[Train] Batch ID = 6250, loss = 0.0654356, acc = 0.98
[Validation] Batch ID = 6250, loss = 0.100778, acc = 0.96
[Train] Batch ID = 6260, loss = 0.310897, acc = 0.62
[Validation] Batch ID = 6260, loss = 0.0629376, acc = 0.98
[Train] Batch ID = 6270, loss = 0.240158, acc = 0.82
[Validation] Batch ID = 6270, loss = 0.0962848, acc = 0.94
[Train] Batch ID = 6280, loss = 0.056573, acc = 1.0
[Validation] Batch ID = 6280, loss = 0.086497, acc = 0.96
[Train] Batch ID = 6290, loss = 0.0707832, acc = 0.96
[Validation] Batch ID = 6290, loss = 0.107444, acc = 0.92
[Train] Batch ID = 6300, loss = 0.0848669, acc = 0.96
[Validation] Batch ID = 6300, loss = 0.0973555, acc = 0.92
[Train] Batch ID = 6310, loss = 0.291331, acc = 0.7
[Validation] Batch ID = 6310, loss = 0.106215, acc = 0.98
[Train] Batch ID = 6320, loss = 0.0503116, acc = 0.98
[Validation] Batch ID = 6320, loss = 0.0999261, acc = 0.94
[Train] Batch ID = 6330, loss = 0.0752168, acc = 1.0
[Validation] Batch ID = 6330, loss = 0.114369, acc = 0.92
[Train] Batch ID = 6340, loss = 0.0648313, acc = 0.98
[Validation] Batch ID = 6340, loss = 0.0789355, acc = 0.96
[Train] Batch ID = 6350, loss = 0.056943, acc = 1.0
[Validation] Batch ID = 6350, loss = 0.1133, acc = 0.94
[Train] Batch ID = 6360, loss = 0.309001, acc = 0.68
[Validation] Batch ID = 6360, loss = 0.0833175, acc = 0.98
[Train] Batch ID = 6370, loss = 0.0385679, acc = 1.0
[Validation] Batch ID = 6370, loss = 0.106298, acc = 0.92
[Train] Batch ID = 6380, loss = 0.0581265, acc = 1.0
[Validation] Batch ID = 6380, loss = 0.10221, acc = 0.96
[Train] Batch ID = 6390, loss = 0.0425605, acc = 1.0
[Validation] Batch ID = 6390, loss = 0.102534, acc = 0.96
[Train] Batch ID = 6400, loss = 0.303558, acc = 0.64
[Validation] Batch ID = 6400, loss = 0.0824382, acc = 0.98
[Train] Batch ID = 6410, loss = 0.257615, acc = 0.74
[Validation] Batch ID = 6410, loss = 0.0812071, acc = 0.96
[Train] Batch ID = 6420, loss = 0.300148, acc = 0.62
[Validation] Batch ID = 6420, loss = 0.128023, acc = 0.94
[Train] Batch ID = 6430, loss = 0.0466745, acc = 1.0
[Validation] Batch ID = 6430, loss = 0.108326, acc = 0.92
[Train] Batch ID = 6440, loss = 0.280808, acc = 0.78
[Validation] Batch ID = 6440, loss = 0.12184, acc = 0.92
[Train] Batch ID = 6450, loss = 0.275625, acc = 0.74
[Validation] Batch ID = 6450, loss = 0.0994354, acc = 0.92
[Train] Batch ID = 6460, loss = 0.0574024, acc = 0.98
[Validation] Batch ID = 6460, loss = 0.121209, acc = 0.98
[Train] Batch ID = 6470, loss = 0.0618423, acc = 0.96
[Validation] Batch ID = 6470, loss = 0.0957479, acc = 0.96
[Train] Batch ID = 6480, loss = 0.273448, acc = 0.74
[Validation] Batch ID = 6480, loss = 0.0881586, acc = 0.94
[Train] Batch ID = 6490, loss = 0.333295, acc = 0.56
[Validation] Batch ID = 6490, loss = 0.108645, acc = 0.94
[Train] Batch ID = 6500, loss = 0.0620709, acc = 0.98
[Validation] Batch ID = 6500, loss = 0.107227, acc = 0.94
[Train] Batch ID = 6510, loss = 0.33872, acc = 0.58
[Validation] Batch ID = 6510, loss = 0.0859817, acc = 0.94
[Train] Batch ID = 6520, loss = 0.313993, acc = 0.62
[Validation] Batch ID = 6520, loss = 0.105326, acc = 0.92
[Train] Batch ID = 6530, loss = 0.270128, acc = 0.78
[Validation] Batch ID = 6530, loss = 0.124158, acc = 0.86
[Train] Batch ID = 6540, loss = 0.285958, acc = 0.68
[Validation] Batch ID = 6540, loss = 0.113875, acc = 0.9
[Train] Batch ID = 6550, loss = 0.327764, acc = 0.66
[Validation] Batch ID = 6550, loss = 0.114084, acc = 0.9
[Train] Batch ID = 6560, loss = 0.0545782, acc = 1.0
[Validation] Batch ID = 6560, loss = 0.08413, acc = 0.92
[Train] Batch ID = 6570, loss = 0.0470913, acc = 1.0
[Validation] Batch ID = 6570, loss = 0.0779244, acc = 0.96
[Train] Batch ID = 6580, loss = 0.272972, acc = 0.68
[Validation] Batch ID = 6580, loss = 0.07664, acc = 0.96
[Train] Batch ID = 6590, loss = 0.0484631, acc = 1.0
[Validation] Batch ID = 6590, loss = 0.101806, acc = 0.94
[Train] Batch ID = 6600, loss = 0.271623, acc = 0.74
[Validation] Batch ID = 6600, loss = 0.110062, acc = 0.92
[Train] Batch ID = 6610, loss = 0.0479224, acc = 1.0
[Validation] Batch ID = 6610, loss = 0.115264, acc = 0.9
[Train] Batch ID = 6620, loss = 0.0606963, acc = 0.98
[Validation] Batch ID = 6620, loss = 0.126707, acc = 0.96
[Train] Batch ID = 6630, loss = 0.072026, acc = 0.98
[Validation] Batch ID = 6630, loss = 0.132214, acc = 0.9
[Train] Batch ID = 6640, loss = 0.072203, acc = 0.98
[Validation] Batch ID = 6640, loss = 0.0571554, acc = 1.0
[Train] Batch ID = 6650, loss = 0.0563057, acc = 1.0
[Validation] Batch ID = 6650, loss = 0.0663561, acc = 0.98
[Train] Batch ID = 6660, loss = 0.047503, acc = 1.0
[Validation] Batch ID = 6660, loss = 0.113502, acc = 0.94
[Train] Batch ID = 6670, loss = 0.0386325, acc = 1.0
[Validation] Batch ID = 6670, loss = 0.0820084, acc = 0.98
[Train] Batch ID = 6680, loss = 0.280239, acc = 0.78
[Validation] Batch ID = 6680, loss = 0.121086, acc = 0.88
[Train] Batch ID = 6690, loss = 0.0616162, acc = 1.0
[Validation] Batch ID = 6690, loss = 0.0918657, acc = 0.94
[Train] Batch ID = 6700, loss = 0.060578, acc = 1.0
[Validation] Batch ID = 6700, loss = 0.0800744, acc = 0.94
[Train] Batch ID = 6710, loss = 0.277742, acc = 0.72
[Validation] Batch ID = 6710, loss = 0.0724496, acc = 1.0
[Train] Batch ID = 6720, loss = 0.283863, acc = 0.78
[Validation] Batch ID = 6720, loss = 0.06415, acc = 0.98
[Train] Batch ID = 6730, loss = 0.041308, acc = 1.0
[Validation] Batch ID = 6730, loss = 0.112281, acc = 0.92
[Train] Batch ID = 6740, loss = 0.308038, acc = 0.62
[Validation] Batch ID = 6740, loss = 0.106205, acc = 0.92
[Train] Batch ID = 6750, loss = 0.040191, acc = 1.0
[Validation] Batch ID = 6750, loss = 0.0912596, acc = 0.96
[Train] Batch ID = 6760, loss = 0.0477022, acc = 1.0
[Validation] Batch ID = 6760, loss = 0.0896535, acc = 0.96
[Train] Batch ID = 6770, loss = 0.0606559, acc = 1.0
[Validation] Batch ID = 6770, loss = 0.0841062, acc = 0.94
[Train] Batch ID = 6780, loss = 0.241235, acc = 0.76
[Validation] Batch ID = 6780, loss = 0.104323, acc = 0.94
[Train] Batch ID = 6790, loss = 0.0624806, acc = 1.0
[Validation] Batch ID = 6790, loss = 0.0848831, acc = 0.94
[Train] Batch ID = 6800, loss = 0.274583, acc = 0.72
[Validation] Batch ID = 6800, loss = 0.0661882, acc = 0.98
[Train] Batch ID = 6810, loss = 0.317315, acc = 0.64
[Validation] Batch ID = 6810, loss = 0.0902677, acc = 0.96
[Train] Batch ID = 6820, loss = 0.0537432, acc = 1.0
[Validation] Batch ID = 6820, loss = 0.0905093, acc = 0.98
[Train] Batch ID = 6830, loss = 0.272607, acc = 0.74
[Validation] Batch ID = 6830, loss = 0.0810471, acc = 0.96
[Train] Batch ID = 6840, loss = 0.286404, acc = 0.66
[Validation] Batch ID = 6840, loss = 0.0892204, acc = 0.94
[Train] Batch ID = 6850, loss = 0.0637688, acc = 0.98
[Validation] Batch ID = 6850, loss = 0.117243, acc = 0.96
[Train] Batch ID = 6860, loss = 0.066502, acc = 0.98
[Validation] Batch ID = 6860, loss = 0.0814948, acc = 0.94
[Train] Batch ID = 6870, loss = 0.299192, acc = 0.72
[Validation] Batch ID = 6870, loss = 0.121373, acc = 0.92
[Train] Batch ID = 6880, loss = 0.345319, acc = 0.58
[Validation] Batch ID = 6880, loss = 0.0548027, acc = 1.0
[Train] Batch ID = 6890, loss = 0.0537293, acc = 1.0
[Validation] Batch ID = 6890, loss = 0.0882011, acc = 0.96
[Train] Batch ID = 6900, loss = 0.283388, acc = 0.62
[Validation] Batch ID = 6900, loss = 0.143836, acc = 0.86
[Train] Batch ID = 6910, loss = 0.0401841, acc = 1.0
[Validation] Batch ID = 6910, loss = 0.0863653, acc = 0.94
[Train] Batch ID = 6920, loss = 0.338397, acc = 0.44
[Validation] Batch ID = 6920, loss = 0.0949168, acc = 0.94
[Train] Batch ID = 6930, loss = 0.299574, acc = 0.7
[Validation] Batch ID = 6930, loss = 0.0776279, acc = 0.96
[Train] Batch ID = 6940, loss = 0.263118, acc = 0.7
[Validation] Batch ID = 6940, loss = 0.103064, acc = 0.92
[Train] Batch ID = 6950, loss = 0.061091, acc = 1.0
[Validation] Batch ID = 6950, loss = 0.118397, acc = 0.94
[Train] Batch ID = 6960, loss = 0.257486, acc = 0.76
[Validation] Batch ID = 6960, loss = 0.111664, acc = 0.86
[Train] Batch ID = 6970, loss = 0.054967, acc = 0.98
[Validation] Batch ID = 6970, loss = 0.0852872, acc = 0.98
[Train] Batch ID = 6980, loss = 0.0523128, acc = 0.98
[Validation] Batch ID = 6980, loss = 0.0755873, acc = 0.96
[Train] Batch ID = 6990, loss = 0.254943, acc = 0.76
[Validation] Batch ID = 6990, loss = 0.0773402, acc = 0.92
[Train] Batch ID = 7000, loss = 0.271886, acc = 0.74
[Validation] Batch ID = 7000, loss = 0.0968943, acc = 0.92
Evaluate full validation dataset ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Saving model ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Current loss: 0.0913591 Best loss: 0.109951
[TOTAL Validation] Batch ID = 7000, loss = 0.0913591, acc = 0.949433106576
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Model successfully saved here: outputs/checkpoints/c1s_9_c1n_256_c2s_6_c2n_64_c2d_0.7_c1vl_16_c1s_5_c1nf_16_c2vl_32_lr_0.0001_rs_1--TrafficSign--1510487290.423481
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Augmented Factor = 0.4261625379000001
[Train] Batch ID = 7010, loss = 0.0487198, acc = 1.0
[Validation] Batch ID = 7010, loss = 0.0986421, acc = 0.9
[Train] Batch ID = 7020, loss = 0.0339564, acc = 1.0
[Validation] Batch ID = 7020, loss = 0.106646, acc = 0.96
[Train] Batch ID = 7030, loss = 0.245646, acc = 0.76
[Validation] Batch ID = 7030, loss = 0.0894943, acc = 1.0
[Train] Batch ID = 7040, loss = 0.0515622, acc = 0.98
[Validation] Batch ID = 7040, loss = 0.101572, acc = 0.96
[Train] Batch ID = 7050, loss = 0.0724402, acc = 0.96
[Validation] Batch ID = 7050, loss = 0.0889175, acc = 0.96
[Train] Batch ID = 7060, loss = 0.259647, acc = 0.66
[Validation] Batch ID = 7060, loss = 0.0868668, acc = 0.98
[Train] Batch ID = 7070, loss = 0.0438396, acc = 1.0
[Validation] Batch ID = 7070, loss = 0.103552, acc = 0.96
[Train] Batch ID = 7080, loss = 0.0423951, acc = 1.0
[Validation] Batch ID = 7080, loss = 0.0937201, acc = 0.94
[Train] Batch ID = 7090, loss = 0.0470159, acc = 1.0
[Validation] Batch ID = 7090, loss = 0.0955545, acc = 0.96
[Train] Batch ID = 7100, loss = 0.0515601, acc = 0.98
[Validation] Batch ID = 7100, loss = 0.0995023, acc = 0.92
[Train] Batch ID = 7110, loss = 0.0541927, acc = 1.0
[Validation] Batch ID = 7110, loss = 0.097404, acc = 0.9
[Train] Batch ID = 7120, loss = 0.31425, acc = 0.68
[Validation] Batch ID = 7120, loss = 0.109746, acc = 0.92
[Train] Batch ID = 7130, loss = 0.295422, acc = 0.66
[Validation] Batch ID = 7130, loss = 0.0838397, acc = 0.96
[Train] Batch ID = 7140, loss = 0.0465429, acc = 1.0
[Validation] Batch ID = 7140, loss = 0.0603324, acc = 0.96
[Train] Batch ID = 7150, loss = 0.269984, acc = 0.68
[Validation] Batch ID = 7150, loss = 0.0777524, acc = 0.98
[Train] Batch ID = 7160, loss = 0.0428573, acc = 1.0
[Validation] Batch ID = 7160, loss = 0.0999772, acc = 0.98
[Train] Batch ID = 7170, loss = 0.0560181, acc = 0.98
[Validation] Batch ID = 7170, loss = 0.0900145, acc = 0.98
[Train] Batch ID = 7180, loss = 0.0496103, acc = 1.0
[Validation] Batch ID = 7180, loss = 0.103325, acc = 0.98
[Train] Batch ID = 7190, loss = 0.0498815, acc = 1.0
[Validation] Batch ID = 7190, loss = 0.0723835, acc = 1.0
[Train] Batch ID = 7200, loss = 0.0398846, acc = 1.0
[Validation] Batch ID = 7200, loss = 0.069744, acc = 0.98
[Train] Batch ID = 7210, loss = 0.0362986, acc = 1.0
[Validation] Batch ID = 7210, loss = 0.0756558, acc = 0.96
[Train] Batch ID = 7220, loss = 0.0402217, acc = 1.0
[Validation] Batch ID = 7220, loss = 0.0544531, acc = 0.98
[Train] Batch ID = 7230, loss = 0.034736, acc = 0.98
[Validation] Batch ID = 7230, loss = 0.0718904, acc = 0.98
[Train] Batch ID = 7240, loss = 0.0341844, acc = 1.0
[Validation] Batch ID = 7240, loss = 0.104571, acc = 0.92
[Train] Batch ID = 7250, loss = 0.0448337, acc = 1.0
[Validation] Batch ID = 7250, loss = 0.0615128, acc = 0.96
[Train] Batch ID = 7260, loss = 0.0549241, acc = 0.98
[Validation] Batch ID = 7260, loss = 0.0918379, acc = 0.94
[Train] Batch ID = 7270, loss = 0.29714, acc = 0.64
[Validation] Batch ID = 7270, loss = 0.097023, acc = 0.94
[Train] Batch ID = 7280, loss = 0.0407278, acc = 1.0
[Validation] Batch ID = 7280, loss = 0.0803461, acc = 0.98
[Train] Batch ID = 7290, loss = 0.0433269, acc = 1.0
[Validation] Batch ID = 7290, loss = 0.0580045, acc = 1.0
[Train] Batch ID = 7300, loss = 0.271525, acc = 0.78
[Validation] Batch ID = 7300, loss = 0.0788717, acc = 0.98
[Train] Batch ID = 7310, loss = 0.0414915, acc = 1.0
[Validation] Batch ID = 7310, loss = 0.0903151, acc = 0.92
[Train] Batch ID = 7320, loss = 0.041784, acc = 1.0
[Validation] Batch ID = 7320, loss = 0.088121, acc = 0.98
[Train] Batch ID = 7330, loss = 0.290061, acc = 0.72
[Validation] Batch ID = 7330, loss = 0.0544936, acc = 0.98
[Train] Batch ID = 7340, loss = 0.245797, acc = 0.72
[Validation] Batch ID = 7340, loss = 0.0812885, acc = 0.94
[Train] Batch ID = 7350, loss = 0.0529019, acc = 0.98
[Validation] Batch ID = 7350, loss = 0.0926233, acc = 0.96
[Train] Batch ID = 7360, loss = 0.260998, acc = 0.82
[Validation] Batch ID = 7360, loss = 0.0866582, acc = 0.94
[Train] Batch ID = 7370, loss = 0.274054, acc = 0.68
[Validation] Batch ID = 7370, loss = 0.0892459, acc = 0.94
[Train] Batch ID = 7380, loss = 0.0432344, acc = 1.0
[Validation] Batch ID = 7380, loss = 0.0596435, acc = 1.0
[Train] Batch ID = 7390, loss = 0.0422385, acc = 0.98
[Validation] Batch ID = 7390, loss = 0.0826426, acc = 0.98
[Train] Batch ID = 7400, loss = 0.0544904, acc = 0.98
[Validation] Batch ID = 7400, loss = 0.0995799, acc = 0.94
[Train] Batch ID = 7410, loss = 0.0425538, acc = 1.0
[Validation] Batch ID = 7410, loss = 0.0606936, acc = 0.98
[Train] Batch ID = 7420, loss = 0.293901, acc = 0.64
[Validation] Batch ID = 7420, loss = 0.1077, acc = 0.94
[Train] Batch ID = 7430, loss = 0.0515678, acc = 1.0
[Validation] Batch ID = 7430, loss = 0.0764414, acc = 0.96
[Train] Batch ID = 7440, loss = 0.059557, acc = 1.0
[Validation] Batch ID = 7440, loss = 0.104203, acc = 0.92
[Train] Batch ID = 7450, loss = 0.0428586, acc = 1.0
[Validation] Batch ID = 7450, loss = 0.0946019, acc = 0.94
[Train] Batch ID = 7460, loss = 0.327217, acc = 0.6
[Validation] Batch ID = 7460, loss = 0.0573529, acc = 1.0
[Train] Batch ID = 7470, loss = 0.309099, acc = 0.74
[Validation] Batch ID = 7470, loss = 0.118871, acc = 0.88
[Train] Batch ID = 7480, loss = 0.0390445, acc = 0.98
[Validation] Batch ID = 7480, loss = 0.0555397, acc = 0.98
[Train] Batch ID = 7490, loss = 0.27242, acc = 0.72
[Validation] Batch ID = 7490, loss = 0.0735152, acc = 0.96
[Train] Batch ID = 7500, loss = 0.286898, acc = 0.7
[Validation] Batch ID = 7500, loss = 0.103136, acc = 0.9
[Train] Batch ID = 7510, loss = 0.279976, acc = 0.66
[Validation] Batch ID = 7510, loss = 0.113373, acc = 0.92
[Train] Batch ID = 7520, loss = 0.0405618, acc = 1.0
[Validation] Batch ID = 7520, loss = 0.0805577, acc = 0.94
[Train] Batch ID = 7530, loss = 0.0368176, acc = 1.0
[Validation] Batch ID = 7530, loss = 0.0916392, acc = 0.96
[Train] Batch ID = 7540, loss = 0.308076, acc = 0.66
[Validation] Batch ID = 7540, loss = 0.0965591, acc = 0.94
[Train] Batch ID = 7550, loss = 0.0345143, acc = 1.0
[Validation] Batch ID = 7550, loss = 0.0668828, acc = 0.96
[Train] Batch ID = 7560, loss = 0.296109, acc = 0.66
[Validation] Batch ID = 7560, loss = 0.0875618, acc = 0.94
[Train] Batch ID = 7570, loss = 0.0351576, acc = 1.0
[Validation] Batch ID = 7570, loss = 0.109747, acc = 0.94
[Train] Batch ID = 7580, loss = 0.0575651, acc = 0.98
[Validation] Batch ID = 7580, loss = 0.100511, acc = 0.92
[Train] Batch ID = 7590, loss = 0.269704, acc = 0.74
[Validation] Batch ID = 7590, loss = 0.0941592, acc = 0.96
[Train] Batch ID = 7600, loss = 0.0640152, acc = 1.0
[Validation] Batch ID = 7600, loss = 0.0619655, acc = 0.94
[Train] Batch ID = 7610, loss = 0.252545, acc = 0.74
[Validation] Batch ID = 7610, loss = 0.0662513, acc = 1.0
[Train] Batch ID = 7620, loss = 0.0483569, acc = 0.98
[Validation] Batch ID = 7620, loss = 0.0925375, acc = 0.96
[Train] Batch ID = 7630, loss = 0.243786, acc = 0.78
[Validation] Batch ID = 7630, loss = 0.0655651, acc = 1.0
[Train] Batch ID = 7640, loss = 0.0557597, acc = 0.98
[Validation] Batch ID = 7640, loss = 0.0742074, acc = 1.0
[Train] Batch ID = 7650, loss = 0.270343, acc = 0.76
[Validation] Batch ID = 7650, loss = 0.0979451, acc = 0.96
[Train] Batch ID = 7660, loss = 0.0419352, acc = 1.0
[Validation] Batch ID = 7660, loss = 0.0865019, acc = 0.96
[Train] Batch ID = 7670, loss = 0.257101, acc = 0.72
[Validation] Batch ID = 7670, loss = 0.152153, acc = 0.82
[Train] Batch ID = 7680, loss = 0.322734, acc = 0.6
[Validation] Batch ID = 7680, loss = 0.0826568, acc = 1.0
[Train] Batch ID = 7690, loss = 0.283752, acc = 0.72
[Validation] Batch ID = 7690, loss = 0.0917829, acc = 0.9
[Train] Batch ID = 7700, loss = 0.282952, acc = 0.7
[Validation] Batch ID = 7700, loss = 0.0655329, acc = 0.98
[Train] Batch ID = 7710, loss = 0.0576194, acc = 1.0
[Validation] Batch ID = 7710, loss = 0.0779399, acc = 0.96
[Train] Batch ID = 7720, loss = 0.0477936, acc = 0.98
[Validation] Batch ID = 7720, loss = 0.0846093, acc = 0.96
[Train] Batch ID = 7730, loss = 0.0554332, acc = 1.0
[Validation] Batch ID = 7730, loss = 0.103984, acc = 0.92
[Train] Batch ID = 7740, loss = 0.307251, acc = 0.58
[Validation] Batch ID = 7740, loss = 0.0981987, acc = 0.94
[Train] Batch ID = 7750, loss = 0.0403732, acc = 1.0
[Validation] Batch ID = 7750, loss = 0.0712164, acc = 1.0
[Train] Batch ID = 7760, loss = 0.0351518, acc = 1.0
[Validation] Batch ID = 7760, loss = 0.0951276, acc = 0.94
[Train] Batch ID = 7770, loss = 0.0402704, acc = 0.98
[Validation] Batch ID = 7770, loss = 0.128983, acc = 0.9
[Train] Batch ID = 7780, loss = 0.03894, acc = 1.0
[Validation] Batch ID = 7780, loss = 0.123883, acc = 0.92
[Train] Batch ID = 7790, loss = 0.223138, acc = 0.86
[Validation] Batch ID = 7790, loss = 0.0732819, acc = 0.94
[Train] Batch ID = 7800, loss = 0.0438965, acc = 1.0
[Validation] Batch ID = 7800, loss = 0.0890185, acc = 0.96
[Train] Batch ID = 7810, loss = 0.271668, acc = 0.68
[Validation] Batch ID = 7810, loss = 0.0767867, acc = 0.98
[Train] Batch ID = 7820, loss = 0.222192, acc = 0.8
[Validation] Batch ID = 7820, loss = 0.0952505, acc = 0.94
[Train] Batch ID = 7830, loss = 0.316375, acc = 0.66
[Validation] Batch ID = 7830, loss = 0.0820147, acc = 0.96
[Train] Batch ID = 7840, loss = 0.3245, acc = 0.64
[Validation] Batch ID = 7840, loss = 0.0980256, acc = 0.94
[Train] Batch ID = 7850, loss = 0.0398391, acc = 1.0
[Validation] Batch ID = 7850, loss = 0.124014, acc = 0.88
[Train] Batch ID = 7860, loss = 0.329532, acc = 0.62
[Validation] Batch ID = 7860, loss = 0.0787504, acc = 0.96
[Train] Batch ID = 7870, loss = 0.0362406, acc = 1.0
[Validation] Batch ID = 7870, loss = 0.0910912, acc = 0.9
[Train] Batch ID = 7880, loss = 0.0380281, acc = 1.0
[Validation] Batch ID = 7880, loss = 0.0923428, acc = 0.98
[Train] Batch ID = 7890, loss = 0.274604, acc = 0.68
[Validation] Batch ID = 7890, loss = 0.0775265, acc = 0.96
[Train] Batch ID = 7900, loss = 0.0457938, acc = 0.98
[Validation] Batch ID = 7900, loss = 0.0856165, acc = 0.96
[Train] Batch ID = 7910, loss = 0.264536, acc = 0.7
[Validation] Batch ID = 7910, loss = 0.118862, acc = 0.96
[Train] Batch ID = 7920, loss = 0.0331632, acc = 1.0
[Validation] Batch ID = 7920, loss = 0.0454306, acc = 1.0
[Train] Batch ID = 7930, loss = 0.0375573, acc = 1.0
[Validation] Batch ID = 7930, loss = 0.105206, acc = 0.9
[Train] Batch ID = 7940, loss = 0.22417, acc = 0.88
[Validation] Batch ID = 7940, loss = 0.0847631, acc = 0.96
[Train] Batch ID = 7950, loss = 0.27494, acc = 0.7
[Validation] Batch ID = 7950, loss = 0.0998986, acc = 0.88
[Train] Batch ID = 7960, loss = 0.0510396, acc = 0.98
[Validation] Batch ID = 7960, loss = 0.0802052, acc = 0.98
[Train] Batch ID = 7970, loss = 0.257686, acc = 0.72
[Validation] Batch ID = 7970, loss = 0.0668219, acc = 0.98
[Train] Batch ID = 7980, loss = 0.278713, acc = 0.68
[Validation] Batch ID = 7980, loss = 0.0821996, acc = 0.94
[Train] Batch ID = 7990, loss = 0.24132, acc = 0.76
[Validation] Batch ID = 7990, loss = 0.0855121, acc = 0.96
[Train] Batch ID = 8000, loss = 0.0290238, acc = 1.0
[Validation] Batch ID = 8000, loss = 0.0743022, acc = 0.96
Evaluate full validation dataset ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Saving model ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Current loss: 0.0818688 Best loss: 0.0913591
[TOTAL Validation] Batch ID = 8000, loss = 0.0818688, acc = 0.956235827664
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Model successfully saved here: outputs/checkpoints/c1s_9_c1n_256_c2s_6_c2n_64_c2d_0.7_c1vl_16_c1s_5_c1nf_16_c2vl_32_lr_0.0001_rs_1--TrafficSign--1510487290.423481
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Augmented Factor = 0.3835462841100001
[Train] Batch ID = 8010, loss = 0.27528, acc = 0.62
[Validation] Batch ID = 8010, loss = 0.0748837, acc = 0.92
[Train] Batch ID = 8020, loss = 0.292786, acc = 0.6
[Validation] Batch ID = 8020, loss = 0.0763902, acc = 0.96
[Train] Batch ID = 8030, loss = 0.282813, acc = 0.74
[Validation] Batch ID = 8030, loss = 0.0640242, acc = 0.98
[Train] Batch ID = 8040, loss = 0.0348446, acc = 1.0
[Validation] Batch ID = 8040, loss = 0.108665, acc = 0.92
[Train] Batch ID = 8050, loss = 0.0668036, acc = 0.98
[Validation] Batch ID = 8050, loss = 0.0669015, acc = 0.98
[Train] Batch ID = 8060, loss = 0.0382698, acc = 1.0
[Validation] Batch ID = 8060, loss = 0.0759994, acc = 0.94
[Train] Batch ID = 8070, loss = 0.0416656, acc = 1.0
[Validation] Batch ID = 8070, loss = 0.100446, acc = 0.94
[Train] Batch ID = 8080, loss = 0.256744, acc = 0.74
[Validation] Batch ID = 8080, loss = 0.0728336, acc = 0.96
[Train] Batch ID = 8090, loss = 0.043247, acc = 1.0
[Validation] Batch ID = 8090, loss = 0.0846095, acc = 0.94
[Train] Batch ID = 8100, loss = 0.0422729, acc = 1.0
[Validation] Batch ID = 8100, loss = 0.0894126, acc = 0.98
[Train] Batch ID = 8110, loss = 0.260622, acc = 0.7
[Validation] Batch ID = 8110, loss = 0.0688025, acc = 0.98
[Train] Batch ID = 8120, loss = 0.0506637, acc = 0.98
[Validation] Batch ID = 8120, loss = 0.116244, acc = 0.92
[Train] Batch ID = 8130, loss = 0.273258, acc = 0.78
[Validation] Batch ID = 8130, loss = 0.0962926, acc = 0.98
[Train] Batch ID = 8140, loss = 0.0215239, acc = 1.0
[Validation] Batch ID = 8140, loss = 0.0722177, acc = 0.98
[Train] Batch ID = 8150, loss = 0.0423395, acc = 1.0
[Validation] Batch ID = 8150, loss = 0.0832904, acc = 0.94
[Train] Batch ID = 8160, loss = 0.0294857, acc = 1.0
[Validation] Batch ID = 8160, loss = 0.065913, acc = 0.98
[Train] Batch ID = 8170, loss = 0.25224, acc = 0.86
[Validation] Batch ID = 8170, loss = 0.0794374, acc = 0.92
[Train] Batch ID = 8180, loss = 0.0444033, acc = 1.0
[Validation] Batch ID = 8180, loss = 0.0845283, acc = 0.98
[Train] Batch ID = 8190, loss = 0.0378583, acc = 1.0
[Validation] Batch ID = 8190, loss = 0.0511073, acc = 0.98
[Train] Batch ID = 8200, loss = 0.0438331, acc = 1.0
[Validation] Batch ID = 8200, loss = 0.0819042, acc = 0.96
[Train] Batch ID = 8210, loss = 0.0381253, acc = 1.0
[Validation] Batch ID = 8210, loss = 0.0810078, acc = 0.96
[Train] Batch ID = 8220, loss = 0.0397449, acc = 1.0
[Validation] Batch ID = 8220, loss = 0.0666166, acc = 0.96
[Train] Batch ID = 8230, loss = 0.294424, acc = 0.64
[Validation] Batch ID = 8230, loss = 0.0659258, acc = 0.96
[Train] Batch ID = 8240, loss = 0.257666, acc = 0.78
[Validation] Batch ID = 8240, loss = 0.0871216, acc = 0.92
[Train] Batch ID = 8250, loss = 0.308528, acc = 0.64
[Validation] Batch ID = 8250, loss = 0.0690989, acc = 0.96
[Train] Batch ID = 8260, loss = 0.0301057, acc = 1.0
[Validation] Batch ID = 8260, loss = 0.124542, acc = 0.94
[Train] Batch ID = 8270, loss = 0.0244233, acc = 1.0
[Validation] Batch ID = 8270, loss = 0.0924073, acc = 0.94
[Train] Batch ID = 8280, loss = 0.0393176, acc = 1.0
[Validation] Batch ID = 8280, loss = 0.0750193, acc = 0.94
[Train] Batch ID = 8290, loss = 0.256089, acc = 0.72
[Validation] Batch ID = 8290, loss = 0.0847558, acc = 0.94
[Train] Batch ID = 8300, loss = 0.0295313, acc = 1.0
[Validation] Batch ID = 8300, loss = 0.115506, acc = 0.9
[Train] Batch ID = 8310, loss = 0.041745, acc = 1.0
[Validation] Batch ID = 8310, loss = 0.0846277, acc = 0.92
[Train] Batch ID = 8320, loss = 0.281196, acc = 0.76
[Validation] Batch ID = 8320, loss = 0.0756631, acc = 0.96
[Train] Batch ID = 8330, loss = 0.301806, acc = 0.68
[Validation] Batch ID = 8330, loss = 0.0362425, acc = 1.0
[Train] Batch ID = 8340, loss = 0.0437055, acc = 0.98
[Validation] Batch ID = 8340, loss = 0.103319, acc = 0.94
[Train] Batch ID = 8350, loss = 0.244345, acc = 0.76
[Validation] Batch ID = 8350, loss = 0.0921808, acc = 0.94
[Train] Batch ID = 8360, loss = 0.0414006, acc = 1.0
[Validation] Batch ID = 8360, loss = 0.0825483, acc = 0.94
[Train] Batch ID = 8370, loss = 0.265903, acc = 0.72
[Validation] Batch ID = 8370, loss = 0.0760844, acc = 0.94
[Train] Batch ID = 8380, loss = 0.0352259, acc = 1.0
[Validation] Batch ID = 8380, loss = 0.0853136, acc = 0.96
[Train] Batch ID = 8390, loss = 0.255135, acc = 0.82
[Validation] Batch ID = 8390, loss = 0.082369, acc = 0.94
[Train] Batch ID = 8400, loss = 0.0458829, acc = 1.0
[Validation] Batch ID = 8400, loss = 0.0636071, acc = 0.94
[Train] Batch ID = 8410, loss = 0.294154, acc = 0.7
[Validation] Batch ID = 8410, loss = 0.0617988, acc = 0.98
[Train] Batch ID = 8420, loss = 0.0220582, acc = 1.0
[Validation] Batch ID = 8420, loss = 0.0722412, acc = 0.96
[Train] Batch ID = 8430, loss = 0.26236, acc = 0.7
[Validation] Batch ID = 8430, loss = 0.0926747, acc = 0.94
[Train] Batch ID = 8440, loss = 0.0361782, acc = 1.0
[Validation] Batch ID = 8440, loss = 0.0755438, acc = 0.98
[Train] Batch ID = 8450, loss = 0.269942, acc = 0.72
[Validation] Batch ID = 8450, loss = 0.0526855, acc = 0.98
[Train] Batch ID = 8460, loss = 0.250472, acc = 0.78
[Validation] Batch ID = 8460, loss = 0.0934611, acc = 0.94
[Train] Batch ID = 8470, loss = 0.0200514, acc = 1.0
[Validation] Batch ID = 8470, loss = 0.093321, acc = 0.98
[Train] Batch ID = 8480, loss = 0.0428039, acc = 0.98
[Validation] Batch ID = 8480, loss = 0.0552503, acc = 1.0
[Train] Batch ID = 8490, loss = 0.265512, acc = 0.7
[Validation] Batch ID = 8490, loss = 0.0614077, acc = 0.98
[Train] Batch ID = 8500, loss = 0.0308441, acc = 1.0
[Validation] Batch ID = 8500, loss = 0.0605858, acc = 0.96
[Train] Batch ID = 8510, loss = 0.0265815, acc = 1.0
[Validation] Batch ID = 8510, loss = 0.0989401, acc = 0.96
[Train] Batch ID = 8520, loss = 0.247413, acc = 0.74
[Validation] Batch ID = 8520, loss = 0.0698089, acc = 0.96
[Train] Batch ID = 8530, loss = 0.0259142, acc = 1.0
[Validation] Batch ID = 8530, loss = 0.115373, acc = 0.9
[Train] Batch ID = 8540, loss = 0.239534, acc = 0.8
[Validation] Batch ID = 8540, loss = 0.0865728, acc = 0.96
[Train] Batch ID = 8550, loss = 0.236485, acc = 0.8
[Validation] Batch ID = 8550, loss = 0.0670755, acc = 0.96
[Train] Batch ID = 8560, loss = 0.0396632, acc = 1.0
[Validation] Batch ID = 8560, loss = 0.066268, acc = 0.96
[Train] Batch ID = 8570, loss = 0.288155, acc = 0.7
[Validation] Batch ID = 8570, loss = 0.0882024, acc = 0.9
[Train] Batch ID = 8580, loss = 0.264624, acc = 0.7
[Validation] Batch ID = 8580, loss = 0.0561912, acc = 1.0
[Train] Batch ID = 8590, loss = 0.0405446, acc = 1.0
[Validation] Batch ID = 8590, loss = 0.0788573, acc = 0.94
[Train] Batch ID = 8600, loss = 0.0394679, acc = 1.0
[Validation] Batch ID = 8600, loss = 0.0881677, acc = 0.92
[Train] Batch ID = 8610, loss = 0.239138, acc = 0.76
[Validation] Batch ID = 8610, loss = 0.0776586, acc = 0.98
[Train] Batch ID = 8620, loss = 0.0242431, acc = 1.0
[Validation] Batch ID = 8620, loss = 0.0821427, acc = 0.92
[Train] Batch ID = 8630, loss = 0.28181, acc = 0.76
[Validation] Batch ID = 8630, loss = 0.0882124, acc = 0.94
[Train] Batch ID = 8640, loss = 0.0338977, acc = 1.0
[Validation] Batch ID = 8640, loss = 0.0731739, acc = 0.96
[Train] Batch ID = 8650, loss = 0.0441589, acc = 1.0
[Validation] Batch ID = 8650, loss = 0.0815353, acc = 0.94
[Train] Batch ID = 8660, loss = 0.0376473, acc = 1.0
[Validation] Batch ID = 8660, loss = 0.100622, acc = 0.92
[Train] Batch ID = 8670, loss = 0.0424785, acc = 1.0
[Validation] Batch ID = 8670, loss = 0.0515921, acc = 1.0
[Train] Batch ID = 8680, loss = 0.0327239, acc = 1.0
[Validation] Batch ID = 8680, loss = 0.0605735, acc = 1.0
[Train] Batch ID = 8690, loss = 0.0422158, acc = 0.98
[Validation] Batch ID = 8690, loss = 0.0657072, acc = 0.98
[Train] Batch ID = 8700, loss = 0.281405, acc = 0.74
[Validation] Batch ID = 8700, loss = 0.0472511, acc = 1.0
[Train] Batch ID = 8710, loss = 0.29021, acc = 0.66
[Validation] Batch ID = 8710, loss = 0.068747, acc = 0.96
[Train] Batch ID = 8720, loss = 0.0364292, acc = 1.0
[Validation] Batch ID = 8720, loss = 0.0628496, acc = 0.96
[Train] Batch ID = 8730, loss = 0.219382, acc = 0.8
[Validation] Batch ID = 8730, loss = 0.0792795, acc = 0.96
[Train] Batch ID = 8740, loss = 0.0300492, acc = 1.0
[Validation] Batch ID = 8740, loss = 0.0716525, acc = 0.94
[Train] Batch ID = 8750, loss = 0.200257, acc = 0.82
[Validation] Batch ID = 8750, loss = 0.0666566, acc = 0.94
[Train] Batch ID = 8760, loss = 0.253806, acc = 0.76
[Validation] Batch ID = 8760, loss = 0.0725813, acc = 0.96
[Train] Batch ID = 8770, loss = 0.221337, acc = 0.88
[Validation] Batch ID = 8770, loss = 0.0730072, acc = 0.94
[Train] Batch ID = 8780, loss = 0.269851, acc = 0.72
[Validation] Batch ID = 8780, loss = 0.0718302, acc = 0.98
[Train] Batch ID = 8790, loss = 0.0234266, acc = 1.0
[Validation] Batch ID = 8790, loss = 0.0509318, acc = 1.0
[Train] Batch ID = 8800, loss = 0.0462745, acc = 1.0
[Validation] Batch ID = 8800, loss = 0.0881032, acc = 0.94
[Train] Batch ID = 8810, loss = 0.0257416, acc = 1.0
[Validation] Batch ID = 8810, loss = 0.058623, acc = 1.0
[Train] Batch ID = 8820, loss = 0.0393008, acc = 1.0
[Validation] Batch ID = 8820, loss = 0.111003, acc = 0.92
[Train] Batch ID = 8830, loss = 0.0302658, acc = 1.0
[Validation] Batch ID = 8830, loss = 0.0815632, acc = 0.94
[Train] Batch ID = 8840, loss = 0.269064, acc = 0.74
[Validation] Batch ID = 8840, loss = 0.0525029, acc = 0.96
[Train] Batch ID = 8850, loss = 0.0329526, acc = 1.0
[Validation] Batch ID = 8850, loss = 0.0874354, acc = 0.96
[Train] Batch ID = 8860, loss = 0.0312124, acc = 1.0
[Validation] Batch ID = 8860, loss = 0.0950556, acc = 0.9
[Train] Batch ID = 8870, loss = 0.0351712, acc = 1.0
[Validation] Batch ID = 8870, loss = 0.0639514, acc = 0.94
[Train] Batch ID = 8880, loss = 0.019568, acc = 1.0
[Validation] Batch ID = 8880, loss = 0.0550488, acc = 0.98
[Train] Batch ID = 8890, loss = 0.0259505, acc = 1.0
[Validation] Batch ID = 8890, loss = 0.0472877, acc = 1.0
[Train] Batch ID = 8900, loss = 0.0441991, acc = 0.96
[Validation] Batch ID = 8900, loss = 0.0555078, acc = 0.96
[Train] Batch ID = 8910, loss = 0.261854, acc = 0.72
[Validation] Batch ID = 8910, loss = 0.0588934, acc = 0.98
[Train] Batch ID = 8920, loss = 0.0327642, acc = 0.98
[Validation] Batch ID = 8920, loss = 0.0632027, acc = 0.98
[Train] Batch ID = 8930, loss = 0.0298702, acc = 1.0
[Validation] Batch ID = 8930, loss = 0.0688324, acc = 0.96
[Train] Batch ID = 8940, loss = 0.037612, acc = 1.0
[Validation] Batch ID = 8940, loss = 0.0776624, acc = 0.96
[Train] Batch ID = 8950, loss = 0.0400275, acc = 1.0
[Validation] Batch ID = 8950, loss = 0.0566437, acc = 0.98
[Train] Batch ID = 8960, loss = 0.261337, acc = 0.72
[Validation] Batch ID = 8960, loss = 0.0795078, acc = 0.94
[Train] Batch ID = 8970, loss = 0.274757, acc = 0.78
[Validation] Batch ID = 8970, loss = 0.0614441, acc = 0.96
[Train] Batch ID = 8980, loss = 0.0376411, acc = 1.0
[Validation] Batch ID = 8980, loss = 0.0612421, acc = 0.98
[Train] Batch ID = 8990, loss = 0.033753, acc = 1.0
[Validation] Batch ID = 8990, loss = 0.0590532, acc = 0.98
[Train] Batch ID = 9000, loss = 0.270359, acc = 0.68
[Validation] Batch ID = 9000, loss = 0.0639195, acc = 0.96
Evaluate full validation dataset ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Saving model ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Current loss: 0.0730149 Best loss: 0.0818688
[TOTAL Validation] Batch ID = 9000, loss = 0.0730149, acc = 0.956916099773
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Model successfully saved here: outputs/checkpoints/c1s_9_c1n_256_c2s_6_c2n_64_c2d_0.7_c1vl_16_c1s_5_c1nf_16_c2vl_32_lr_0.0001_rs_1--TrafficSign--1510487290.423481
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Augmented Factor = 0.34519165569900007
[Train] Batch ID = 9010, loss = 0.0371402, acc = 0.98
[Validation] Batch ID = 9010, loss = 0.0990682, acc = 0.92
[Train] Batch ID = 9020, loss = 0.244633, acc = 0.8
[Validation] Batch ID = 9020, loss = 0.0506787, acc = 1.0
[Train] Batch ID = 9030, loss = 0.0375165, acc = 1.0
[Validation] Batch ID = 9030, loss = 0.0584152, acc = 0.96
[Train] Batch ID = 9040, loss = 0.0230043, acc = 1.0
[Validation] Batch ID = 9040, loss = 0.0782268, acc = 0.96
[Train] Batch ID = 9050, loss = 0.02809, acc = 1.0
[Validation] Batch ID = 9050, loss = 0.0911876, acc = 0.94
[Train] Batch ID = 9060, loss = 0.0511767, acc = 0.94
[Validation] Batch ID = 9060, loss = 0.052349, acc = 0.98
[Train] Batch ID = 9070, loss = 0.0325103, acc = 1.0
[Validation] Batch ID = 9070, loss = 0.0557392, acc = 0.96
[Train] Batch ID = 9080, loss = 0.0182243, acc = 1.0
[Validation] Batch ID = 9080, loss = 0.0564094, acc = 0.98
[Train] Batch ID = 9090, loss = 0.0210972, acc = 1.0
[Validation] Batch ID = 9090, loss = 0.0613834, acc = 0.94
[Train] Batch ID = 9100, loss = 0.0289811, acc = 1.0
[Validation] Batch ID = 9100, loss = 0.0835657, acc = 0.98
[Train] Batch ID = 9110, loss = 0.276841, acc = 0.64
[Validation] Batch ID = 9110, loss = 0.0645217, acc = 0.96
[Train] Batch ID = 9120, loss = 0.0263086, acc = 1.0
[Validation] Batch ID = 9120, loss = 0.0862485, acc = 0.98
[Train] Batch ID = 9130, loss = 0.0258585, acc = 1.0
[Validation] Batch ID = 9130, loss = 0.0768491, acc = 0.94
[Train] Batch ID = 9140, loss = 0.263266, acc = 0.76
[Validation] Batch ID = 9140, loss = 0.0517884, acc = 1.0
[Train] Batch ID = 9150, loss = 0.0472574, acc = 1.0
[Validation] Batch ID = 9150, loss = 0.0501246, acc = 1.0
[Train] Batch ID = 9160, loss = 0.246189, acc = 0.7
[Validation] Batch ID = 9160, loss = 0.059866, acc = 0.96
[Train] Batch ID = 9170, loss = 0.0285539, acc = 1.0
[Validation] Batch ID = 9170, loss = 0.0761802, acc = 0.96
[Train] Batch ID = 9180, loss = 0.0300271, acc = 1.0
[Validation] Batch ID = 9180, loss = 0.0740342, acc = 0.96
[Train] Batch ID = 9190, loss = 0.0494826, acc = 1.0
[Validation] Batch ID = 9190, loss = 0.0888444, acc = 0.92
[Train] Batch ID = 9200, loss = 0.221246, acc = 0.82
[Validation] Batch ID = 9200, loss = 0.0855724, acc = 0.92
[Train] Batch ID = 9210, loss = 0.0438174, acc = 0.98
[Validation] Batch ID = 9210, loss = 0.0885618, acc = 0.92
[Train] Batch ID = 9220, loss = 0.230868, acc = 0.76
[Validation] Batch ID = 9220, loss = 0.0523801, acc = 0.96
[Train] Batch ID = 9230, loss = 0.274029, acc = 0.68
[Validation] Batch ID = 9230, loss = 0.105097, acc = 0.88
[Train] Batch ID = 9240, loss = 0.248899, acc = 0.88
[Validation] Batch ID = 9240, loss = 0.0569448, acc = 0.96
[Train] Batch ID = 9250, loss = 0.0319467, acc = 1.0
[Validation] Batch ID = 9250, loss = 0.0515399, acc = 0.98
[Train] Batch ID = 9260, loss = 0.271277, acc = 0.72
[Validation] Batch ID = 9260, loss = 0.0678958, acc = 0.96
[Train] Batch ID = 9270, loss = 0.0334095, acc = 1.0
[Validation] Batch ID = 9270, loss = 0.0894422, acc = 0.92
[Train] Batch ID = 9280, loss = 0.0244803, acc = 1.0
[Validation] Batch ID = 9280, loss = 0.0687834, acc = 0.94
[Train] Batch ID = 9290, loss = 0.0389232, acc = 0.98
[Validation] Batch ID = 9290, loss = 0.0482319, acc = 1.0
[Train] Batch ID = 9300, loss = 0.0306783, acc = 1.0
[Validation] Batch ID = 9300, loss = 0.0740482, acc = 0.96
[Train] Batch ID = 9310, loss = 0.0265655, acc = 1.0
[Validation] Batch ID = 9310, loss = 0.0955756, acc = 0.94
[Train] Batch ID = 9320, loss = 0.0298557, acc = 1.0
[Validation] Batch ID = 9320, loss = 0.0929293, acc = 0.94
[Train] Batch ID = 9330, loss = 0.252435, acc = 0.72
[Validation] Batch ID = 9330, loss = 0.0674733, acc = 0.94
[Train] Batch ID = 9340, loss = 0.0273754, acc = 1.0
[Validation] Batch ID = 9340, loss = 0.0390324, acc = 1.0
[Train] Batch ID = 9350, loss = 0.0282579, acc = 1.0
[Validation] Batch ID = 9350, loss = 0.0569153, acc = 0.98
[Train] Batch ID = 9360, loss = 0.263307, acc = 0.76
[Validation] Batch ID = 9360, loss = 0.0835898, acc = 0.96
[Train] Batch ID = 9370, loss = 0.250693, acc = 0.78
[Validation] Batch ID = 9370, loss = 0.0923268, acc = 0.94
[Train] Batch ID = 9380, loss = 0.0383909, acc = 1.0
[Validation] Batch ID = 9380, loss = 0.0753173, acc = 0.98
[Train] Batch ID = 9390, loss = 0.28642, acc = 0.68
[Validation] Batch ID = 9390, loss = 0.0844799, acc = 0.96
[Train] Batch ID = 9400, loss = 0.258013, acc = 0.76
[Validation] Batch ID = 9400, loss = 0.0748619, acc = 0.94
[Train] Batch ID = 9410, loss = 0.299166, acc = 0.62
[Validation] Batch ID = 9410, loss = 0.0575375, acc = 1.0
[Train] Batch ID = 9420, loss = 0.230754, acc = 0.84
[Validation] Batch ID = 9420, loss = 0.0900916, acc = 0.92
[Train] Batch ID = 9430, loss = 0.252281, acc = 0.78
[Validation] Batch ID = 9430, loss = 0.0876613, acc = 0.92
[Train] Batch ID = 9440, loss = 0.21312, acc = 0.84
[Validation] Batch ID = 9440, loss = 0.0949212, acc = 0.88
[Train] Batch ID = 9450, loss = 0.0253684, acc = 1.0
[Validation] Batch ID = 9450, loss = 0.067889, acc = 0.96
[Train] Batch ID = 9460, loss = 0.0228306, acc = 1.0
[Validation] Batch ID = 9460, loss = 0.0697475, acc = 0.98
[Train] Batch ID = 9470, loss = 0.0300234, acc = 1.0
[Validation] Batch ID = 9470, loss = 0.0643063, acc = 1.0
[Train] Batch ID = 9480, loss = 0.234244, acc = 0.76
[Validation] Batch ID = 9480, loss = 0.0580945, acc = 0.94
[Train] Batch ID = 9490, loss = 0.0241856, acc = 1.0
[Validation] Batch ID = 9490, loss = 0.0526494, acc = 0.98
[Train] Batch ID = 9500, loss = 0.301242, acc = 0.72
[Validation] Batch ID = 9500, loss = 0.0691274, acc = 0.94
[Train] Batch ID = 9510, loss = 0.0424527, acc = 1.0
[Validation] Batch ID = 9510, loss = 0.0751837, acc = 0.94
[Train] Batch ID = 9520, loss = 0.262915, acc = 0.68
[Validation] Batch ID = 9520, loss = 0.099433, acc = 0.92
[Train] Batch ID = 9530, loss = 0.279886, acc = 0.62
[Validation] Batch ID = 9530, loss = 0.0846491, acc = 0.96
[Train] Batch ID = 9540, loss = 0.0204471, acc = 1.0
[Validation] Batch ID = 9540, loss = 0.0536329, acc = 0.98
[Train] Batch ID = 9550, loss = 0.219712, acc = 0.84
[Validation] Batch ID = 9550, loss = 0.0850142, acc = 0.92
[Train] Batch ID = 9560, loss = 0.0245071, acc = 1.0
[Validation] Batch ID = 9560, loss = 0.0734636, acc = 0.96
[Train] Batch ID = 9570, loss = 0.0444164, acc = 1.0
[Validation] Batch ID = 9570, loss = 0.0879174, acc = 0.96
[Train] Batch ID = 9580, loss = 0.210319, acc = 0.82
[Validation] Batch ID = 9580, loss = 0.0602446, acc = 0.98
[Train] Batch ID = 9590, loss = 0.214075, acc = 0.84
[Validation] Batch ID = 9590, loss = 0.0685335, acc = 0.94
[Train] Batch ID = 9600, loss = 0.035629, acc = 1.0
[Validation] Batch ID = 9600, loss = 0.0464298, acc = 1.0
[Train] Batch ID = 9610, loss = 0.0310239, acc = 1.0
[Validation] Batch ID = 9610, loss = 0.0688841, acc = 0.94
[Train] Batch ID = 9620, loss = 0.0417222, acc = 0.98
[Validation] Batch ID = 9620, loss = 0.0528665, acc = 0.98
[Train] Batch ID = 9630, loss = 0.219635, acc = 0.82
[Validation] Batch ID = 9630, loss = 0.0601971, acc = 0.98
[Train] Batch ID = 9640, loss = 0.275698, acc = 0.7
[Validation] Batch ID = 9640, loss = 0.113864, acc = 0.88
[Train] Batch ID = 9650, loss = 0.252119, acc = 0.76
[Validation] Batch ID = 9650, loss = 0.0579154, acc = 0.96
[Train] Batch ID = 9660, loss = 0.0389128, acc = 1.0
[Validation] Batch ID = 9660, loss = 0.0641635, acc = 0.96
[Train] Batch ID = 9670, loss = 0.258587, acc = 0.76
[Validation] Batch ID = 9670, loss = 0.0542866, acc = 0.96
[Train] Batch ID = 9680, loss = 0.0439214, acc = 0.98
[Validation] Batch ID = 9680, loss = 0.0575417, acc = 1.0
[Train] Batch ID = 9690, loss = 0.0282933, acc = 1.0
[Validation] Batch ID = 9690, loss = 0.066501, acc = 0.96
[Train] Batch ID = 9700, loss = 0.217716, acc = 0.86
[Validation] Batch ID = 9700, loss = 0.148524, acc = 0.9
[Train] Batch ID = 9710, loss = 0.239336, acc = 0.78
[Validation] Batch ID = 9710, loss = 0.0797583, acc = 0.92
[Train] Batch ID = 9720, loss = 0.0425604, acc = 1.0
[Validation] Batch ID = 9720, loss = 0.0475135, acc = 1.0
[Train] Batch ID = 9730, loss = 0.0409698, acc = 1.0
[Validation] Batch ID = 9730, loss = 0.0530235, acc = 0.98
[Train] Batch ID = 9740, loss = 0.0250429, acc = 1.0
[Validation] Batch ID = 9740, loss = 0.0458096, acc = 1.0
[Train] Batch ID = 9750, loss = 0.0339193, acc = 1.0
[Validation] Batch ID = 9750, loss = 0.0612558, acc = 0.98
[Train] Batch ID = 9760, loss = 0.0356182, acc = 1.0
[Validation] Batch ID = 9760, loss = 0.0505561, acc = 0.98
[Train] Batch ID = 9770, loss = 0.253273, acc = 0.76
[Validation] Batch ID = 9770, loss = 0.0510211, acc = 1.0
[Train] Batch ID = 9780, loss = 0.0218458, acc = 1.0
[Validation] Batch ID = 9780, loss = 0.0535055, acc = 1.0
[Train] Batch ID = 9790, loss = 0.042029, acc = 0.98
[Validation] Batch ID = 9790, loss = 0.0609709, acc = 0.96
[Train] Batch ID = 9800, loss = 0.0300864, acc = 1.0
[Validation] Batch ID = 9800, loss = 0.0807172, acc = 0.94
[Train] Batch ID = 9810, loss = 0.0242036, acc = 1.0
[Validation] Batch ID = 9810, loss = 0.0761893, acc = 0.96
[Train] Batch ID = 9820, loss = 0.0378429, acc = 0.98
[Validation] Batch ID = 9820, loss = 0.0495288, acc = 0.98
[Train] Batch ID = 9830, loss = 0.295582, acc = 0.66
[Validation] Batch ID = 9830, loss = 0.049226, acc = 1.0
[Train] Batch ID = 9840, loss = 0.23147, acc = 0.78
[Validation] Batch ID = 9840, loss = 0.0919249, acc = 0.92
[Train] Batch ID = 9850, loss = 0.0285242, acc = 1.0
[Validation] Batch ID = 9850, loss = 0.0455753, acc = 1.0
[Train] Batch ID = 9860, loss = 0.0230636, acc = 1.0
[Validation] Batch ID = 9860, loss = 0.09085, acc = 0.94
[Train] Batch ID = 9870, loss = 0.0291944, acc = 1.0
[Validation] Batch ID = 9870, loss = 0.0596458, acc = 0.98
[Train] Batch ID = 9880, loss = 0.0224168, acc = 1.0
[Validation] Batch ID = 9880, loss = 0.0559767, acc = 0.96
[Train] Batch ID = 9890, loss = 0.240785, acc = 0.78
[Validation] Batch ID = 9890, loss = 0.108747, acc = 0.9
[Train] Batch ID = 9900, loss = 0.035039, acc = 1.0
[Validation] Batch ID = 9900, loss = 0.0791783, acc = 0.94
[Train] Batch ID = 9910, loss = 0.242656, acc = 0.72
[Validation] Batch ID = 9910, loss = 0.0469035, acc = 1.0
[Train] Batch ID = 9920, loss = 0.278609, acc = 0.66
[Validation] Batch ID = 9920, loss = 0.0769367, acc = 0.94
[Train] Batch ID = 9930, loss = 0.269497, acc = 0.68
[Validation] Batch ID = 9930, loss = 0.0846269, acc = 0.96
[Train] Batch ID = 9940, loss = 0.023544, acc = 1.0
[Validation] Batch ID = 9940, loss = 0.0624251, acc = 1.0
[Train] Batch ID = 9950, loss = 0.0249742, acc = 1.0
[Validation] Batch ID = 9950, loss = 0.074779, acc = 0.94
[Train] Batch ID = 9960, loss = 0.168816, acc = 0.9
[Validation] Batch ID = 9960, loss = 0.0835778, acc = 0.92
[Train] Batch ID = 9970, loss = 0.0314519, acc = 1.0
[Validation] Batch ID = 9970, loss = 0.0639506, acc = 1.0
[Train] Batch ID = 9980, loss = 0.26008, acc = 0.74
[Validation] Batch ID = 9980, loss = 0.0971057, acc = 0.94
[Train] Batch ID = 9990, loss = 0.214483, acc = 0.82
[Validation] Batch ID = 9990, loss = 0.0537682, acc = 0.98
[Train] Batch ID = 10000, loss = 0.274471, acc = 0.6
[Validation] Batch ID = 10000, loss = 0.0670121, acc = 0.92
Evaluate full validation dataset ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Saving model ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Current loss: 0.0658573 Best loss: 0.0730149
[TOTAL Validation] Batch ID = 10000, loss = 0.0658573, acc = 0.962585034014
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Model successfully saved here: outputs/checkpoints/c1s_9_c1n_256_c2s_6_c2n_64_c2d_0.7_c1vl_16_c1s_5_c1nf_16_c2vl_32_lr_0.0001_rs_1--TrafficSign--1510487290.423481
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Augmented Factor = 0.3106724901291001
[Train] Batch ID = 10010, loss = 0.0320103, acc = 1.0
[Validation] Batch ID = 10010, loss = 0.0582178, acc = 0.98
[Train] Batch ID = 10020, loss = 0.0450144, acc = 1.0
[Validation] Batch ID = 10020, loss = 0.0855528, acc = 0.94
[Train] Batch ID = 10030, loss = 0.235422, acc = 0.74
[Validation] Batch ID = 10030, loss = 0.0340095, acc = 1.0
[Train] Batch ID = 10040, loss = 0.0306786, acc = 1.0
[Validation] Batch ID = 10040, loss = 0.0542091, acc = 0.98
[Train] Batch ID = 10050, loss = 0.0256784, acc = 1.0
[Validation] Batch ID = 10050, loss = 0.0816129, acc = 0.94
[Train] Batch ID = 10060, loss = 0.0304254, acc = 1.0
[Validation] Batch ID = 10060, loss = 0.0498559, acc = 0.96
[Train] Batch ID = 10070, loss = 0.0401404, acc = 1.0
[Validation] Batch ID = 10070, loss = 0.0606166, acc = 0.98
[Train] Batch ID = 10080, loss = 0.220529, acc = 0.8
[Validation] Batch ID = 10080, loss = 0.0591235, acc = 0.94
[Train] Batch ID = 10090, loss = 0.303144, acc = 0.64
[Validation] Batch ID = 10090, loss = 0.0839164, acc = 0.94
[Train] Batch ID = 10100, loss = 0.029797, acc = 0.98
[Validation] Batch ID = 10100, loss = 0.0683755, acc = 0.96
[Train] Batch ID = 10110, loss = 0.298102, acc = 0.66
[Validation] Batch ID = 10110, loss = 0.0792787, acc = 0.94
[Train] Batch ID = 10120, loss = 0.0323543, acc = 0.98
[Validation] Batch ID = 10120, loss = 0.0470284, acc = 1.0
[Train] Batch ID = 10130, loss = 0.256514, acc = 0.66
[Validation] Batch ID = 10130, loss = 0.058399, acc = 0.96
[Train] Batch ID = 10140, loss = 0.227415, acc = 0.82
[Validation] Batch ID = 10140, loss = 0.100909, acc = 0.94
[Train] Batch ID = 10150, loss = 0.242073, acc = 0.78
[Validation] Batch ID = 10150, loss = 0.0646949, acc = 0.92
[Train] Batch ID = 10160, loss = 0.0168186, acc = 1.0
[Validation] Batch ID = 10160, loss = 0.0692419, acc = 0.96
[Train] Batch ID = 10170, loss = 0.0356441, acc = 0.98
[Validation] Batch ID = 10170, loss = 0.0699623, acc = 0.96
[Train] Batch ID = 10180, loss = 0.282366, acc = 0.72
[Validation] Batch ID = 10180, loss = 0.0572535, acc = 0.98
[Train] Batch ID = 10190, loss = 0.0248422, acc = 1.0
[Validation] Batch ID = 10190, loss = 0.0692116, acc = 0.96
[Train] Batch ID = 10200, loss = 0.278892, acc = 0.78
[Validation] Batch ID = 10200, loss = 0.0540336, acc = 1.0
[Train] Batch ID = 10210, loss = 0.0237627, acc = 1.0
[Validation] Batch ID = 10210, loss = 0.0644254, acc = 0.98
[Train] Batch ID = 10220, loss = 0.0241029, acc = 1.0
[Validation] Batch ID = 10220, loss = 0.0922657, acc = 0.94
[Train] Batch ID = 10230, loss = 0.026562, acc = 1.0
[Validation] Batch ID = 10230, loss = 0.0597336, acc = 0.96
[Train] Batch ID = 10240, loss = 0.264345, acc = 0.7
[Validation] Batch ID = 10240, loss = 0.0771023, acc = 0.92
[Train] Batch ID = 10250, loss = 0.0275423, acc = 1.0
[Validation] Batch ID = 10250, loss = 0.0515376, acc = 0.98
[Train] Batch ID = 10260, loss = 0.250938, acc = 0.8
[Validation] Batch ID = 10260, loss = 0.0622089, acc = 1.0
[Train] Batch ID = 10270, loss = 0.0225018, acc = 1.0
[Validation] Batch ID = 10270, loss = 0.0682326, acc = 0.96
[Train] Batch ID = 10280, loss = 0.0183854, acc = 1.0
[Validation] Batch ID = 10280, loss = 0.0475966, acc = 0.96
[Train] Batch ID = 10290, loss = 0.25077, acc = 0.66
[Validation] Batch ID = 10290, loss = 0.0811074, acc = 0.94
[Train] Batch ID = 10300, loss = 0.0211376, acc = 1.0
[Validation] Batch ID = 10300, loss = 0.0508417, acc = 0.98
[Train] Batch ID = 10310, loss = 0.0237568, acc = 1.0
[Validation] Batch ID = 10310, loss = 0.0620255, acc = 0.98
[Train] Batch ID = 10320, loss = 0.0204075, acc = 1.0
[Validation] Batch ID = 10320, loss = 0.0409982, acc = 1.0
[Train] Batch ID = 10330, loss = 0.0177919, acc = 1.0
[Validation] Batch ID = 10330, loss = 0.0908218, acc = 0.96
[Train] Batch ID = 10340, loss = 0.0187041, acc = 1.0
[Validation] Batch ID = 10340, loss = 0.0476373, acc = 0.98
[Train] Batch ID = 10350, loss = 0.0421181, acc = 1.0
[Validation] Batch ID = 10350, loss = 0.0492765, acc = 0.96
[Train] Batch ID = 10360, loss = 0.0227811, acc = 1.0
[Validation] Batch ID = 10360, loss = 0.0658845, acc = 0.96
[Train] Batch ID = 10370, loss = 0.0215271, acc = 1.0
[Validation] Batch ID = 10370, loss = 0.0639914, acc = 0.96
[Train] Batch ID = 10380, loss = 0.236647, acc = 0.68
[Validation] Batch ID = 10380, loss = 0.0652875, acc = 0.96
[Train] Batch ID = 10390, loss = 0.0212388, acc = 1.0
[Validation] Batch ID = 10390, loss = 0.0384328, acc = 1.0
[Train] Batch ID = 10400, loss = 0.0267373, acc = 1.0
[Validation] Batch ID = 10400, loss = 0.0580035, acc = 0.96
[Train] Batch ID = 10410, loss = 0.0239185, acc = 1.0
[Validation] Batch ID = 10410, loss = 0.0695637, acc = 0.94
[Train] Batch ID = 10420, loss = 0.0263768, acc = 1.0
[Validation] Batch ID = 10420, loss = 0.0573777, acc = 0.98
[Train] Batch ID = 10430, loss = 0.0202292, acc = 1.0
[Validation] Batch ID = 10430, loss = 0.0647551, acc = 0.98
[Train] Batch ID = 10440, loss = 0.231119, acc = 0.84
[Validation] Batch ID = 10440, loss = 0.0587589, acc = 0.94
[Train] Batch ID = 10450, loss = 0.211117, acc = 0.82
[Validation] Batch ID = 10450, loss = 0.0602316, acc = 0.96
[Train] Batch ID = 10460, loss = 0.0365114, acc = 0.98
[Validation] Batch ID = 10460, loss = 0.0701552, acc = 0.96
[Train] Batch ID = 10470, loss = 0.0223803, acc = 1.0
[Validation] Batch ID = 10470, loss = 0.0578071, acc = 0.96
[Train] Batch ID = 10480, loss = 0.0185824, acc = 1.0
[Validation] Batch ID = 10480, loss = 0.0366971, acc = 1.0
[Train] Batch ID = 10490, loss = 0.0293785, acc = 1.0
[Validation] Batch ID = 10490, loss = 0.0759896, acc = 0.96
[Train] Batch ID = 10500, loss = 0.0228463, acc = 1.0
[Validation] Batch ID = 10500, loss = 0.0360058, acc = 0.98
[Train] Batch ID = 10510, loss = 0.0202342, acc = 1.0
[Validation] Batch ID = 10510, loss = 0.0535699, acc = 0.98
[Train] Batch ID = 10520, loss = 0.241087, acc = 0.8
[Validation] Batch ID = 10520, loss = 0.0696521, acc = 0.94
[Train] Batch ID = 10530, loss = 0.0207031, acc = 1.0
[Validation] Batch ID = 10530, loss = 0.0942779, acc = 0.92
[Train] Batch ID = 10540, loss = 0.239436, acc = 0.7
[Validation] Batch ID = 10540, loss = 0.0320139, acc = 1.0
[Train] Batch ID = 10550, loss = 0.0280003, acc = 1.0
[Validation] Batch ID = 10550, loss = 0.0531046, acc = 0.96
[Train] Batch ID = 10560, loss = 0.0255739, acc = 1.0
[Validation] Batch ID = 10560, loss = 0.0985358, acc = 0.9
[Train] Batch ID = 10570, loss = 0.0332375, acc = 1.0
[Validation] Batch ID = 10570, loss = 0.0499371, acc = 1.0
[Train] Batch ID = 10580, loss = 0.262228, acc = 0.74
[Validation] Batch ID = 10580, loss = 0.0497987, acc = 0.98
[Train] Batch ID = 10590, loss = 0.0305478, acc = 1.0
[Validation] Batch ID = 10590, loss = 0.0663325, acc = 0.9
[Train] Batch ID = 10600, loss = 0.030163, acc = 1.0
[Validation] Batch ID = 10600, loss = 0.0508735, acc = 1.0
[Train] Batch ID = 10610, loss = 0.24278, acc = 0.74
[Validation] Batch ID = 10610, loss = 0.0471718, acc = 0.98
[Train] Batch ID = 10620, loss = 0.0338154, acc = 1.0
[Validation] Batch ID = 10620, loss = 0.0667417, acc = 0.94
[Train] Batch ID = 10630, loss = 0.02298, acc = 1.0
[Validation] Batch ID = 10630, loss = 0.0605788, acc = 0.96
[Train] Batch ID = 10640, loss = 0.23921, acc = 0.76
[Validation] Batch ID = 10640, loss = 0.0475721, acc = 0.98
[Train] Batch ID = 10650, loss = 0.228578, acc = 0.78
[Validation] Batch ID = 10650, loss = 0.0768908, acc = 0.94
[Train] Batch ID = 10660, loss = 0.266876, acc = 0.76
[Validation] Batch ID = 10660, loss = 0.0463165, acc = 1.0
[Train] Batch ID = 10670, loss = 0.0222616, acc = 1.0
[Validation] Batch ID = 10670, loss = 0.0809626, acc = 0.96
[Train] Batch ID = 10680, loss = 0.268812, acc = 0.66
[Validation] Batch ID = 10680, loss = 0.0948099, acc = 0.94
[Train] Batch ID = 10690, loss = 0.0326004, acc = 1.0
[Validation] Batch ID = 10690, loss = 0.0961061, acc = 0.94
[Train] Batch ID = 10700, loss = 0.206323, acc = 0.82
[Validation] Batch ID = 10700, loss = 0.0666905, acc = 0.98
[Train] Batch ID = 10710, loss = 0.0433316, acc = 0.98
[Validation] Batch ID = 10710, loss = 0.0655883, acc = 0.96
[Train] Batch ID = 10720, loss = 0.0220687, acc = 1.0
[Validation] Batch ID = 10720, loss = 0.0553731, acc = 0.98
[Train] Batch ID = 10730, loss = 0.028526, acc = 1.0
[Validation] Batch ID = 10730, loss = 0.0439219, acc = 0.98
[Train] Batch ID = 10740, loss = 0.0231754, acc = 1.0
[Validation] Batch ID = 10740, loss = 0.0821082, acc = 0.94
[Train] Batch ID = 10750, loss = 0.0290804, acc = 1.0
[Validation] Batch ID = 10750, loss = 0.0532277, acc = 0.96
[Train] Batch ID = 10760, loss = 0.0244261, acc = 1.0
[Validation] Batch ID = 10760, loss = 0.0606453, acc = 0.98
[Train] Batch ID = 10770, loss = 0.0230861, acc = 1.0
[Validation] Batch ID = 10770, loss = 0.0691229, acc = 0.96
[Train] Batch ID = 10780, loss = 0.0267517, acc = 1.0
[Validation] Batch ID = 10780, loss = 0.0531272, acc = 0.98
[Train] Batch ID = 10790, loss = 0.276305, acc = 0.7
[Validation] Batch ID = 10790, loss = 0.0818927, acc = 0.94
[Train] Batch ID = 10800, loss = 0.0255802, acc = 1.0
[Validation] Batch ID = 10800, loss = 0.0461357, acc = 1.0
[Train] Batch ID = 10810, loss = 0.277776, acc = 0.66
[Validation] Batch ID = 10810, loss = 0.0396541, acc = 1.0
[Train] Batch ID = 10820, loss = 0.0253764, acc = 1.0
[Validation] Batch ID = 10820, loss = 0.0725836, acc = 0.96
[Train] Batch ID = 10830, loss = 0.0273572, acc = 1.0
[Validation] Batch ID = 10830, loss = 0.0584495, acc = 0.94
[Train] Batch ID = 10840, loss = 0.0392492, acc = 0.98
[Validation] Batch ID = 10840, loss = 0.0794945, acc = 0.92
[Train] Batch ID = 10850, loss = 0.238792, acc = 0.78
[Validation] Batch ID = 10850, loss = 0.0578238, acc = 0.98
[Train] Batch ID = 10860, loss = 0.265717, acc = 0.7
[Validation] Batch ID = 10860, loss = 0.0693805, acc = 0.96
[Train] Batch ID = 10870, loss = 0.276501, acc = 0.74
[Validation] Batch ID = 10870, loss = 0.0530867, acc = 0.98
[Train] Batch ID = 10880, loss = 0.0315018, acc = 1.0
[Validation] Batch ID = 10880, loss = 0.0463138, acc = 0.98
[Train] Batch ID = 10890, loss = 0.0326479, acc = 1.0
[Validation] Batch ID = 10890, loss = 0.0606482, acc = 0.96
[Train] Batch ID = 10900, loss = 0.26162, acc = 0.8
[Validation] Batch ID = 10900, loss = 0.0488446, acc = 0.96
[Train] Batch ID = 10910, loss = 0.0307617, acc = 1.0
[Validation] Batch ID = 10910, loss = 0.0547645, acc = 0.98
[Train] Batch ID = 10920, loss = 0.247803, acc = 0.82
[Validation] Batch ID = 10920, loss = 0.0725425, acc = 0.94
[Train] Batch ID = 10930, loss = 0.0194928, acc = 1.0
[Validation] Batch ID = 10930, loss = 0.0892456, acc = 0.9
[Train] Batch ID = 10940, loss = 0.0240848, acc = 1.0
[Validation] Batch ID = 10940, loss = 0.0423664, acc = 0.98
[Train] Batch ID = 10950, loss = 0.026734, acc = 1.0
[Validation] Batch ID = 10950, loss = 0.0483184, acc = 0.98
[Train] Batch ID = 10960, loss = 0.0158559, acc = 1.0
[Validation] Batch ID = 10960, loss = 0.0472608, acc = 1.0
[Train] Batch ID = 10970, loss = 0.205094, acc = 0.82
[Validation] Batch ID = 10970, loss = 0.0575934, acc = 0.98
[Train] Batch ID = 10980, loss = 0.264071, acc = 0.76
[Validation] Batch ID = 10980, loss = 0.043741, acc = 0.98
[Train] Batch ID = 10990, loss = 0.231684, acc = 0.8
[Validation] Batch ID = 10990, loss = 0.0772302, acc = 0.96
[Train] Batch ID = 11000, loss = 0.0215243, acc = 1.0
[Validation] Batch ID = 11000, loss = 0.062636, acc = 0.98
Evaluate full validation dataset ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Saving model ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Current loss: 0.0642379 Best loss: 0.0658573
[TOTAL Validation] Batch ID = 11000, loss = 0.0642379, acc = 0.962358276644
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Model successfully saved here: outputs/checkpoints/c1s_9_c1n_256_c2s_6_c2n_64_c2d_0.7_c1vl_16_c1s_5_c1nf_16_c2vl_32_lr_0.0001_rs_1--TrafficSign--1510487290.423481
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Augmented Factor = 0.27960524111619006
[Train] Batch ID = 11010, loss = 0.0267694, acc = 1.0
[Validation] Batch ID = 11010, loss = 0.0556503, acc = 1.0
[Train] Batch ID = 11020, loss = 0.0217711, acc = 1.0
[Validation] Batch ID = 11020, loss = 0.0690887, acc = 0.96
[Train] Batch ID = 11030, loss = 0.0254033, acc = 1.0
[Validation] Batch ID = 11030, loss = 0.0602076, acc = 0.98
[Train] Batch ID = 11040, loss = 0.0288611, acc = 1.0
[Validation] Batch ID = 11040, loss = 0.0623529, acc = 0.94
[Train] Batch ID = 11050, loss = 0.0169745, acc = 1.0
[Validation] Batch ID = 11050, loss = 0.0533513, acc = 0.98
[Train] Batch ID = 11060, loss = 0.0206985, acc = 1.0
[Validation] Batch ID = 11060, loss = 0.103609, acc = 0.88
[Train] Batch ID = 11070, loss = 0.247159, acc = 0.7
[Validation] Batch ID = 11070, loss = 0.0802765, acc = 0.94
[Train] Batch ID = 11080, loss = 0.0180518, acc = 1.0
[Validation] Batch ID = 11080, loss = 0.0401566, acc = 1.0
[Train] Batch ID = 11090, loss = 0.0208967, acc = 1.0
[Validation] Batch ID = 11090, loss = 0.0481562, acc = 1.0
[Train] Batch ID = 11100, loss = 0.0282308, acc = 1.0
[Validation] Batch ID = 11100, loss = 0.066747, acc = 0.96
[Train] Batch ID = 11110, loss = 0.0142134, acc = 1.0
[Validation] Batch ID = 11110, loss = 0.060303, acc = 0.98
[Train] Batch ID = 11120, loss = 0.0330066, acc = 1.0
[Validation] Batch ID = 11120, loss = 0.0512098, acc = 0.98
[Train] Batch ID = 11130, loss = 0.221467, acc = 0.76
[Validation] Batch ID = 11130, loss = 0.0534645, acc = 0.94
[Train] Batch ID = 11140, loss = 0.0206463, acc = 1.0
[Validation] Batch ID = 11140, loss = 0.0546583, acc = 0.96
[Train] Batch ID = 11150, loss = 0.0224343, acc = 1.0
[Validation] Batch ID = 11150, loss = 0.0424858, acc = 0.98
[Train] Batch ID = 11160, loss = 0.0182185, acc = 1.0
[Validation] Batch ID = 11160, loss = 0.0769991, acc = 0.94
[Train] Batch ID = 11170, loss = 0.0209055, acc = 1.0
[Validation] Batch ID = 11170, loss = 0.0540576, acc = 0.98
[Train] Batch ID = 11180, loss = 0.21547, acc = 0.8
[Validation] Batch ID = 11180, loss = 0.0622383, acc = 0.96
[Train] Batch ID = 11190, loss = 0.279556, acc = 0.68
[Validation] Batch ID = 11190, loss = 0.0611318, acc = 1.0
[Train] Batch ID = 11200, loss = 0.264039, acc = 0.7
[Validation] Batch ID = 11200, loss = 0.0421947, acc = 0.96
[Train] Batch ID = 11210, loss = 0.227376, acc = 0.76
[Validation] Batch ID = 11210, loss = 0.0707872, acc = 0.94
[Train] Batch ID = 11220, loss = 0.0266948, acc = 1.0
[Validation] Batch ID = 11220, loss = 0.0633356, acc = 0.96
[Train] Batch ID = 11230, loss = 0.0189968, acc = 1.0
[Validation] Batch ID = 11230, loss = 0.0372418, acc = 1.0
[Train] Batch ID = 11240, loss = 0.208902, acc = 0.82
[Validation] Batch ID = 11240, loss = 0.0542227, acc = 0.94
[Train] Batch ID = 11250, loss = 0.279762, acc = 0.72
[Validation] Batch ID = 11250, loss = 0.0724756, acc = 0.98
[Train] Batch ID = 11260, loss = 0.0232968, acc = 1.0
[Validation] Batch ID = 11260, loss = 0.0469706, acc = 0.98
[Train] Batch ID = 11270, loss = 0.0245158, acc = 0.98
[Validation] Batch ID = 11270, loss = 0.0559607, acc = 0.98
[Train] Batch ID = 11280, loss = 0.022519, acc = 1.0
[Validation] Batch ID = 11280, loss = 0.0612133, acc = 0.94
[Train] Batch ID = 11290, loss = 0.0184895, acc = 1.0
[Validation] Batch ID = 11290, loss = 0.0725897, acc = 0.96
[Train] Batch ID = 11300, loss = 0.0263891, acc = 1.0
[Validation] Batch ID = 11300, loss = 0.0770264, acc = 0.94
[Train] Batch ID = 11310, loss = 0.248416, acc = 0.82
[Validation] Batch ID = 11310, loss = 0.0448853, acc = 0.98
[Train] Batch ID = 11320, loss = 0.0203326, acc = 1.0
[Validation] Batch ID = 11320, loss = 0.0716016, acc = 0.96
[Train] Batch ID = 11330, loss = 0.0204678, acc = 1.0
[Validation] Batch ID = 11330, loss = 0.0672783, acc = 0.96
[Train] Batch ID = 11340, loss = 0.0230403, acc = 1.0
[Validation] Batch ID = 11340, loss = 0.0605401, acc = 0.96
[Train] Batch ID = 11350, loss = 0.0168155, acc = 1.0
[Validation] Batch ID = 11350, loss = 0.0570144, acc = 0.98
[Train] Batch ID = 11360, loss = 0.0168029, acc = 1.0
[Validation] Batch ID = 11360, loss = 0.0485947, acc = 0.98
[Train] Batch ID = 11370, loss = 0.0214255, acc = 1.0
[Validation] Batch ID = 11370, loss = 0.0300471, acc = 1.0
[Train] Batch ID = 11380, loss = 0.019337, acc = 1.0
[Validation] Batch ID = 11380, loss = 0.0332955, acc = 0.98
[Train] Batch ID = 11390, loss = 0.0186135, acc = 1.0
[Validation] Batch ID = 11390, loss = 0.0336652, acc = 1.0
[Train] Batch ID = 11400, loss = 0.0222454, acc = 1.0
[Validation] Batch ID = 11400, loss = 0.047642, acc = 0.96
[Train] Batch ID = 11410, loss = 0.240664, acc = 0.78
[Validation] Batch ID = 11410, loss = 0.044068, acc = 1.0
[Train] Batch ID = 11420, loss = 0.024854, acc = 1.0
[Validation] Batch ID = 11420, loss = 0.0512275, acc = 0.96
[Train] Batch ID = 11430, loss = 0.02464, acc = 1.0
[Validation] Batch ID = 11430, loss = 0.0536726, acc = 1.0
[Train] Batch ID = 11440, loss = 0.304124, acc = 0.64
[Validation] Batch ID = 11440, loss = 0.0910591, acc = 0.94
[Train] Batch ID = 11450, loss = 0.0298229, acc = 1.0
[Validation] Batch ID = 11450, loss = 0.0713518, acc = 0.96
[Train] Batch ID = 11460, loss = 0.0169659, acc = 1.0
[Validation] Batch ID = 11460, loss = 0.0532484, acc = 0.96
[Train] Batch ID = 11470, loss = 0.0264341, acc = 1.0
[Validation] Batch ID = 11470, loss = 0.059095, acc = 0.96
[Train] Batch ID = 11480, loss = 0.0269898, acc = 1.0
[Validation] Batch ID = 11480, loss = 0.0397406, acc = 1.0
[Train] Batch ID = 11490, loss = 0.263662, acc = 0.8
[Validation] Batch ID = 11490, loss = 0.0367855, acc = 1.0
[Train] Batch ID = 11500, loss = 0.0221311, acc = 1.0
[Validation] Batch ID = 11500, loss = 0.0511719, acc = 0.96
[Train] Batch ID = 11510, loss = 0.0260992, acc = 1.0
[Validation] Batch ID = 11510, loss = 0.0683123, acc = 0.94
[Train] Batch ID = 11520, loss = 0.156699, acc = 0.86
[Validation] Batch ID = 11520, loss = 0.0327754, acc = 1.0
[Train] Batch ID = 11530, loss = 0.0276286, acc = 1.0
[Validation] Batch ID = 11530, loss = 0.0554999, acc = 0.98
[Train] Batch ID = 11540, loss = 0.0279818, acc = 0.98
[Validation] Batch ID = 11540, loss = 0.0558727, acc = 0.96
[Train] Batch ID = 11550, loss = 0.0203168, acc = 1.0
[Validation] Batch ID = 11550, loss = 0.0595857, acc = 0.98
[Train] Batch ID = 11560, loss = 0.243685, acc = 0.72
[Validation] Batch ID = 11560, loss = 0.0776727, acc = 0.96
[Train] Batch ID = 11570, loss = 0.0195478, acc = 1.0
[Validation] Batch ID = 11570, loss = 0.059287, acc = 1.0
[Train] Batch ID = 11580, loss = 0.0282897, acc = 1.0
[Validation] Batch ID = 11580, loss = 0.0514211, acc = 0.98
[Train] Batch ID = 11590, loss = 0.26324, acc = 0.74
[Validation] Batch ID = 11590, loss = 0.051008, acc = 0.98
[Train] Batch ID = 11600, loss = 0.1979, acc = 0.9
[Validation] Batch ID = 11600, loss = 0.0488026, acc = 0.98
[Train] Batch ID = 11610, loss = 0.0204028, acc = 1.0
[Validation] Batch ID = 11610, loss = 0.0243663, acc = 1.0
[Train] Batch ID = 11620, loss = 0.22677, acc = 0.8
[Validation] Batch ID = 11620, loss = 0.0364276, acc = 1.0
[Train] Batch ID = 11630, loss = 0.222716, acc = 0.8
[Validation] Batch ID = 11630, loss = 0.0447018, acc = 0.96
[Train] Batch ID = 11640, loss = 0.237172, acc = 0.8
[Validation] Batch ID = 11640, loss = 0.0618803, acc = 0.94
[Train] Batch ID = 11650, loss = 0.0205765, acc = 1.0
[Validation] Batch ID = 11650, loss = 0.0464388, acc = 0.98
[Train] Batch ID = 11660, loss = 0.0260963, acc = 1.0
[Validation] Batch ID = 11660, loss = 0.0396439, acc = 1.0
[Train] Batch ID = 11670, loss = 0.0228697, acc = 1.0
[Validation] Batch ID = 11670, loss = 0.0584696, acc = 0.96
[Train] Batch ID = 11680, loss = 0.0150385, acc = 1.0
[Validation] Batch ID = 11680, loss = 0.0337174, acc = 1.0
[Train] Batch ID = 11690, loss = 0.229641, acc = 0.8
[Validation] Batch ID = 11690, loss = 0.0553332, acc = 0.98
[Train] Batch ID = 11700, loss = 0.0213425, acc = 1.0
[Validation] Batch ID = 11700, loss = 0.0855538, acc = 0.9
[Train] Batch ID = 11710, loss = 0.025438, acc = 1.0
[Validation] Batch ID = 11710, loss = 0.0836318, acc = 0.94
[Train] Batch ID = 11720, loss = 0.0210915, acc = 1.0
[Validation] Batch ID = 11720, loss = 0.040622, acc = 0.96
[Train] Batch ID = 11730, loss = 0.0208527, acc = 1.0
[Validation] Batch ID = 11730, loss = 0.0755471, acc = 0.96
[Train] Batch ID = 11740, loss = 0.0155891, acc = 1.0
[Validation] Batch ID = 11740, loss = 0.0583596, acc = 0.98
[Train] Batch ID = 11750, loss = 0.0262852, acc = 1.0
[Validation] Batch ID = 11750, loss = 0.0363462, acc = 1.0
[Train] Batch ID = 11760, loss = 0.0155518, acc = 1.0
[Validation] Batch ID = 11760, loss = 0.0515345, acc = 0.96
[Train] Batch ID = 11770, loss = 0.0151247, acc = 1.0
[Validation] Batch ID = 11770, loss = 0.0697787, acc = 0.94
[Train] Batch ID = 11780, loss = 0.260807, acc = 0.74
[Validation] Batch ID = 11780, loss = 0.0446781, acc = 0.98
[Train] Batch ID = 11790, loss = 0.0332718, acc = 1.0
[Validation] Batch ID = 11790, loss = 0.0556415, acc = 0.98
[Train] Batch ID = 11800, loss = 0.0186326, acc = 1.0
[Validation] Batch ID = 11800, loss = 0.0702373, acc = 0.94
[Train] Batch ID = 11810, loss = 0.0248306, acc = 1.0
[Validation] Batch ID = 11810, loss = 0.0892354, acc = 0.92
[Train] Batch ID = 11820, loss = 0.0121163, acc = 1.0
[Validation] Batch ID = 11820, loss = 0.0395371, acc = 0.98
[Train] Batch ID = 11830, loss = 0.0199083, acc = 1.0
[Validation] Batch ID = 11830, loss = 0.0485425, acc = 0.98
[Train] Batch ID = 11840, loss = 0.211462, acc = 0.8
[Validation] Batch ID = 11840, loss = 0.0591463, acc = 0.96
[Train] Batch ID = 11850, loss = 0.0233504, acc = 1.0
[Validation] Batch ID = 11850, loss = 0.0383064, acc = 1.0
[Train] Batch ID = 11860, loss = 0.0284902, acc = 1.0
[Validation] Batch ID = 11860, loss = 0.0395091, acc = 0.98
[Train] Batch ID = 11870, loss = 0.0270664, acc = 1.0
[Validation] Batch ID = 11870, loss = 0.0797209, acc = 0.92
[Train] Batch ID = 11880, loss = 0.0183816, acc = 1.0
[Validation] Batch ID = 11880, loss = 0.057735, acc = 0.96
[Train] Batch ID = 11890, loss = 0.0153038, acc = 1.0
[Validation] Batch ID = 11890, loss = 0.0649975, acc = 0.96
[Train] Batch ID = 11900, loss = 0.0239744, acc = 1.0
[Validation] Batch ID = 11900, loss = 0.0714888, acc = 0.94
[Train] Batch ID = 11910, loss = 0.208503, acc = 0.86
[Validation] Batch ID = 11910, loss = 0.0766505, acc = 0.96
[Train] Batch ID = 11920, loss = 0.0176045, acc = 1.0
[Validation] Batch ID = 11920, loss = 0.0728248, acc = 0.94
[Train] Batch ID = 11930, loss = 0.0152934, acc = 1.0
[Validation] Batch ID = 11930, loss = 0.0674915, acc = 0.96
[Train] Batch ID = 11940, loss = 0.021132, acc = 1.0
[Validation] Batch ID = 11940, loss = 0.0491492, acc = 0.98
[Train] Batch ID = 11950, loss = 0.0164855, acc = 1.0
[Validation] Batch ID = 11950, loss = 0.0534265, acc = 0.98
[Train] Batch ID = 11960, loss = 0.0180065, acc = 1.0
[Validation] Batch ID = 11960, loss = 0.0387668, acc = 0.98
[Train] Batch ID = 11970, loss = 0.0178865, acc = 1.0
[Validation] Batch ID = 11970, loss = 0.0348324, acc = 1.0
[Train] Batch ID = 11980, loss = 0.0172653, acc = 1.0
[Validation] Batch ID = 11980, loss = 0.0583721, acc = 0.96
[Train] Batch ID = 11990, loss = 0.215337, acc = 0.78
[Validation] Batch ID = 11990, loss = 0.0599743, acc = 0.96
[Train] Batch ID = 12000, loss = 0.0225344, acc = 1.0
[Validation] Batch ID = 12000, loss = 0.0570171, acc = 0.94
Evaluate full validation dataset ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Saving model ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Current loss: 0.0569155 Best loss: 0.0642379
[TOTAL Validation] Batch ID = 12000, loss = 0.0569155, acc = 0.965079365079
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Model successfully saved here: outputs/checkpoints/c1s_9_c1n_256_c2s_6_c2n_64_c2d_0.7_c1vl_16_c1s_5_c1nf_16_c2vl_32_lr_0.0001_rs_1--TrafficSign--1510487290.423481
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Augmented Factor = 0.2516447170045711
[Train] Batch ID = 12010, loss = 0.0175699, acc = 1.0
[Validation] Batch ID = 12010, loss = 0.0805498, acc = 0.9
[Train] Batch ID = 12020, loss = 0.0187703, acc = 1.0
[Validation] Batch ID = 12020, loss = 0.0750015, acc = 0.94
[Train] Batch ID = 12030, loss = 0.237082, acc = 0.74
[Validation] Batch ID = 12030, loss = 0.0509484, acc = 0.98
[Train] Batch ID = 12040, loss = 0.0222357, acc = 0.98
[Validation] Batch ID = 12040, loss = 0.0532786, acc = 0.96
[Train] Batch ID = 12050, loss = 0.0280928, acc = 1.0
[Validation] Batch ID = 12050, loss = 0.0322465, acc = 1.0
[Train] Batch ID = 12060, loss = 0.0143398, acc = 1.0
[Validation] Batch ID = 12060, loss = 0.0668205, acc = 0.94
[Train] Batch ID = 12070, loss = 0.272467, acc = 0.7
[Validation] Batch ID = 12070, loss = 0.0475622, acc = 0.98
[Train] Batch ID = 12080, loss = 0.0184628, acc = 1.0
[Validation] Batch ID = 12080, loss = 0.0570092, acc = 1.0
[Train] Batch ID = 12090, loss = 0.0127859, acc = 1.0
[Validation] Batch ID = 12090, loss = 0.0804392, acc = 0.92
[Train] Batch ID = 12100, loss = 0.18276, acc = 0.86
[Validation] Batch ID = 12100, loss = 0.0356991, acc = 1.0
[Train] Batch ID = 12110, loss = 0.277591, acc = 0.8
[Validation] Batch ID = 12110, loss = 0.055326, acc = 0.96
[Train] Batch ID = 12120, loss = 0.0205694, acc = 1.0
[Validation] Batch ID = 12120, loss = 0.0441424, acc = 0.98
[Train] Batch ID = 12130, loss = 0.0172047, acc = 1.0
[Validation] Batch ID = 12130, loss = 0.04899, acc = 0.98
[Train] Batch ID = 12140, loss = 0.0166822, acc = 1.0
[Validation] Batch ID = 12140, loss = 0.0585138, acc = 0.98
[Train] Batch ID = 12150, loss = 0.0259027, acc = 1.0
[Validation] Batch ID = 12150, loss = 0.0286029, acc = 1.0
[Train] Batch ID = 12160, loss = 0.0213891, acc = 1.0
[Validation] Batch ID = 12160, loss = 0.0259512, acc = 1.0
[Train] Batch ID = 12170, loss = 0.275487, acc = 0.68
[Validation] Batch ID = 12170, loss = 0.0449011, acc = 1.0
[Train] Batch ID = 12180, loss = 0.020905, acc = 1.0
[Validation] Batch ID = 12180, loss = 0.0577991, acc = 0.96
[Train] Batch ID = 12190, loss = 0.229737, acc = 0.8
[Validation] Batch ID = 12190, loss = 0.0752094, acc = 0.92
[Train] Batch ID = 12200, loss = 0.0151092, acc = 1.0
[Validation] Batch ID = 12200, loss = 0.0530333, acc = 0.96
[Train] Batch ID = 12210, loss = 0.0186947, acc = 1.0
[Validation] Batch ID = 12210, loss = 0.0454375, acc = 0.98
[Train] Batch ID = 12220, loss = 0.018811, acc = 1.0
[Validation] Batch ID = 12220, loss = 0.0633392, acc = 0.98
[Train] Batch ID = 12230, loss = 0.0143414, acc = 1.0
[Validation] Batch ID = 12230, loss = 0.0604351, acc = 0.94
[Train] Batch ID = 12240, loss = 0.0132596, acc = 1.0
[Validation] Batch ID = 12240, loss = 0.065626, acc = 0.96
[Train] Batch ID = 12250, loss = 0.017905, acc = 1.0
[Validation] Batch ID = 12250, loss = 0.0401788, acc = 0.98
[Train] Batch ID = 12260, loss = 0.0179461, acc = 1.0
[Validation] Batch ID = 12260, loss = 0.0729683, acc = 0.94
[Train] Batch ID = 12270, loss = 0.0241501, acc = 1.0
[Validation] Batch ID = 12270, loss = 0.0314491, acc = 1.0
[Train] Batch ID = 12280, loss = 0.0146913, acc = 1.0
[Validation] Batch ID = 12280, loss = 0.0394414, acc = 1.0
[Train] Batch ID = 12290, loss = 0.251798, acc = 0.74
[Validation] Batch ID = 12290, loss = 0.0691592, acc = 0.94
[Train] Batch ID = 12300, loss = 0.20632, acc = 0.84
[Validation] Batch ID = 12300, loss = 0.0488044, acc = 0.98
[Train] Batch ID = 12310, loss = 0.0212661, acc = 1.0
[Validation] Batch ID = 12310, loss = 0.0451895, acc = 1.0
[Train] Batch ID = 12320, loss = 0.013328, acc = 1.0
[Validation] Batch ID = 12320, loss = 0.0474859, acc = 0.96
[Train] Batch ID = 12330, loss = 0.0136651, acc = 1.0
[Validation] Batch ID = 12330, loss = 0.0702339, acc = 0.96
[Train] Batch ID = 12340, loss = 0.0207825, acc = 1.0
[Validation] Batch ID = 12340, loss = 0.051839, acc = 0.98
[Train] Batch ID = 12350, loss = 0.235806, acc = 0.78
[Validation] Batch ID = 12350, loss = 0.0663938, acc = 0.94
[Train] Batch ID = 12360, loss = 0.0137588, acc = 1.0
[Validation] Batch ID = 12360, loss = 0.0503481, acc = 0.98
[Train] Batch ID = 12370, loss = 0.0154034, acc = 1.0
[Validation] Batch ID = 12370, loss = 0.0560214, acc = 1.0
[Train] Batch ID = 12380, loss = 0.230688, acc = 0.78
[Validation] Batch ID = 12380, loss = 0.0296935, acc = 1.0
[Train] Batch ID = 12390, loss = 0.016916, acc = 1.0
[Validation] Batch ID = 12390, loss = 0.0606704, acc = 0.96
[Train] Batch ID = 12400, loss = 0.252902, acc = 0.68
[Validation] Batch ID = 12400, loss = 0.0405749, acc = 0.96
[Train] Batch ID = 12410, loss = 0.0149221, acc = 1.0
[Validation] Batch ID = 12410, loss = 0.0558207, acc = 0.98
[Train] Batch ID = 12420, loss = 0.02062, acc = 1.0
[Validation] Batch ID = 12420, loss = 0.0549722, acc = 0.96
[Train] Batch ID = 12430, loss = 0.0227042, acc = 1.0
[Validation] Batch ID = 12430, loss = 0.033422, acc = 0.98
[Train] Batch ID = 12440, loss = 0.237517, acc = 0.76
[Validation] Batch ID = 12440, loss = 0.0466941, acc = 0.96
[Train] Batch ID = 12450, loss = 0.251597, acc = 0.78
[Validation] Batch ID = 12450, loss = 0.0341947, acc = 0.98
[Train] Batch ID = 12460, loss = 0.0171734, acc = 1.0
[Validation] Batch ID = 12460, loss = 0.0566749, acc = 0.96
[Train] Batch ID = 12470, loss = 0.247218, acc = 0.74
[Validation] Batch ID = 12470, loss = 0.057287, acc = 0.98
[Train] Batch ID = 12480, loss = 0.0161513, acc = 1.0
[Validation] Batch ID = 12480, loss = 0.0588566, acc = 0.94
[Train] Batch ID = 12490, loss = 0.0166393, acc = 1.0
[Validation] Batch ID = 12490, loss = 0.0538727, acc = 0.96
[Train] Batch ID = 12500, loss = 0.0267865, acc = 1.0
[Validation] Batch ID = 12500, loss = 0.0373445, acc = 0.98
[Train] Batch ID = 12510, loss = 0.248985, acc = 0.74
[Validation] Batch ID = 12510, loss = 0.0811959, acc = 0.94
[Train] Batch ID = 12520, loss = 0.0314585, acc = 0.96
[Validation] Batch ID = 12520, loss = 0.0268699, acc = 0.98
[Train] Batch ID = 12530, loss = 0.02123, acc = 1.0
[Validation] Batch ID = 12530, loss = 0.0582334, acc = 0.96
[Train] Batch ID = 12540, loss = 0.0195878, acc = 1.0
[Validation] Batch ID = 12540, loss = 0.0381922, acc = 0.98
[Train] Batch ID = 12550, loss = 0.238293, acc = 0.74
[Validation] Batch ID = 12550, loss = 0.0413543, acc = 0.98
[Train] Batch ID = 12560, loss = 0.0141016, acc = 1.0
[Validation] Batch ID = 12560, loss = 0.0573876, acc = 0.98
[Train] Batch ID = 12570, loss = 0.0228829, acc = 1.0
[Validation] Batch ID = 12570, loss = 0.0325435, acc = 0.98
[Train] Batch ID = 12580, loss = 0.0326469, acc = 1.0
[Validation] Batch ID = 12580, loss = 0.0349488, acc = 0.98
[Train] Batch ID = 12590, loss = 0.0187995, acc = 1.0
[Validation] Batch ID = 12590, loss = 0.0724595, acc = 0.98
[Train] Batch ID = 12600, loss = 0.241252, acc = 0.86
[Validation] Batch ID = 12600, loss = 0.031216, acc = 1.0
[Train] Batch ID = 12610, loss = 0.0159245, acc = 1.0
[Validation] Batch ID = 12610, loss = 0.0598384, acc = 0.96
[Train] Batch ID = 12620, loss = 0.0166101, acc = 1.0
[Validation] Batch ID = 12620, loss = 0.0435974, acc = 1.0
[Train] Batch ID = 12630, loss = 0.0220705, acc = 1.0
[Validation] Batch ID = 12630, loss = 0.0619918, acc = 0.94
[Train] Batch ID = 12640, loss = 0.0209025, acc = 1.0
[Validation] Batch ID = 12640, loss = 0.0505198, acc = 0.96
[Train] Batch ID = 12650, loss = 0.233334, acc = 0.76
[Validation] Batch ID = 12650, loss = 0.0463609, acc = 0.98
[Train] Batch ID = 12660, loss = 0.0249046, acc = 1.0
[Validation] Batch ID = 12660, loss = 0.0528342, acc = 0.96
[Train] Batch ID = 12670, loss = 0.271484, acc = 0.68
[Validation] Batch ID = 12670, loss = 0.0234601, acc = 1.0
[Train] Batch ID = 12680, loss = 0.0153836, acc = 1.0
[Validation] Batch ID = 12680, loss = 0.0680249, acc = 0.96
[Train] Batch ID = 12690, loss = 0.021112, acc = 1.0
[Validation] Batch ID = 12690, loss = 0.0615473, acc = 0.94
[Train] Batch ID = 12700, loss = 0.228721, acc = 0.86
[Validation] Batch ID = 12700, loss = 0.0463136, acc = 0.96
[Train] Batch ID = 12710, loss = 0.265453, acc = 0.76
[Validation] Batch ID = 12710, loss = 0.0561977, acc = 0.96
[Train] Batch ID = 12720, loss = 0.0230482, acc = 1.0
[Validation] Batch ID = 12720, loss = 0.0546143, acc = 1.0
[Train] Batch ID = 12730, loss = 0.0230284, acc = 1.0
[Validation] Batch ID = 12730, loss = 0.0410447, acc = 0.98
[Train] Batch ID = 12740, loss = 0.240681, acc = 0.74
[Validation] Batch ID = 12740, loss = 0.0481054, acc = 0.98
[Train] Batch ID = 12750, loss = 0.24796, acc = 0.78
[Validation] Batch ID = 12750, loss = 0.0576588, acc = 0.96
[Train] Batch ID = 12760, loss = 0.275701, acc = 0.68
[Validation] Batch ID = 12760, loss = 0.0515709, acc = 0.96
[Train] Batch ID = 12770, loss = 0.0223249, acc = 1.0
[Validation] Batch ID = 12770, loss = 0.0472653, acc = 0.98
[Train] Batch ID = 12780, loss = 0.285133, acc = 0.7
[Validation] Batch ID = 12780, loss = 0.0662981, acc = 0.94
[Train] Batch ID = 12790, loss = 0.192709, acc = 0.86
[Validation] Batch ID = 12790, loss = 0.0702019, acc = 0.96
[Train] Batch ID = 12800, loss = 0.0251002, acc = 1.0
[Validation] Batch ID = 12800, loss = 0.0415289, acc = 0.98
[Train] Batch ID = 12810, loss = 0.241417, acc = 0.72
[Validation] Batch ID = 12810, loss = 0.0702363, acc = 0.96
[Train] Batch ID = 12820, loss = 0.0165064, acc = 1.0
[Validation] Batch ID = 12820, loss = 0.0481134, acc = 1.0
[Train] Batch ID = 12830, loss = 0.282329, acc = 0.7
[Validation] Batch ID = 12830, loss = 0.0701857, acc = 0.96
[Train] Batch ID = 12840, loss = 0.0139216, acc = 1.0
[Validation] Batch ID = 12840, loss = 0.0834343, acc = 0.92
[Train] Batch ID = 12850, loss = 0.0179657, acc = 1.0
[Validation] Batch ID = 12850, loss = 0.0437821, acc = 0.96
[Train] Batch ID = 12860, loss = 0.0256352, acc = 1.0
[Validation] Batch ID = 12860, loss = 0.0782957, acc = 0.9
[Train] Batch ID = 12870, loss = 0.0199623, acc = 1.0
[Validation] Batch ID = 12870, loss = 0.0621775, acc = 0.94
[Train] Batch ID = 12880, loss = 0.0125086, acc = 1.0
[Validation] Batch ID = 12880, loss = 0.0589617, acc = 0.96
[Train] Batch ID = 12890, loss = 0.0175682, acc = 1.0
[Validation] Batch ID = 12890, loss = 0.0675731, acc = 0.92
[Train] Batch ID = 12900, loss = 0.0237742, acc = 1.0
[Validation] Batch ID = 12900, loss = 0.0449194, acc = 0.96
[Train] Batch ID = 12910, loss = 0.0175294, acc = 1.0
[Validation] Batch ID = 12910, loss = 0.0533717, acc = 0.96
[Train] Batch ID = 12920, loss = 0.0209649, acc = 1.0
[Validation] Batch ID = 12920, loss = 0.0416077, acc = 1.0
[Train] Batch ID = 12930, loss = 0.0152044, acc = 1.0
[Validation] Batch ID = 12930, loss = 0.0572876, acc = 0.98
[Train] Batch ID = 12940, loss = 0.022147, acc = 0.98
[Validation] Batch ID = 12940, loss = 0.0417758, acc = 1.0
[Train] Batch ID = 12950, loss = 0.0154079, acc = 1.0
[Validation] Batch ID = 12950, loss = 0.0516375, acc = 0.96
[Train] Batch ID = 12960, loss = 0.0182955, acc = 1.0
[Validation] Batch ID = 12960, loss = 0.0656333, acc = 0.92
[Train] Batch ID = 12970, loss = 0.0163364, acc = 1.0
[Validation] Batch ID = 12970, loss = 0.0401941, acc = 0.98
[Train] Batch ID = 12980, loss = 0.220062, acc = 0.8
[Validation] Batch ID = 12980, loss = 0.033187, acc = 1.0
[Train] Batch ID = 12990, loss = 0.244467, acc = 0.78
[Validation] Batch ID = 12990, loss = 0.0490043, acc = 0.98
[Train] Batch ID = 13000, loss = 0.0107988, acc = 1.0
[Validation] Batch ID = 13000, loss = 0.0635478, acc = 0.98
Evaluate full validation dataset ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Saving model ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Current loss: 0.0540795 Best loss: 0.0569155
[TOTAL Validation] Batch ID = 13000, loss = 0.0540795, acc = 0.966213151927
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Model successfully saved here: outputs/checkpoints/c1s_9_c1n_256_c2s_6_c2n_64_c2d_0.7_c1vl_16_c1s_5_c1nf_16_c2vl_32_lr_0.0001_rs_1--TrafficSign--1510487290.423481
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Augmented Factor = 0.22648024530411398
[Train] Batch ID = 13010, loss = 0.0217956, acc = 1.0
[Validation] Batch ID = 13010, loss = 0.0555536, acc = 0.96
[Train] Batch ID = 13020, loss = 0.0128282, acc = 1.0
[Validation] Batch ID = 13020, loss = 0.060201, acc = 0.96
[Train] Batch ID = 13030, loss = 0.0110627, acc = 1.0
[Validation] Batch ID = 13030, loss = 0.0406832, acc = 0.94
[Train] Batch ID = 13040, loss = 0.013509, acc = 1.0
[Validation] Batch ID = 13040, loss = 0.0389228, acc = 0.98
[Train] Batch ID = 13050, loss = 0.01269, acc = 1.0
[Validation] Batch ID = 13050, loss = 0.069461, acc = 0.96
[Train] Batch ID = 13060, loss = 0.0208766, acc = 1.0
[Validation] Batch ID = 13060, loss = 0.0602078, acc = 0.94
[Train] Batch ID = 13070, loss = 0.0181481, acc = 1.0
[Validation] Batch ID = 13070, loss = 0.0515454, acc = 0.96
[Train] Batch ID = 13080, loss = 0.245159, acc = 0.74
[Validation] Batch ID = 13080, loss = 0.0463636, acc = 1.0
[Train] Batch ID = 13090, loss = 0.021373, acc = 1.0
[Validation] Batch ID = 13090, loss = 0.0791642, acc = 0.92
[Train] Batch ID = 13100, loss = 0.256569, acc = 0.7
[Validation] Batch ID = 13100, loss = 0.0419138, acc = 0.98
[Train] Batch ID = 13110, loss = 0.244184, acc = 0.78
[Validation] Batch ID = 13110, loss = 0.0339549, acc = 1.0
[Train] Batch ID = 13120, loss = 0.0129958, acc = 1.0
[Validation] Batch ID = 13120, loss = 0.0584424, acc = 0.98
[Train] Batch ID = 13130, loss = 0.0185103, acc = 1.0
[Validation] Batch ID = 13130, loss = 0.0761853, acc = 0.96
[Train] Batch ID = 13140, loss = 0.0169928, acc = 1.0
[Validation] Batch ID = 13140, loss = 0.0376334, acc = 0.98
[Train] Batch ID = 13150, loss = 0.223224, acc = 0.78
[Validation] Batch ID = 13150, loss = 0.0791546, acc = 0.9
[Train] Batch ID = 13160, loss = 0.00994549, acc = 1.0
[Validation] Batch ID = 13160, loss = 0.0492361, acc = 0.98
[Train] Batch ID = 13170, loss = 0.0140954, acc = 1.0
[Validation] Batch ID = 13170, loss = 0.0714803, acc = 0.92
[Train] Batch ID = 13180, loss = 0.205359, acc = 0.94
[Validation] Batch ID = 13180, loss = 0.0699719, acc = 0.96
[Train] Batch ID = 13190, loss = 0.253633, acc = 0.72
[Validation] Batch ID = 13190, loss = 0.0387252, acc = 0.98
[Train] Batch ID = 13200, loss = 0.0197266, acc = 1.0
[Validation] Batch ID = 13200, loss = 0.0349778, acc = 1.0
[Train] Batch ID = 13210, loss = 0.0203485, acc = 1.0
[Validation] Batch ID = 13210, loss = 0.0588877, acc = 0.98
[Train] Batch ID = 13220, loss = 0.0187013, acc = 1.0
[Validation] Batch ID = 13220, loss = 0.0285849, acc = 1.0
[Train] Batch ID = 13230, loss = 0.0174957, acc = 1.0
[Validation] Batch ID = 13230, loss = 0.0430944, acc = 0.98
[Train] Batch ID = 13240, loss = 0.0122792, acc = 1.0
[Validation] Batch ID = 13240, loss = 0.0546641, acc = 0.96
[Train] Batch ID = 13250, loss = 0.0116748, acc = 1.0
[Validation] Batch ID = 13250, loss = 0.0496791, acc = 0.98
[Train] Batch ID = 13260, loss = 0.242589, acc = 0.82
[Validation] Batch ID = 13260, loss = 0.0381083, acc = 1.0
[Train] Batch ID = 13270, loss = 0.00838318, acc = 1.0
[Validation] Batch ID = 13270, loss = 0.064811, acc = 0.98
[Train] Batch ID = 13280, loss = 0.0263035, acc = 1.0
[Validation] Batch ID = 13280, loss = 0.0658505, acc = 0.92
[Train] Batch ID = 13290, loss = 0.0167579, acc = 1.0
[Validation] Batch ID = 13290, loss = 0.0619174, acc = 0.96
[Train] Batch ID = 13300, loss = 0.0229413, acc = 1.0
[Validation] Batch ID = 13300, loss = 0.0395722, acc = 0.96
[Train] Batch ID = 13310, loss = 0.221866, acc = 0.8
[Validation] Batch ID = 13310, loss = 0.0789589, acc = 0.94
[Train] Batch ID = 13320, loss = 0.255754, acc = 0.78
[Validation] Batch ID = 13320, loss = 0.107457, acc = 0.9
[Train] Batch ID = 13330, loss = 0.0242144, acc = 1.0
[Validation] Batch ID = 13330, loss = 0.0270562, acc = 0.98
[Train] Batch ID = 13340, loss = 0.0179694, acc = 1.0
[Validation] Batch ID = 13340, loss = 0.0667641, acc = 0.94
[Train] Batch ID = 13350, loss = 0.0141127, acc = 1.0
[Validation] Batch ID = 13350, loss = 0.0497414, acc = 0.98
[Train] Batch ID = 13360, loss = 0.0218103, acc = 1.0
[Validation] Batch ID = 13360, loss = 0.0540661, acc = 0.98
[Train] Batch ID = 13370, loss = 0.0196735, acc = 1.0
[Validation] Batch ID = 13370, loss = 0.0462488, acc = 0.98
[Train] Batch ID = 13380, loss = 0.0147022, acc = 1.0
[Validation] Batch ID = 13380, loss = 0.0620971, acc = 0.94
[Train] Batch ID = 13390, loss = 0.0183105, acc = 1.0
[Validation] Batch ID = 13390, loss = 0.0443389, acc = 0.98
[Train] Batch ID = 13400, loss = 0.165949, acc = 0.88
[Validation] Batch ID = 13400, loss = 0.0499432, acc = 0.96
[Train] Batch ID = 13410, loss = 0.0250492, acc = 1.0
[Validation] Batch ID = 13410, loss = 0.069731, acc = 0.96
[Train] Batch ID = 13420, loss = 0.0199806, acc = 1.0
[Validation] Batch ID = 13420, loss = 0.0442849, acc = 1.0
[Train] Batch ID = 13430, loss = 0.0229912, acc = 1.0
[Validation] Batch ID = 13430, loss = 0.0526869, acc = 0.94
[Train] Batch ID = 13440, loss = 0.014231, acc = 1.0
[Validation] Batch ID = 13440, loss = 0.0503653, acc = 0.98
[Train] Batch ID = 13450, loss = 0.0198954, acc = 1.0
[Validation] Batch ID = 13450, loss = 0.0355697, acc = 1.0
[Train] Batch ID = 13460, loss = 0.0125129, acc = 1.0
[Validation] Batch ID = 13460, loss = 0.0369097, acc = 0.98
[Train] Batch ID = 13470, loss = 0.0145162, acc = 1.0
[Validation] Batch ID = 13470, loss = 0.0595161, acc = 0.96
[Train] Batch ID = 13480, loss = 0.219522, acc = 0.82
[Validation] Batch ID = 13480, loss = 0.0621883, acc = 0.96
[Train] Batch ID = 13490, loss = 0.0214466, acc = 1.0
[Validation] Batch ID = 13490, loss = 0.0463491, acc = 0.98
[Train] Batch ID = 13500, loss = 0.011065, acc = 1.0
[Validation] Batch ID = 13500, loss = 0.0444813, acc = 0.98
[Train] Batch ID = 13510, loss = 0.0229387, acc = 1.0
[Validation] Batch ID = 13510, loss = 0.0577275, acc = 0.94
[Train] Batch ID = 13520, loss = 0.235128, acc = 0.74
[Validation] Batch ID = 13520, loss = 0.0576322, acc = 0.96
[Train] Batch ID = 13530, loss = 0.00933447, acc = 1.0
[Validation] Batch ID = 13530, loss = 0.0424697, acc = 1.0
[Train] Batch ID = 13540, loss = 0.187531, acc = 0.78
[Validation] Batch ID = 13540, loss = 0.0404698, acc = 0.98
[Train] Batch ID = 13550, loss = 0.0186331, acc = 1.0
[Validation] Batch ID = 13550, loss = 0.0595799, acc = 0.92
[Train] Batch ID = 13560, loss = 0.0133592, acc = 1.0
[Validation] Batch ID = 13560, loss = 0.053987, acc = 0.94
[Train] Batch ID = 13570, loss = 0.0209069, acc = 0.98
[Validation] Batch ID = 13570, loss = 0.0373226, acc = 1.0
[Train] Batch ID = 13580, loss = 0.180876, acc = 0.88
[Validation] Batch ID = 13580, loss = 0.0489699, acc = 0.96
[Train] Batch ID = 13590, loss = 0.0185618, acc = 1.0
[Validation] Batch ID = 13590, loss = 0.0325749, acc = 1.0
[Train] Batch ID = 13600, loss = 0.0190196, acc = 1.0
[Validation] Batch ID = 13600, loss = 0.0332634, acc = 1.0
[Train] Batch ID = 13610, loss = 0.239987, acc = 0.8
[Validation] Batch ID = 13610, loss = 0.0644114, acc = 0.94
[Train] Batch ID = 13620, loss = 0.237697, acc = 0.8
[Validation] Batch ID = 13620, loss = 0.0727512, acc = 0.96
[Train] Batch ID = 13630, loss = 0.0226662, acc = 1.0
[Validation] Batch ID = 13630, loss = 0.065892, acc = 0.96
[Train] Batch ID = 13640, loss = 0.0124876, acc = 1.0
[Validation] Batch ID = 13640, loss = 0.0890835, acc = 0.9
[Train] Batch ID = 13650, loss = 0.0200429, acc = 1.0
[Validation] Batch ID = 13650, loss = 0.0378764, acc = 0.96
[Train] Batch ID = 13660, loss = 0.250392, acc = 0.68
[Validation] Batch ID = 13660, loss = 0.048941, acc = 0.98
[Train] Batch ID = 13670, loss = 0.0194942, acc = 1.0
[Validation] Batch ID = 13670, loss = 0.0734322, acc = 0.96
[Train] Batch ID = 13680, loss = 0.0200593, acc = 1.0
[Validation] Batch ID = 13680, loss = 0.0511995, acc = 0.98
[Train] Batch ID = 13690, loss = 0.0208543, acc = 1.0
[Validation] Batch ID = 13690, loss = 0.0324438, acc = 1.0
[Train] Batch ID = 13700, loss = 0.0160377, acc = 1.0
[Validation] Batch ID = 13700, loss = 0.0402422, acc = 0.98
[Train] Batch ID = 13710, loss = 0.0271988, acc = 1.0
[Validation] Batch ID = 13710, loss = 0.031485, acc = 1.0
[Train] Batch ID = 13720, loss = 0.0340653, acc = 1.0
[Validation] Batch ID = 13720, loss = 0.0610131, acc = 0.96
[Train] Batch ID = 13730, loss = 0.0112979, acc = 1.0
[Validation] Batch ID = 13730, loss = 0.0420173, acc = 0.98
[Train] Batch ID = 13740, loss = 0.220664, acc = 0.82
[Validation] Batch ID = 13740, loss = 0.0480506, acc = 0.98
[Train] Batch ID = 13750, loss = 0.0179719, acc = 1.0
[Validation] Batch ID = 13750, loss = 0.0470977, acc = 0.96
[Train] Batch ID = 13760, loss = 0.0156603, acc = 1.0
[Validation] Batch ID = 13760, loss = 0.0635835, acc = 0.94
[Train] Batch ID = 13770, loss = 0.0110398, acc = 1.0
[Validation] Batch ID = 13770, loss = 0.0256402, acc = 0.96
[Train] Batch ID = 13780, loss = 0.0133317, acc = 1.0
[Validation] Batch ID = 13780, loss = 0.0491741, acc = 0.98
[Train] Batch ID = 13790, loss = 0.0178357, acc = 0.98
[Validation] Batch ID = 13790, loss = 0.0774262, acc = 0.92
[Train] Batch ID = 13800, loss = 0.0131886, acc = 1.0
[Validation] Batch ID = 13800, loss = 0.0524007, acc = 0.94
[Train] Batch ID = 13810, loss = 0.0207726, acc = 1.0
[Validation] Batch ID = 13810, loss = 0.055231, acc = 0.96
[Train] Batch ID = 13820, loss = 0.0184319, acc = 1.0
[Validation] Batch ID = 13820, loss = 0.0658886, acc = 0.92
[Train] Batch ID = 13830, loss = 0.0121448, acc = 1.0
[Validation] Batch ID = 13830, loss = 0.0608737, acc = 0.94
[Train] Batch ID = 13840, loss = 0.0176109, acc = 1.0
[Validation] Batch ID = 13840, loss = 0.0342796, acc = 0.96
[Train] Batch ID = 13850, loss = 0.0135915, acc = 1.0
[Validation] Batch ID = 13850, loss = 0.0660631, acc = 0.94
[Train] Batch ID = 13860, loss = 0.244507, acc = 0.8
[Validation] Batch ID = 13860, loss = 0.0460863, acc = 0.98
[Train] Batch ID = 13870, loss = 0.0121728, acc = 1.0
[Validation] Batch ID = 13870, loss = 0.0749173, acc = 0.94
[Train] Batch ID = 13880, loss = 0.231046, acc = 0.76
[Validation] Batch ID = 13880, loss = 0.03055, acc = 1.0
[Train] Batch ID = 13890, loss = 0.0161479, acc = 1.0
[Validation] Batch ID = 13890, loss = 0.0521142, acc = 0.98
[Train] Batch ID = 13900, loss = 0.0134029, acc = 1.0
[Validation] Batch ID = 13900, loss = 0.0563484, acc = 0.94
[Train] Batch ID = 13910, loss = 0.0129106, acc = 1.0
[Validation] Batch ID = 13910, loss = 0.0309789, acc = 0.98
[Train] Batch ID = 13920, loss = 0.0242851, acc = 1.0
[Validation] Batch ID = 13920, loss = 0.0269284, acc = 1.0
[Train] Batch ID = 13930, loss = 0.18367, acc = 0.96
[Validation] Batch ID = 13930, loss = 0.0714316, acc = 0.94
[Train] Batch ID = 13940, loss = 0.0116534, acc = 1.0
[Validation] Batch ID = 13940, loss = 0.0739671, acc = 0.92
[Train] Batch ID = 13950, loss = 0.247025, acc = 0.76
[Validation] Batch ID = 13950, loss = 0.0429501, acc = 0.98
[Train] Batch ID = 13960, loss = 0.0195282, acc = 1.0
[Validation] Batch ID = 13960, loss = 0.0639656, acc = 0.96
[Train] Batch ID = 13970, loss = 0.231796, acc = 0.74
[Validation] Batch ID = 13970, loss = 0.061947, acc = 0.94
[Train] Batch ID = 13980, loss = 0.0175333, acc = 1.0
[Validation] Batch ID = 13980, loss = 0.0363198, acc = 1.0
[Train] Batch ID = 13990, loss = 0.0146424, acc = 1.0
[Validation] Batch ID = 13990, loss = 0.043886, acc = 0.98
[Train] Batch ID = 14000, loss = 0.0214707, acc = 1.0
[Validation] Batch ID = 14000, loss = 0.0592368, acc = 0.94
Evaluate full validation dataset ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Saving model ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Current loss: 0.0517805 Best loss: 0.0540795
[TOTAL Validation] Batch ID = 14000, loss = 0.0517805, acc = 0.966213151927
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Model successfully saved here: outputs/checkpoints/c1s_9_c1n_256_c2s_6_c2n_64_c2d_0.7_c1vl_16_c1s_5_c1nf_16_c2vl_32_lr_0.0001_rs_1--TrafficSign--1510487290.423481
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Augmented Factor = 0.20383222077370258
[Train] Batch ID = 14010, loss = 0.203466, acc = 0.84
[Validation] Batch ID = 14010, loss = 0.0562444, acc = 0.96
[Train] Batch ID = 14020, loss = 0.0202147, acc = 1.0
[Validation] Batch ID = 14020, loss = 0.0437304, acc = 0.98
[Train] Batch ID = 14030, loss = 0.0118778, acc = 1.0
[Validation] Batch ID = 14030, loss = 0.0473346, acc = 0.96
[Train] Batch ID = 14040, loss = 0.221029, acc = 0.76
[Validation] Batch ID = 14040, loss = 0.053237, acc = 0.98
[Train] Batch ID = 14050, loss = 0.0165804, acc = 1.0
[Validation] Batch ID = 14050, loss = 0.0455848, acc = 0.98
[Train] Batch ID = 14060, loss = 0.0194048, acc = 1.0
[Validation] Batch ID = 14060, loss = 0.0566186, acc = 0.96
[Train] Batch ID = 14070, loss = 0.0190483, acc = 1.0
[Validation] Batch ID = 14070, loss = 0.0368394, acc = 1.0
[Train] Batch ID = 14080, loss = 0.225059, acc = 0.78
[Validation] Batch ID = 14080, loss = 0.0259959, acc = 1.0
[Train] Batch ID = 14090, loss = 0.0126204, acc = 1.0
[Validation] Batch ID = 14090, loss = 0.0412608, acc = 1.0
[Train] Batch ID = 14100, loss = 0.0180644, acc = 1.0
[Validation] Batch ID = 14100, loss = 0.0540486, acc = 1.0
[Train] Batch ID = 14110, loss = 0.0089155, acc = 1.0
[Validation] Batch ID = 14110, loss = 0.0440098, acc = 0.98
[Train] Batch ID = 14120, loss = 0.187564, acc = 0.92
[Validation] Batch ID = 14120, loss = 0.0783404, acc = 0.92
[Train] Batch ID = 14130, loss = 0.153832, acc = 0.92
[Validation] Batch ID = 14130, loss = 0.0573817, acc = 0.94
[Train] Batch ID = 14140, loss = 0.0216071, acc = 1.0
[Validation] Batch ID = 14140, loss = 0.0310153, acc = 1.0
[Train] Batch ID = 14150, loss = 0.0181738, acc = 0.98
[Validation] Batch ID = 14150, loss = 0.0176965, acc = 1.0
[Train] Batch ID = 14160, loss = 0.0141067, acc = 1.0
[Validation] Batch ID = 14160, loss = 0.033951, acc = 0.98
[Train] Batch ID = 14170, loss = 0.0196069, acc = 1.0
[Validation] Batch ID = 14170, loss = 0.0599175, acc = 0.96
[Train] Batch ID = 14180, loss = 0.0170713, acc = 0.98
[Validation] Batch ID = 14180, loss = 0.0422436, acc = 0.96
[Train] Batch ID = 14190, loss = 0.0171395, acc = 1.0
[Validation] Batch ID = 14190, loss = 0.0484306, acc = 0.98
[Train] Batch ID = 14200, loss = 0.015157, acc = 1.0
[Validation] Batch ID = 14200, loss = 0.0388945, acc = 0.96
[Train] Batch ID = 14210, loss = 0.0160967, acc = 1.0
[Validation] Batch ID = 14210, loss = 0.0820909, acc = 0.94
[Train] Batch ID = 14220, loss = 0.199017, acc = 0.86
[Validation] Batch ID = 14220, loss = 0.0210557, acc = 1.0
[Train] Batch ID = 14230, loss = 0.0116434, acc = 1.0
[Validation] Batch ID = 14230, loss = 0.04394, acc = 0.98
[Train] Batch ID = 14240, loss = 0.248596, acc = 0.82
[Validation] Batch ID = 14240, loss = 0.0656162, acc = 0.98
[Train] Batch ID = 14250, loss = 0.0135822, acc = 1.0
[Validation] Batch ID = 14250, loss = 0.0276338, acc = 0.98
[Train] Batch ID = 14260, loss = 0.0108429, acc = 1.0
[Validation] Batch ID = 14260, loss = 0.0527308, acc = 0.96
[Train] Batch ID = 14270, loss = 0.0164156, acc = 1.0
[Validation] Batch ID = 14270, loss = 0.0209673, acc = 1.0
[Train] Batch ID = 14280, loss = 0.0134638, acc = 1.0
[Validation] Batch ID = 14280, loss = 0.0524857, acc = 0.96
[Train] Batch ID = 14290, loss = 0.0157613, acc = 1.0
[Validation] Batch ID = 14290, loss = 0.0617812, acc = 0.94
[Train] Batch ID = 14300, loss = 0.0204554, acc = 1.0
[Validation] Batch ID = 14300, loss = 0.0259335, acc = 1.0
[Train] Batch ID = 14310, loss = 0.00918008, acc = 1.0
[Validation] Batch ID = 14310, loss = 0.074198, acc = 0.96
[Train] Batch ID = 14320, loss = 0.0226162, acc = 1.0
[Validation] Batch ID = 14320, loss = 0.0550051, acc = 0.96
[Train] Batch ID = 14330, loss = 0.0150857, acc = 1.0
[Validation] Batch ID = 14330, loss = 0.0635429, acc = 0.92
[Train] Batch ID = 14340, loss = 0.239866, acc = 0.82
[Validation] Batch ID = 14340, loss = 0.0656054, acc = 0.94
[Train] Batch ID = 14350, loss = 0.0144525, acc = 1.0
[Validation] Batch ID = 14350, loss = 0.0420936, acc = 0.98
[Train] Batch ID = 14360, loss = 0.0174445, acc = 1.0
[Validation] Batch ID = 14360, loss = 0.0296047, acc = 1.0
[Train] Batch ID = 14370, loss = 0.0103337, acc = 1.0
[Validation] Batch ID = 14370, loss = 0.0316573, acc = 0.98
[Train] Batch ID = 14380, loss = 0.0122254, acc = 1.0
[Validation] Batch ID = 14380, loss = 0.0454262, acc = 0.98
[Train] Batch ID = 14390, loss = 0.0112844, acc = 1.0
[Validation] Batch ID = 14390, loss = 0.0527906, acc = 0.98
[Train] Batch ID = 14400, loss = 0.0125567, acc = 1.0
[Validation] Batch ID = 14400, loss = 0.0533561, acc = 0.96
[Train] Batch ID = 14410, loss = 0.0193282, acc = 1.0
[Validation] Batch ID = 14410, loss = 0.0638536, acc = 0.94
[Train] Batch ID = 14420, loss = 0.0140374, acc = 1.0
[Validation] Batch ID = 14420, loss = 0.0274256, acc = 0.98
[Train] Batch ID = 14430, loss = 0.266533, acc = 0.76
[Validation] Batch ID = 14430, loss = 0.0411989, acc = 0.96
[Train] Batch ID = 14440, loss = 0.0134864, acc = 1.0
[Validation] Batch ID = 14440, loss = 0.0208384, acc = 1.0
[Train] Batch ID = 14450, loss = 0.0143936, acc = 1.0
[Validation] Batch ID = 14450, loss = 0.0591412, acc = 0.94
[Train] Batch ID = 14460, loss = 0.202675, acc = 0.88
[Validation] Batch ID = 14460, loss = 0.0437313, acc = 0.96
[Train] Batch ID = 14470, loss = 0.195715, acc = 0.88
[Validation] Batch ID = 14470, loss = 0.0527227, acc = 0.98
[Train] Batch ID = 14480, loss = 0.214039, acc = 0.82
[Validation] Batch ID = 14480, loss = 0.0690891, acc = 0.94
[Train] Batch ID = 14490, loss = 0.0140469, acc = 1.0
[Validation] Batch ID = 14490, loss = 0.079239, acc = 0.92
[Train] Batch ID = 14500, loss = 0.019497, acc = 1.0
[Validation] Batch ID = 14500, loss = 0.0512354, acc = 0.98
[Train] Batch ID = 14510, loss = 0.0138834, acc = 1.0
[Validation] Batch ID = 14510, loss = 0.0635605, acc = 0.94
[Train] Batch ID = 14520, loss = 0.244601, acc = 0.74
[Validation] Batch ID = 14520, loss = 0.0361998, acc = 0.98
[Train] Batch ID = 14530, loss = 0.0145111, acc = 1.0
[Validation] Batch ID = 14530, loss = 0.0287625, acc = 0.96
[Train] Batch ID = 14540, loss = 0.00783642, acc = 1.0
[Validation] Batch ID = 14540, loss = 0.0579598, acc = 0.94
[Train] Batch ID = 14550, loss = 0.0090403, acc = 1.0
[Validation] Batch ID = 14550, loss = 0.0201208, acc = 1.0
[Train] Batch ID = 14560, loss = 0.0157432, acc = 1.0
[Validation] Batch ID = 14560, loss = 0.0612433, acc = 0.96
[Train] Batch ID = 14570, loss = 0.00779548, acc = 1.0
[Validation] Batch ID = 14570, loss = 0.0293981, acc = 0.98
[Train] Batch ID = 14580, loss = 0.014183, acc = 1.0
[Validation] Batch ID = 14580, loss = 0.0305216, acc = 0.98
[Train] Batch ID = 14590, loss = 0.0107267, acc = 1.0
[Validation] Batch ID = 14590, loss = 0.0578391, acc = 0.98
[Train] Batch ID = 14600, loss = 0.0118599, acc = 1.0
[Validation] Batch ID = 14600, loss = 0.0273645, acc = 1.0
[Train] Batch ID = 14610, loss = 0.0144261, acc = 1.0
[Validation] Batch ID = 14610, loss = 0.0620002, acc = 0.98
[Train] Batch ID = 14620, loss = 0.0170586, acc = 1.0
[Validation] Batch ID = 14620, loss = 0.0407411, acc = 0.96
[Train] Batch ID = 14630, loss = 0.0153513, acc = 1.0
[Validation] Batch ID = 14630, loss = 0.0421233, acc = 0.96
[Train] Batch ID = 14640, loss = 0.219209, acc = 0.84
[Validation] Batch ID = 14640, loss = 0.0438253, acc = 0.96
[Train] Batch ID = 14650, loss = 0.0138177, acc = 1.0
[Validation] Batch ID = 14650, loss = 0.0685225, acc = 0.96
[Train] Batch ID = 14660, loss = 0.00639381, acc = 1.0
[Validation] Batch ID = 14660, loss = 0.0470836, acc = 0.96
[Train] Batch ID = 14670, loss = 0.0147285, acc = 1.0
[Validation] Batch ID = 14670, loss = 0.0286004, acc = 1.0
[Train] Batch ID = 14680, loss = 0.0117134, acc = 1.0
[Validation] Batch ID = 14680, loss = 0.0354125, acc = 1.0
[Train] Batch ID = 14690, loss = 0.0126837, acc = 1.0
[Validation] Batch ID = 14690, loss = 0.0451521, acc = 1.0
[Train] Batch ID = 14700, loss = 0.0221791, acc = 1.0
[Validation] Batch ID = 14700, loss = 0.0446644, acc = 0.96
[Train] Batch ID = 14710, loss = 0.00831289, acc = 1.0
[Validation] Batch ID = 14710, loss = 0.0512175, acc = 0.92
[Train] Batch ID = 14720, loss = 0.0184709, acc = 1.0
[Validation] Batch ID = 14720, loss = 0.034469, acc = 0.98
[Train] Batch ID = 14730, loss = 0.228537, acc = 0.84
[Validation] Batch ID = 14730, loss = 0.0539398, acc = 0.96
[Train] Batch ID = 14740, loss = 0.0124278, acc = 1.0
[Validation] Batch ID = 14740, loss = 0.0494461, acc = 0.96
[Train] Batch ID = 14750, loss = 0.266271, acc = 0.72
[Validation] Batch ID = 14750, loss = 0.0475507, acc = 0.96
[Train] Batch ID = 14760, loss = 0.0165065, acc = 1.0
[Validation] Batch ID = 14760, loss = 0.0451781, acc = 0.96
[Train] Batch ID = 14770, loss = 0.00855368, acc = 1.0
[Validation] Batch ID = 14770, loss = 0.043562, acc = 0.98
[Train] Batch ID = 14780, loss = 0.011566, acc = 1.0
[Validation] Batch ID = 14780, loss = 0.0436674, acc = 1.0
[Train] Batch ID = 14790, loss = 0.011488, acc = 1.0
[Validation] Batch ID = 14790, loss = 0.0405886, acc = 0.98
[Train] Batch ID = 14800, loss = 0.234057, acc = 0.74
[Validation] Batch ID = 14800, loss = 0.0325993, acc = 1.0
[Train] Batch ID = 14810, loss = 0.0104344, acc = 1.0
[Validation] Batch ID = 14810, loss = 0.0442596, acc = 1.0
[Train] Batch ID = 14820, loss = 0.0171571, acc = 1.0
[Validation] Batch ID = 14820, loss = 0.0417559, acc = 0.96
[Train] Batch ID = 14830, loss = 0.00779435, acc = 1.0
[Validation] Batch ID = 14830, loss = 0.0331379, acc = 0.96
[Train] Batch ID = 14840, loss = 0.00860059, acc = 1.0
[Validation] Batch ID = 14840, loss = 0.0706909, acc = 0.88
[Train] Batch ID = 14850, loss = 0.0104501, acc = 1.0
[Validation] Batch ID = 14850, loss = 0.0296497, acc = 0.98
[Train] Batch ID = 14860, loss = 0.260989, acc = 0.7
[Validation] Batch ID = 14860, loss = 0.0541074, acc = 0.96
[Train] Batch ID = 14870, loss = 0.0100119, acc = 1.0
[Validation] Batch ID = 14870, loss = 0.0282313, acc = 1.0
[Train] Batch ID = 14880, loss = 0.225192, acc = 0.76
[Validation] Batch ID = 14880, loss = 0.0380161, acc = 0.98
[Train] Batch ID = 14890, loss = 0.208854, acc = 0.8
[Validation] Batch ID = 14890, loss = 0.0246938, acc = 1.0
[Train] Batch ID = 14900, loss = 0.0226865, acc = 1.0
[Validation] Batch ID = 14900, loss = 0.0450178, acc = 1.0
[Train] Batch ID = 14910, loss = 0.0164565, acc = 1.0
[Validation] Batch ID = 14910, loss = 0.0307414, acc = 1.0
[Train] Batch ID = 14920, loss = 0.0121235, acc = 1.0
[Validation] Batch ID = 14920, loss = 0.0331958, acc = 0.98
[Train] Batch ID = 14930, loss = 0.0153693, acc = 1.0
[Validation] Batch ID = 14930, loss = 0.0278498, acc = 0.98
[Train] Batch ID = 14940, loss = 0.012833, acc = 1.0
[Validation] Batch ID = 14940, loss = 0.0336789, acc = 1.0
[Train] Batch ID = 14950, loss = 0.009922, acc = 1.0
[Validation] Batch ID = 14950, loss = 0.0497969, acc = 0.98
[Train] Batch ID = 14960, loss = 0.0106934, acc = 1.0
[Validation] Batch ID = 14960, loss = 0.0361566, acc = 0.98
[Train] Batch ID = 14970, loss = 0.00720681, acc = 1.0
[Validation] Batch ID = 14970, loss = 0.0216081, acc = 1.0
[Train] Batch ID = 14980, loss = 0.00770243, acc = 1.0
[Validation] Batch ID = 14980, loss = 0.0746249, acc = 0.92
[Train] Batch ID = 14990, loss = 0.00857291, acc = 1.0
[Validation] Batch ID = 14990, loss = 0.0442599, acc = 0.98
[Train] Batch ID = 15000, loss = 0.00988107, acc = 1.0
[Validation] Batch ID = 15000, loss = 0.0346062, acc = 1.0
Evaluate full validation dataset ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Saving model ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Current loss: 0.0475598 Best loss: 0.0517805
[TOTAL Validation] Batch ID = 15000, loss = 0.0475598, acc = 0.968480725624
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Model successfully saved here: outputs/checkpoints/c1s_9_c1n_256_c2s_6_c2n_64_c2d_0.7_c1vl_16_c1s_5_c1nf_16_c2vl_32_lr_0.0001_rs_1--TrafficSign--1510487290.423481
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Augmented Factor = 0.18344899869633233
[Train] Batch ID = 15010, loss = 0.0195009, acc = 1.0
[Validation] Batch ID = 15010, loss = 0.0537054, acc = 0.94
[Train] Batch ID = 15020, loss = 0.0139916, acc = 1.0
[Validation] Batch ID = 15020, loss = 0.0433528, acc = 0.96
[Train] Batch ID = 15030, loss = 0.244256, acc = 0.74
[Validation] Batch ID = 15030, loss = 0.033646, acc = 0.98
[Train] Batch ID = 15040, loss = 0.011397, acc = 1.0
[Validation] Batch ID = 15040, loss = 0.0215763, acc = 1.0
[Train] Batch ID = 15050, loss = 0.0203587, acc = 1.0
[Validation] Batch ID = 15050, loss = 0.0387565, acc = 1.0
[Train] Batch ID = 15060, loss = 0.0143561, acc = 1.0
[Validation] Batch ID = 15060, loss = 0.0551605, acc = 0.98
[Train] Batch ID = 15070, loss = 0.0114322, acc = 1.0
[Validation] Batch ID = 15070, loss = 0.0438803, acc = 1.0
[Train] Batch ID = 15080, loss = 0.0143031, acc = 1.0
[Validation] Batch ID = 15080, loss = 0.0616548, acc = 0.96
[Train] Batch ID = 15090, loss = 0.0183336, acc = 1.0
[Validation] Batch ID = 15090, loss = 0.0383666, acc = 0.96
[Train] Batch ID = 15100, loss = 0.00853729, acc = 1.0
[Validation] Batch ID = 15100, loss = 0.0579503, acc = 0.96
[Train] Batch ID = 15110, loss = 0.0187059, acc = 1.0
[Validation] Batch ID = 15110, loss = 0.0431201, acc = 0.96
[Train] Batch ID = 15120, loss = 0.0212592, acc = 1.0
[Validation] Batch ID = 15120, loss = 0.0573835, acc = 0.96
[Train] Batch ID = 15130, loss = 0.0112095, acc = 1.0
[Validation] Batch ID = 15130, loss = 0.0416821, acc = 0.98
[Train] Batch ID = 15140, loss = 0.0240188, acc = 0.98
[Validation] Batch ID = 15140, loss = 0.0493539, acc = 0.94
[Train] Batch ID = 15150, loss = 0.0112658, acc = 1.0
[Validation] Batch ID = 15150, loss = 0.0565765, acc = 0.94
[Train] Batch ID = 15160, loss = 0.0111156, acc = 1.0
[Validation] Batch ID = 15160, loss = 0.03372, acc = 1.0
[Train] Batch ID = 15170, loss = 0.00996929, acc = 1.0
[Validation] Batch ID = 15170, loss = 0.0649887, acc = 0.92
[Train] Batch ID = 15180, loss = 0.015613, acc = 1.0
[Validation] Batch ID = 15180, loss = 0.0589631, acc = 0.92
[Train] Batch ID = 15190, loss = 0.01074, acc = 1.0
[Validation] Batch ID = 15190, loss = 0.0393959, acc = 0.98
[Train] Batch ID = 15200, loss = 0.0110103, acc = 1.0
[Validation] Batch ID = 15200, loss = 0.057469, acc = 0.98
[Train] Batch ID = 15210, loss = 0.181816, acc = 0.9
[Validation] Batch ID = 15210, loss = 0.0652272, acc = 0.94
[Train] Batch ID = 15220, loss = 0.158652, acc = 0.9
[Validation] Batch ID = 15220, loss = 0.0361428, acc = 0.96
[Train] Batch ID = 15230, loss = 0.0142205, acc = 1.0
[Validation] Batch ID = 15230, loss = 0.0519986, acc = 0.98
[Train] Batch ID = 15240, loss = 0.0103469, acc = 1.0
[Validation] Batch ID = 15240, loss = 0.049191, acc = 0.94
[Train] Batch ID = 15250, loss = 0.0098641, acc = 1.0
[Validation] Batch ID = 15250, loss = 0.0531481, acc = 0.98
[Train] Batch ID = 15260, loss = 0.0132855, acc = 1.0
[Validation] Batch ID = 15260, loss = 0.0583383, acc = 0.98
[Train] Batch ID = 15270, loss = 0.0129511, acc = 1.0
[Validation] Batch ID = 15270, loss = 0.0531587, acc = 0.96
[Train] Batch ID = 15280, loss = 0.0215572, acc = 1.0
[Validation] Batch ID = 15280, loss = 0.0393173, acc = 0.98
[Train] Batch ID = 15290, loss = 0.0164872, acc = 1.0
[Validation] Batch ID = 15290, loss = 0.029098, acc = 1.0
[Train] Batch ID = 15300, loss = 0.0160943, acc = 1.0
[Validation] Batch ID = 15300, loss = 0.0424113, acc = 0.98
[Train] Batch ID = 15310, loss = 0.0101976, acc = 1.0
[Validation] Batch ID = 15310, loss = 0.0517624, acc = 0.96
[Train] Batch ID = 15320, loss = 0.0160082, acc = 1.0
[Validation] Batch ID = 15320, loss = 0.0321096, acc = 1.0
[Train] Batch ID = 15330, loss = 0.00761872, acc = 1.0
[Validation] Batch ID = 15330, loss = 0.0534977, acc = 0.96
[Train] Batch ID = 15340, loss = 0.0104171, acc = 1.0
[Validation] Batch ID = 15340, loss = 0.0615207, acc = 0.94
[Train] Batch ID = 15350, loss = 0.0152187, acc = 1.0
[Validation] Batch ID = 15350, loss = 0.0838535, acc = 0.9
[Train] Batch ID = 15360, loss = 0.0181694, acc = 1.0
[Validation] Batch ID = 15360, loss = 0.0344293, acc = 1.0
[Train] Batch ID = 15370, loss = 0.0049273, acc = 1.0
[Validation] Batch ID = 15370, loss = 0.0455798, acc = 0.98
[Train] Batch ID = 15380, loss = 0.00905102, acc = 1.0
[Validation] Batch ID = 15380, loss = 0.043164, acc = 1.0
[Train] Batch ID = 15390, loss = 0.0216415, acc = 1.0
[Validation] Batch ID = 15390, loss = 0.0587692, acc = 0.94
[Train] Batch ID = 15400, loss = 0.242652, acc = 0.76
[Validation] Batch ID = 15400, loss = 0.0430674, acc = 0.96
[Train] Batch ID = 15410, loss = 0.25209, acc = 0.78
[Validation] Batch ID = 15410, loss = 0.040581, acc = 0.96
[Train] Batch ID = 15420, loss = 0.0171264, acc = 1.0
[Validation] Batch ID = 15420, loss = 0.0506348, acc = 0.96
[Train] Batch ID = 15430, loss = 0.0118538, acc = 1.0
[Validation] Batch ID = 15430, loss = 0.0361167, acc = 0.96
[Train] Batch ID = 15440, loss = 0.261513, acc = 0.76
[Validation] Batch ID = 15440, loss = 0.0239811, acc = 1.0
[Train] Batch ID = 15450, loss = 0.0220238, acc = 1.0
[Validation] Batch ID = 15450, loss = 0.0377151, acc = 1.0
[Train] Batch ID = 15460, loss = 0.274453, acc = 0.74
[Validation] Batch ID = 15460, loss = 0.029723, acc = 0.98
[Train] Batch ID = 15470, loss = 0.0125358, acc = 1.0
[Validation] Batch ID = 15470, loss = 0.0603751, acc = 0.98
[Train] Batch ID = 15480, loss = 0.0144089, acc = 1.0
[Validation] Batch ID = 15480, loss = 0.0675919, acc = 0.96
[Train] Batch ID = 15490, loss = 0.232417, acc = 0.8
[Validation] Batch ID = 15490, loss = 0.0627741, acc = 0.96
[Train] Batch ID = 15500, loss = 0.0180878, acc = 1.0
[Validation] Batch ID = 15500, loss = 0.0207185, acc = 1.0
[Train] Batch ID = 15510, loss = 0.0152604, acc = 1.0
[Validation] Batch ID = 15510, loss = 0.0508125, acc = 0.98
[Train] Batch ID = 15520, loss = 0.258461, acc = 0.7
[Validation] Batch ID = 15520, loss = 0.0563423, acc = 0.94
[Train] Batch ID = 15530, loss = 0.0117211, acc = 1.0
[Validation] Batch ID = 15530, loss = 0.0575027, acc = 0.94
[Train] Batch ID = 15540, loss = 0.0110345, acc = 1.0
[Validation] Batch ID = 15540, loss = 0.0773278, acc = 0.9
[Train] Batch ID = 15550, loss = 0.0085011, acc = 1.0
[Validation] Batch ID = 15550, loss = 0.042823, acc = 0.98
[Train] Batch ID = 15560, loss = 0.231707, acc = 0.7
[Validation] Batch ID = 15560, loss = 0.054902, acc = 0.98
[Train] Batch ID = 15570, loss = 0.019186, acc = 1.0
[Validation] Batch ID = 15570, loss = 0.0556313, acc = 0.98
[Train] Batch ID = 15580, loss = 0.0134613, acc = 1.0
[Validation] Batch ID = 15580, loss = 0.0363215, acc = 0.98
[Train] Batch ID = 15590, loss = 0.0126588, acc = 1.0
[Validation] Batch ID = 15590, loss = 0.0373643, acc = 0.98
[Train] Batch ID = 15600, loss = 0.0128648, acc = 1.0
[Validation] Batch ID = 15600, loss = 0.021724, acc = 1.0
[Train] Batch ID = 15610, loss = 0.0116731, acc = 1.0
[Validation] Batch ID = 15610, loss = 0.0292522, acc = 1.0
[Train] Batch ID = 15620, loss = 0.218831, acc = 0.84
[Validation] Batch ID = 15620, loss = 0.0654211, acc = 0.92
[Train] Batch ID = 15630, loss = 0.0160361, acc = 1.0
[Validation] Batch ID = 15630, loss = 0.0721302, acc = 0.92
[Train] Batch ID = 15640, loss = 0.00697157, acc = 1.0
[Validation] Batch ID = 15640, loss = 0.0372314, acc = 0.98
[Train] Batch ID = 15650, loss = 0.0210146, acc = 1.0
[Validation] Batch ID = 15650, loss = 0.0573293, acc = 0.96
[Train] Batch ID = 15660, loss = 0.00676244, acc = 1.0
[Validation] Batch ID = 15660, loss = 0.0224818, acc = 1.0
[Train] Batch ID = 15670, loss = 0.0148738, acc = 1.0
[Validation] Batch ID = 15670, loss = 0.0625632, acc = 0.94
[Train] Batch ID = 15680, loss = 0.0142547, acc = 1.0
[Validation] Batch ID = 15680, loss = 0.0320464, acc = 1.0
[Train] Batch ID = 15690, loss = 0.00637703, acc = 1.0
[Validation] Batch ID = 15690, loss = 0.0402285, acc = 0.98
[Train] Batch ID = 15700, loss = 0.0199578, acc = 1.0
[Validation] Batch ID = 15700, loss = 0.0484345, acc = 0.98
[Train] Batch ID = 15710, loss = 0.0103618, acc = 1.0
[Validation] Batch ID = 15710, loss = 0.0493943, acc = 0.96
[Train] Batch ID = 15720, loss = 0.206241, acc = 0.82
[Validation] Batch ID = 15720, loss = 0.0470986, acc = 0.96
[Train] Batch ID = 15730, loss = 0.0155977, acc = 1.0
[Validation] Batch ID = 15730, loss = 0.04912, acc = 0.96
[Train] Batch ID = 15740, loss = 0.0194605, acc = 1.0
[Validation] Batch ID = 15740, loss = 0.0472566, acc = 0.96
[Train] Batch ID = 15750, loss = 0.223423, acc = 0.78
[Validation] Batch ID = 15750, loss = 0.0444133, acc = 1.0
[Train] Batch ID = 15760, loss = 0.0115861, acc = 1.0
[Validation] Batch ID = 15760, loss = 0.0460848, acc = 0.94
[Train] Batch ID = 15770, loss = 0.0093744, acc = 1.0
[Validation] Batch ID = 15770, loss = 0.047696, acc = 0.98
[Train] Batch ID = 15780, loss = 0.00912353, acc = 1.0
[Validation] Batch ID = 15780, loss = 0.0429961, acc = 0.96
[Train] Batch ID = 15790, loss = 0.0107375, acc = 1.0
[Validation] Batch ID = 15790, loss = 0.053271, acc = 0.94
[Train] Batch ID = 15800, loss = 0.00886228, acc = 1.0
[Validation] Batch ID = 15800, loss = 0.0485335, acc = 0.98
[Train] Batch ID = 15810, loss = 0.00733353, acc = 1.0
[Validation] Batch ID = 15810, loss = 0.0459577, acc = 1.0
[Train] Batch ID = 15820, loss = 0.0139804, acc = 1.0
[Validation] Batch ID = 15820, loss = 0.0360679, acc = 0.98
[Train] Batch ID = 15830, loss = 0.0148384, acc = 1.0
[Validation] Batch ID = 15830, loss = 0.0222546, acc = 0.98
[Train] Batch ID = 15840, loss = 0.243678, acc = 0.84
[Validation] Batch ID = 15840, loss = 0.0439197, acc = 0.98
[Train] Batch ID = 15850, loss = 0.00912225, acc = 1.0
[Validation] Batch ID = 15850, loss = 0.0579148, acc = 0.96
[Train] Batch ID = 15860, loss = 0.0168384, acc = 1.0
[Validation] Batch ID = 15860, loss = 0.0420261, acc = 1.0
[Train] Batch ID = 15870, loss = 0.176428, acc = 0.84
[Validation] Batch ID = 15870, loss = 0.0498796, acc = 0.96
[Train] Batch ID = 15880, loss = 0.182638, acc = 0.92
[Validation] Batch ID = 15880, loss = 0.0492946, acc = 0.96
[Train] Batch ID = 15890, loss = 0.0109115, acc = 1.0
[Validation] Batch ID = 15890, loss = 0.0625243, acc = 0.94
[Train] Batch ID = 15900, loss = 0.0132191, acc = 1.0
[Validation] Batch ID = 15900, loss = 0.0412078, acc = 0.98
[Train] Batch ID = 15910, loss = 0.244258, acc = 0.72
[Validation] Batch ID = 15910, loss = 0.040069, acc = 0.98
[Train] Batch ID = 15920, loss = 0.0130169, acc = 1.0
[Validation] Batch ID = 15920, loss = 0.0680322, acc = 0.94
[Train] Batch ID = 15930, loss = 0.0174861, acc = 1.0
[Validation] Batch ID = 15930, loss = 0.0315664, acc = 1.0
[Train] Batch ID = 15940, loss = 0.0103326, acc = 1.0
[Validation] Batch ID = 15940, loss = 0.0535319, acc = 0.96
[Train] Batch ID = 15950, loss = 0.00871107, acc = 1.0
[Validation] Batch ID = 15950, loss = 0.0493256, acc = 0.98
[Train] Batch ID = 15960, loss = 0.0238107, acc = 1.0
[Validation] Batch ID = 15960, loss = 0.0428512, acc = 1.0
[Train] Batch ID = 15970, loss = 0.0140351, acc = 1.0
[Validation] Batch ID = 15970, loss = 0.0627117, acc = 0.92
[Train] Batch ID = 15980, loss = 0.0156468, acc = 1.0
[Validation] Batch ID = 15980, loss = 0.0521207, acc = 0.98
[Train] Batch ID = 15990, loss = 0.011368, acc = 1.0
[Validation] Batch ID = 15990, loss = 0.0514348, acc = 0.96
[Train] Batch ID = 16000, loss = 0.213225, acc = 0.78
[Validation] Batch ID = 16000, loss = 0.0350242, acc = 0.98
Evaluate full validation dataset ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Saving model ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Current loss: 0.0446877 Best loss: 0.0475598
[TOTAL Validation] Batch ID = 16000, loss = 0.0446877, acc = 0.968480725624
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Model successfully saved here: outputs/checkpoints/c1s_9_c1n_256_c2s_6_c2n_64_c2d_0.7_c1vl_16_c1s_5_c1nf_16_c2vl_32_lr_0.0001_rs_1--TrafficSign--1510487290.423481
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Augmented Factor = 0.1651040988266991
[Train] Batch ID = 16010, loss = 0.0111596, acc = 1.0
[Validation] Batch ID = 16010, loss = 0.062686, acc = 0.92
[Train] Batch ID = 16020, loss = 0.00728413, acc = 1.0
[Validation] Batch ID = 16020, loss = 0.0375616, acc = 0.98
[Train] Batch ID = 16030, loss = 0.0219501, acc = 1.0
[Validation] Batch ID = 16030, loss = 0.0471256, acc = 0.98
[Train] Batch ID = 16040, loss = 0.00826156, acc = 1.0
[Validation] Batch ID = 16040, loss = 0.041215, acc = 0.98
[Train] Batch ID = 16050, loss = 0.0118491, acc = 1.0
[Validation] Batch ID = 16050, loss = 0.0551145, acc = 0.94
[Train] Batch ID = 16060, loss = 0.0173468, acc = 1.0
[Validation] Batch ID = 16060, loss = 0.0197725, acc = 1.0
[Train] Batch ID = 16070, loss = 0.00950886, acc = 1.0
[Validation] Batch ID = 16070, loss = 0.0636382, acc = 0.94
[Train] Batch ID = 16080, loss = 0.011442, acc = 1.0
[Validation] Batch ID = 16080, loss = 0.0706439, acc = 0.92
[Train] Batch ID = 16090, loss = 0.0182996, acc = 1.0
[Validation] Batch ID = 16090, loss = 0.0451216, acc = 0.94
[Train] Batch ID = 16100, loss = 0.00755775, acc = 1.0
[Validation] Batch ID = 16100, loss = 0.068078, acc = 0.92
[Train] Batch ID = 16110, loss = 0.0202015, acc = 1.0
[Validation] Batch ID = 16110, loss = 0.0587874, acc = 0.94
[Train] Batch ID = 16120, loss = 0.0161636, acc = 1.0
[Validation] Batch ID = 16120, loss = 0.040745, acc = 0.98
[Train] Batch ID = 16130, loss = 0.234428, acc = 0.82
[Validation] Batch ID = 16130, loss = 0.0424431, acc = 1.0
[Train] Batch ID = 16140, loss = 0.00756473, acc = 1.0
[Validation] Batch ID = 16140, loss = 0.0482823, acc = 0.96
[Train] Batch ID = 16150, loss = 0.0139153, acc = 1.0
[Validation] Batch ID = 16150, loss = 0.0616782, acc = 0.96
[Train] Batch ID = 16160, loss = 0.00660626, acc = 1.0
[Validation] Batch ID = 16160, loss = 0.0416498, acc = 0.94
[Train] Batch ID = 16170, loss = 0.0174369, acc = 1.0
[Validation] Batch ID = 16170, loss = 0.0381829, acc = 0.98
[Train] Batch ID = 16180, loss = 0.00543556, acc = 1.0
[Validation] Batch ID = 16180, loss = 0.0597887, acc = 0.96
[Train] Batch ID = 16190, loss = 0.22521, acc = 0.78
[Validation] Batch ID = 16190, loss = 0.0809974, acc = 0.92
[Train] Batch ID = 16200, loss = 0.0122592, acc = 1.0
[Validation] Batch ID = 16200, loss = 0.0306249, acc = 1.0
[Train] Batch ID = 16210, loss = 0.194817, acc = 0.8
[Validation] Batch ID = 16210, loss = 0.0383178, acc = 0.98
[Train] Batch ID = 16220, loss = 0.179779, acc = 0.8
[Validation] Batch ID = 16220, loss = 0.0444652, acc = 0.98
[Train] Batch ID = 16230, loss = 0.0114048, acc = 1.0
[Validation] Batch ID = 16230, loss = 0.0371979, acc = 0.98
[Train] Batch ID = 16240, loss = 0.00890548, acc = 1.0
[Validation] Batch ID = 16240, loss = 0.0296927, acc = 0.98
[Train] Batch ID = 16250, loss = 0.183314, acc = 0.88
[Validation] Batch ID = 16250, loss = 0.0376843, acc = 0.98
[Train] Batch ID = 16260, loss = 0.260523, acc = 0.72
[Validation] Batch ID = 16260, loss = 0.0430788, acc = 0.98
[Train] Batch ID = 16270, loss = 0.0131867, acc = 1.0
[Validation] Batch ID = 16270, loss = 0.0637037, acc = 0.92
[Train] Batch ID = 16280, loss = 0.0142716, acc = 1.0
[Validation] Batch ID = 16280, loss = 0.0570839, acc = 0.94
[Train] Batch ID = 16290, loss = 0.0122782, acc = 1.0
[Validation] Batch ID = 16290, loss = 0.0537266, acc = 0.98
[Train] Batch ID = 16300, loss = 0.0126009, acc = 1.0
[Validation] Batch ID = 16300, loss = 0.0448658, acc = 0.98
[Train] Batch ID = 16310, loss = 0.0157917, acc = 1.0
[Validation] Batch ID = 16310, loss = 0.0605974, acc = 0.94
[Train] Batch ID = 16320, loss = 0.0139092, acc = 1.0
[Validation] Batch ID = 16320, loss = 0.0395077, acc = 0.96
[Train] Batch ID = 16330, loss = 0.0116256, acc = 1.0
[Validation] Batch ID = 16330, loss = 0.0686646, acc = 0.96
[Train] Batch ID = 16340, loss = 0.00698763, acc = 1.0
[Validation] Batch ID = 16340, loss = 0.0281766, acc = 1.0
[Train] Batch ID = 16350, loss = 0.011349, acc = 1.0
[Validation] Batch ID = 16350, loss = 0.0491005, acc = 0.98
[Train] Batch ID = 16360, loss = 0.0121404, acc = 1.0
[Validation] Batch ID = 16360, loss = 0.0712704, acc = 0.92
[Train] Batch ID = 16370, loss = 0.0123089, acc = 1.0
[Validation] Batch ID = 16370, loss = 0.0956472, acc = 0.88
[Train] Batch ID = 16380, loss = 0.00964068, acc = 1.0
[Validation] Batch ID = 16380, loss = 0.0643815, acc = 0.9
[Train] Batch ID = 16390, loss = 0.00782296, acc = 1.0
[Validation] Batch ID = 16390, loss = 0.0672783, acc = 0.92
[Train] Batch ID = 16400, loss = 0.209254, acc = 0.84
[Validation] Batch ID = 16400, loss = 0.0990469, acc = 0.9
[Train] Batch ID = 16410, loss = 0.00927037, acc = 1.0
[Validation] Batch ID = 16410, loss = 0.029404, acc = 1.0
[Train] Batch ID = 16420, loss = 0.00645013, acc = 1.0
[Validation] Batch ID = 16420, loss = 0.0471549, acc = 0.96
[Train] Batch ID = 16430, loss = 0.00995546, acc = 1.0
[Validation] Batch ID = 16430, loss = 0.0460424, acc = 0.98
[Train] Batch ID = 16440, loss = 0.0174432, acc = 1.0
[Validation] Batch ID = 16440, loss = 0.0486032, acc = 0.98
[Train] Batch ID = 16450, loss = 0.00793474, acc = 1.0
[Validation] Batch ID = 16450, loss = 0.0646354, acc = 0.96
[Train] Batch ID = 16460, loss = 0.238787, acc = 0.74
[Validation] Batch ID = 16460, loss = 0.065985, acc = 0.94
[Train] Batch ID = 16470, loss = 0.214727, acc = 0.82
[Validation] Batch ID = 16470, loss = 0.0448887, acc = 0.98
[Train] Batch ID = 16480, loss = 0.00809389, acc = 1.0
[Validation] Batch ID = 16480, loss = 0.051358, acc = 0.96
[Train] Batch ID = 16490, loss = 0.0119758, acc = 1.0
[Validation] Batch ID = 16490, loss = 0.0277735, acc = 1.0
[Train] Batch ID = 16500, loss = 0.0142311, acc = 1.0
[Validation] Batch ID = 16500, loss = 0.0499849, acc = 0.96
[Train] Batch ID = 16510, loss = 0.0115587, acc = 1.0
[Validation] Batch ID = 16510, loss = 0.0305036, acc = 0.98
[Train] Batch ID = 16520, loss = 0.0161015, acc = 1.0
[Validation] Batch ID = 16520, loss = 0.0391198, acc = 1.0
[Train] Batch ID = 16530, loss = 0.210369, acc = 0.84
[Validation] Batch ID = 16530, loss = 0.0350899, acc = 0.98
[Train] Batch ID = 16540, loss = 0.012747, acc = 1.0
[Validation] Batch ID = 16540, loss = 0.0366477, acc = 1.0
[Train] Batch ID = 16550, loss = 0.021012, acc = 1.0
[Validation] Batch ID = 16550, loss = 0.0467369, acc = 0.96
[Train] Batch ID = 16560, loss = 0.00634157, acc = 1.0
[Validation] Batch ID = 16560, loss = 0.0519444, acc = 0.98
[Train] Batch ID = 16570, loss = 0.0083133, acc = 1.0
[Validation] Batch ID = 16570, loss = 0.0292467, acc = 1.0
[Train] Batch ID = 16580, loss = 0.00835137, acc = 1.0
[Validation] Batch ID = 16580, loss = 0.0394915, acc = 0.98
[Train] Batch ID = 16590, loss = 0.00580469, acc = 1.0
[Validation] Batch ID = 16590, loss = 0.0621927, acc = 0.9
[Train] Batch ID = 16600, loss = 0.01922, acc = 1.0
[Validation] Batch ID = 16600, loss = 0.0520019, acc = 0.96
[Train] Batch ID = 16610, loss = 0.0078655, acc = 1.0
[Validation] Batch ID = 16610, loss = 0.0392148, acc = 0.98
[Train] Batch ID = 16620, loss = 0.19014, acc = 0.86
[Validation] Batch ID = 16620, loss = 0.0618087, acc = 0.94
[Train] Batch ID = 16630, loss = 0.0185664, acc = 1.0
[Validation] Batch ID = 16630, loss = 0.0418871, acc = 0.96
[Train] Batch ID = 16640, loss = 0.0106119, acc = 1.0
[Validation] Batch ID = 16640, loss = 0.0418145, acc = 0.96
[Train] Batch ID = 16650, loss = 0.0110694, acc = 1.0
[Validation] Batch ID = 16650, loss = 0.0351152, acc = 1.0
[Train] Batch ID = 16660, loss = 0.018404, acc = 1.0
[Validation] Batch ID = 16660, loss = 0.0444471, acc = 0.96
[Train] Batch ID = 16670, loss = 0.0111381, acc = 1.0
[Validation] Batch ID = 16670, loss = 0.0301699, acc = 1.0
[Train] Batch ID = 16680, loss = 0.00807489, acc = 1.0
[Validation] Batch ID = 16680, loss = 0.0485798, acc = 0.94
[Train] Batch ID = 16690, loss = 0.0116735, acc = 1.0
[Validation] Batch ID = 16690, loss = 0.0488661, acc = 0.98
[Train] Batch ID = 16700, loss = 0.00896963, acc = 1.0
[Validation] Batch ID = 16700, loss = 0.0274078, acc = 1.0
[Train] Batch ID = 16710, loss = 0.0111859, acc = 1.0
[Validation] Batch ID = 16710, loss = 0.0345827, acc = 0.98
[Train] Batch ID = 16720, loss = 0.0142488, acc = 1.0
[Validation] Batch ID = 16720, loss = 0.0425249, acc = 0.96
[Train] Batch ID = 16730, loss = 0.0101594, acc = 1.0
[Validation] Batch ID = 16730, loss = 0.0519483, acc = 0.94
[Train] Batch ID = 16740, loss = 0.00984201, acc = 1.0
[Validation] Batch ID = 16740, loss = 0.0328203, acc = 0.98
[Train] Batch ID = 16750, loss = 0.0150954, acc = 1.0
[Validation] Batch ID = 16750, loss = 0.0468718, acc = 0.94
[Train] Batch ID = 16760, loss = 0.179914, acc = 0.86
[Validation] Batch ID = 16760, loss = 0.036911, acc = 0.98
[Train] Batch ID = 16770, loss = 0.0173769, acc = 1.0
[Validation] Batch ID = 16770, loss = 0.0518868, acc = 0.94
[Train] Batch ID = 16780, loss = 0.0145045, acc = 1.0
[Validation] Batch ID = 16780, loss = 0.0405632, acc = 0.98
[Train] Batch ID = 16790, loss = 0.0131199, acc = 1.0
[Validation] Batch ID = 16790, loss = 0.0577672, acc = 0.92
[Train] Batch ID = 16800, loss = 0.183624, acc = 0.86
[Validation] Batch ID = 16800, loss = 0.0539635, acc = 0.96
[Train] Batch ID = 16810, loss = 0.0143922, acc = 1.0
[Validation] Batch ID = 16810, loss = 0.027719, acc = 1.0
[Train] Batch ID = 16820, loss = 0.0204897, acc = 1.0
[Validation] Batch ID = 16820, loss = 0.0182774, acc = 1.0
[Train] Batch ID = 16830, loss = 0.243592, acc = 0.76
[Validation] Batch ID = 16830, loss = 0.0399112, acc = 1.0
[Train] Batch ID = 16840, loss = 0.0157409, acc = 1.0
[Validation] Batch ID = 16840, loss = 0.0852602, acc = 0.9
[Train] Batch ID = 16850, loss = 0.234445, acc = 0.78
[Validation] Batch ID = 16850, loss = 0.0337557, acc = 1.0
[Train] Batch ID = 16860, loss = 0.0186027, acc = 0.98
[Validation] Batch ID = 16860, loss = 0.0637741, acc = 0.92
[Train] Batch ID = 16870, loss = 0.214686, acc = 0.82
[Validation] Batch ID = 16870, loss = 0.0344707, acc = 1.0
[Train] Batch ID = 16880, loss = 0.0162625, acc = 1.0
[Validation] Batch ID = 16880, loss = 0.0606221, acc = 0.92
[Train] Batch ID = 16890, loss = 0.0084759, acc = 1.0
[Validation] Batch ID = 16890, loss = 0.045178, acc = 0.98
[Train] Batch ID = 16900, loss = 0.0101897, acc = 1.0
[Validation] Batch ID = 16900, loss = 0.0283651, acc = 1.0
[Train] Batch ID = 16910, loss = 0.224305, acc = 0.68
[Validation] Batch ID = 16910, loss = 0.0467173, acc = 0.98
[Train] Batch ID = 16920, loss = 0.00930812, acc = 1.0
[Validation] Batch ID = 16920, loss = 0.0478665, acc = 0.98
[Train] Batch ID = 16930, loss = 0.017007, acc = 1.0
[Validation] Batch ID = 16930, loss = 0.0472921, acc = 1.0
[Train] Batch ID = 16940, loss = 0.0108301, acc = 1.0
[Validation] Batch ID = 16940, loss = 0.0370016, acc = 0.96
[Train] Batch ID = 16950, loss = 0.226896, acc = 0.82
[Validation] Batch ID = 16950, loss = 0.038037, acc = 0.96
[Train] Batch ID = 16960, loss = 0.198158, acc = 0.84
[Validation] Batch ID = 16960, loss = 0.0307961, acc = 0.98
[Train] Batch ID = 16970, loss = 0.0169276, acc = 1.0
[Validation] Batch ID = 16970, loss = 0.0791598, acc = 0.94
[Train] Batch ID = 16980, loss = 0.00820132, acc = 1.0
[Validation] Batch ID = 16980, loss = 0.0363663, acc = 0.98
[Train] Batch ID = 16990, loss = 0.00814005, acc = 1.0
[Validation] Batch ID = 16990, loss = 0.049557, acc = 0.94
[Train] Batch ID = 17000, loss = 0.0081375, acc = 1.0
[Validation] Batch ID = 17000, loss = 0.0368923, acc = 0.98
Evaluate full validation dataset ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Saving model ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Current loss: 0.0435779 Best loss: 0.0446877
[TOTAL Validation] Batch ID = 17000, loss = 0.0435779, acc = 0.968480725624
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Model successfully saved here: outputs/checkpoints/c1s_9_c1n_256_c2s_6_c2n_64_c2d_0.7_c1vl_16_c1s_5_c1nf_16_c2vl_32_lr_0.0001_rs_1--TrafficSign--1510487290.423481
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Augmented Factor = 0.1485936889440292
[Train] Batch ID = 17010, loss = 0.0107931, acc = 1.0
[Validation] Batch ID = 17010, loss = 0.0318854, acc = 0.98
[Train] Batch ID = 17020, loss = 0.0109536, acc = 1.0
[Validation] Batch ID = 17020, loss = 0.0277872, acc = 1.0
[Train] Batch ID = 17030, loss = 0.00786561, acc = 1.0
[Validation] Batch ID = 17030, loss = 0.0407727, acc = 0.96
[Train] Batch ID = 17040, loss = 0.0107863, acc = 1.0
[Validation] Batch ID = 17040, loss = 0.0496761, acc = 0.96
[Train] Batch ID = 17050, loss = 0.0155346, acc = 1.0
[Validation] Batch ID = 17050, loss = 0.0519211, acc = 0.94
[Train] Batch ID = 17060, loss = 0.00993681, acc = 1.0
[Validation] Batch ID = 17060, loss = 0.0298174, acc = 1.0
[Train] Batch ID = 17070, loss = 0.0140413, acc = 1.0
[Validation] Batch ID = 17070, loss = 0.0674547, acc = 0.92
[Train] Batch ID = 17080, loss = 0.217565, acc = 0.78
[Validation] Batch ID = 17080, loss = 0.0296709, acc = 0.98
[Train] Batch ID = 17090, loss = 0.00863693, acc = 1.0
[Validation] Batch ID = 17090, loss = 0.0712167, acc = 0.96
[Train] Batch ID = 17100, loss = 0.20093, acc = 0.82
[Validation] Batch ID = 17100, loss = 0.041432, acc = 0.98
[Train] Batch ID = 17110, loss = 0.0140526, acc = 1.0
[Validation] Batch ID = 17110, loss = 0.0345174, acc = 1.0
[Train] Batch ID = 17120, loss = 0.0120637, acc = 1.0
[Validation] Batch ID = 17120, loss = 0.0408866, acc = 0.98
[Train] Batch ID = 17130, loss = 0.0109781, acc = 1.0
[Validation] Batch ID = 17130, loss = 0.0650348, acc = 0.94
[Train] Batch ID = 17140, loss = 0.0122201, acc = 1.0
[Validation] Batch ID = 17140, loss = 0.0626181, acc = 0.96
[Train] Batch ID = 17150, loss = 0.00975302, acc = 1.0
[Validation] Batch ID = 17150, loss = 0.0617188, acc = 0.94
[Train] Batch ID = 17160, loss = 0.0132185, acc = 1.0
[Validation] Batch ID = 17160, loss = 0.0202728, acc = 1.0
[Train] Batch ID = 17170, loss = 0.00865579, acc = 1.0
[Validation] Batch ID = 17170, loss = 0.0396759, acc = 0.98
[Train] Batch ID = 17180, loss = 0.0110322, acc = 1.0
[Validation] Batch ID = 17180, loss = 0.0308778, acc = 0.98
[Train] Batch ID = 17190, loss = 0.0132692, acc = 1.0
[Validation] Batch ID = 17190, loss = 0.0445969, acc = 0.98
[Train] Batch ID = 17200, loss = 0.241525, acc = 0.72
[Validation] Batch ID = 17200, loss = 0.065758, acc = 0.92
[Train] Batch ID = 17210, loss = 0.0126124, acc = 1.0
[Validation] Batch ID = 17210, loss = 0.0751484, acc = 0.94
[Train] Batch ID = 17220, loss = 0.00790253, acc = 1.0
[Validation] Batch ID = 17220, loss = 0.0541396, acc = 0.96
[Train] Batch ID = 17230, loss = 0.00621506, acc = 1.0
[Validation] Batch ID = 17230, loss = 0.0347628, acc = 0.96
[Train] Batch ID = 17240, loss = 0.00727094, acc = 1.0
[Validation] Batch ID = 17240, loss = 0.0255589, acc = 0.96
[Train] Batch ID = 17250, loss = 0.0104037, acc = 1.0
[Validation] Batch ID = 17250, loss = 0.0229335, acc = 1.0
[Train] Batch ID = 17260, loss = 0.0103698, acc = 1.0
[Validation] Batch ID = 17260, loss = 0.0467634, acc = 0.98
[Train] Batch ID = 17270, loss = 0.00828369, acc = 1.0
[Validation] Batch ID = 17270, loss = 0.0585737, acc = 0.94
[Train] Batch ID = 17280, loss = 0.179058, acc = 0.9
[Validation] Batch ID = 17280, loss = 0.0597991, acc = 0.98
[Train] Batch ID = 17290, loss = 0.00742065, acc = 1.0
[Validation] Batch ID = 17290, loss = 0.0498983, acc = 0.96
[Train] Batch ID = 17300, loss = 0.245728, acc = 0.74
[Validation] Batch ID = 17300, loss = 0.0277732, acc = 0.98
[Train] Batch ID = 17310, loss = 0.00789817, acc = 1.0
[Validation] Batch ID = 17310, loss = 0.0597185, acc = 0.94
[Train] Batch ID = 17320, loss = 0.010345, acc = 1.0
[Validation] Batch ID = 17320, loss = 0.0651575, acc = 0.96
[Train] Batch ID = 17330, loss = 0.00746422, acc = 1.0
[Validation] Batch ID = 17330, loss = 0.0401043, acc = 0.98
[Train] Batch ID = 17340, loss = 0.0135294, acc = 1.0
[Validation] Batch ID = 17340, loss = 0.0378934, acc = 0.98
[Train] Batch ID = 17350, loss = 0.0118037, acc = 1.0
[Validation] Batch ID = 17350, loss = 0.0403616, acc = 0.98
[Train] Batch ID = 17360, loss = 0.0112704, acc = 1.0
[Validation] Batch ID = 17360, loss = 0.0357777, acc = 1.0
[Train] Batch ID = 17370, loss = 0.191618, acc = 0.82
[Validation] Batch ID = 17370, loss = 0.0622186, acc = 0.94
[Train] Batch ID = 17380, loss = 0.0141367, acc = 1.0
[Validation] Batch ID = 17380, loss = 0.0298234, acc = 1.0
[Train] Batch ID = 17390, loss = 0.0175016, acc = 1.0
[Validation] Batch ID = 17390, loss = 0.0641619, acc = 0.96
[Train] Batch ID = 17400, loss = 0.0072694, acc = 1.0
[Validation] Batch ID = 17400, loss = 0.0466642, acc = 0.98
[Train] Batch ID = 17410, loss = 0.011422, acc = 1.0
[Validation] Batch ID = 17410, loss = 0.0353274, acc = 1.0
[Train] Batch ID = 17420, loss = 0.0119721, acc = 1.0
[Validation] Batch ID = 17420, loss = 0.0465965, acc = 0.96
[Train] Batch ID = 17430, loss = 0.00625932, acc = 1.0
[Validation] Batch ID = 17430, loss = 0.0244258, acc = 1.0
[Train] Batch ID = 17440, loss = 0.00958698, acc = 1.0
[Validation] Batch ID = 17440, loss = 0.0269825, acc = 1.0
[Train] Batch ID = 17450, loss = 0.0070188, acc = 1.0
[Validation] Batch ID = 17450, loss = 0.0598431, acc = 0.98
[Train] Batch ID = 17460, loss = 0.00640655, acc = 1.0
[Validation] Batch ID = 17460, loss = 0.0411862, acc = 0.98
[Train] Batch ID = 17470, loss = 0.0106687, acc = 1.0
[Validation] Batch ID = 17470, loss = 0.0309782, acc = 1.0
[Train] Batch ID = 17480, loss = 0.0110399, acc = 1.0
[Validation] Batch ID = 17480, loss = 0.0643484, acc = 0.96
[Train] Batch ID = 17490, loss = 0.00764425, acc = 1.0
[Validation] Batch ID = 17490, loss = 0.0594735, acc = 0.94
[Train] Batch ID = 17500, loss = 0.00851075, acc = 1.0
[Validation] Batch ID = 17500, loss = 0.0382578, acc = 0.98
[Train] Batch ID = 17510, loss = 0.0128806, acc = 1.0
[Validation] Batch ID = 17510, loss = 0.0272577, acc = 1.0
[Train] Batch ID = 17520, loss = 0.181398, acc = 0.88
[Validation] Batch ID = 17520, loss = 0.0683395, acc = 0.96
[Train] Batch ID = 17530, loss = 0.21577, acc = 0.82
[Validation] Batch ID = 17530, loss = 0.0424599, acc = 0.98
[Train] Batch ID = 17540, loss = 0.0119789, acc = 1.0
[Validation] Batch ID = 17540, loss = 0.0777235, acc = 0.94
[Train] Batch ID = 17550, loss = 0.00911315, acc = 1.0
[Validation] Batch ID = 17550, loss = 0.017616, acc = 1.0
[Train] Batch ID = 17560, loss = 0.0131789, acc = 1.0
[Validation] Batch ID = 17560, loss = 0.0178919, acc = 1.0
[Train] Batch ID = 17570, loss = 0.0114378, acc = 1.0
[Validation] Batch ID = 17570, loss = 0.0814161, acc = 0.92
[Train] Batch ID = 17580, loss = 0.00718676, acc = 1.0
[Validation] Batch ID = 17580, loss = 0.0632809, acc = 0.94
[Train] Batch ID = 17590, loss = 0.00754958, acc = 1.0
[Validation] Batch ID = 17590, loss = 0.0332366, acc = 0.96
[Train] Batch ID = 17600, loss = 0.00954201, acc = 1.0
[Validation] Batch ID = 17600, loss = 0.0600804, acc = 0.94
[Train] Batch ID = 17610, loss = 0.0107443, acc = 1.0
[Validation] Batch ID = 17610, loss = 0.0401182, acc = 0.96
[Train] Batch ID = 17620, loss = 0.0090585, acc = 1.0
[Validation] Batch ID = 17620, loss = 0.0504681, acc = 0.98
[Train] Batch ID = 17630, loss = 0.00620363, acc = 1.0
[Validation] Batch ID = 17630, loss = 0.0467663, acc = 0.96
[Train] Batch ID = 17640, loss = 0.243305, acc = 0.78
[Validation] Batch ID = 17640, loss = 0.0646638, acc = 0.94
[Train] Batch ID = 17650, loss = 0.00837727, acc = 1.0
[Validation] Batch ID = 17650, loss = 0.0542992, acc = 0.98
[Train] Batch ID = 17660, loss = 0.00657543, acc = 1.0
[Validation] Batch ID = 17660, loss = 0.0562306, acc = 0.94
[Train] Batch ID = 17670, loss = 0.00969348, acc = 1.0
[Validation] Batch ID = 17670, loss = 0.0492313, acc = 0.96
[Train] Batch ID = 17680, loss = 0.235892, acc = 0.76
[Validation] Batch ID = 17680, loss = 0.0447485, acc = 0.94
[Train] Batch ID = 17690, loss = 0.169564, acc = 0.92
[Validation] Batch ID = 17690, loss = 0.0392783, acc = 0.98
[Train] Batch ID = 17700, loss = 0.0122359, acc = 1.0
[Validation] Batch ID = 17700, loss = 0.0245898, acc = 1.0
[Train] Batch ID = 17710, loss = 0.213004, acc = 0.86
[Validation] Batch ID = 17710, loss = 0.0592501, acc = 0.9
[Train] Batch ID = 17720, loss = 0.00919184, acc = 1.0
[Validation] Batch ID = 17720, loss = 0.0399713, acc = 0.98
[Train] Batch ID = 17730, loss = 0.012463, acc = 1.0
[Validation] Batch ID = 17730, loss = 0.0385852, acc = 0.98
[Train] Batch ID = 17740, loss = 0.00961185, acc = 1.0
[Validation] Batch ID = 17740, loss = 0.0605806, acc = 0.94
[Train] Batch ID = 17750, loss = 0.200566, acc = 0.84
[Validation] Batch ID = 17750, loss = 0.0392167, acc = 0.98
[Train] Batch ID = 17760, loss = 0.00691875, acc = 1.0
[Validation] Batch ID = 17760, loss = 0.0328109, acc = 0.98
[Train] Batch ID = 17770, loss = 0.0101364, acc = 1.0
[Validation] Batch ID = 17770, loss = 0.0231473, acc = 1.0
[Train] Batch ID = 17780, loss = 0.00475077, acc = 1.0
[Validation] Batch ID = 17780, loss = 0.0316256, acc = 0.98
[Train] Batch ID = 17790, loss = 0.006053, acc = 1.0
[Validation] Batch ID = 17790, loss = 0.0335807, acc = 1.0
[Train] Batch ID = 17800, loss = 0.0114584, acc = 1.0
[Validation] Batch ID = 17800, loss = 0.0660712, acc = 0.96
[Train] Batch ID = 17810, loss = 0.00913265, acc = 1.0
[Validation] Batch ID = 17810, loss = 0.0580074, acc = 0.94
[Train] Batch ID = 17820, loss = 0.00934535, acc = 1.0
[Validation] Batch ID = 17820, loss = 0.0443817, acc = 0.96
[Train] Batch ID = 17830, loss = 0.0105927, acc = 1.0
[Validation] Batch ID = 17830, loss = 0.037933, acc = 0.98
[Train] Batch ID = 17840, loss = 0.0131286, acc = 1.0
[Validation] Batch ID = 17840, loss = 0.0540507, acc = 0.94
[Train] Batch ID = 17850, loss = 0.00584333, acc = 1.0
[Validation] Batch ID = 17850, loss = 0.0281537, acc = 0.98
[Train] Batch ID = 17860, loss = 0.00587972, acc = 1.0
[Validation] Batch ID = 17860, loss = 0.0236906, acc = 1.0
[Train] Batch ID = 17870, loss = 0.00535287, acc = 1.0
[Validation] Batch ID = 17870, loss = 0.0585847, acc = 0.92
[Train] Batch ID = 17880, loss = 0.0116786, acc = 1.0
[Validation] Batch ID = 17880, loss = 0.0466213, acc = 0.96
[Train] Batch ID = 17890, loss = 0.00497176, acc = 1.0
[Validation] Batch ID = 17890, loss = 0.047242, acc = 0.96
[Train] Batch ID = 17900, loss = 0.0107329, acc = 1.0
[Validation] Batch ID = 17900, loss = 0.0431746, acc = 0.94
[Train] Batch ID = 17910, loss = 0.0166263, acc = 1.0
[Validation] Batch ID = 17910, loss = 0.0702424, acc = 0.94
[Train] Batch ID = 17920, loss = 0.014938, acc = 0.98
[Validation] Batch ID = 17920, loss = 0.0423169, acc = 0.96
[Train] Batch ID = 17930, loss = 0.0104178, acc = 1.0
[Validation] Batch ID = 17930, loss = 0.0258603, acc = 1.0
[Train] Batch ID = 17940, loss = 0.012507, acc = 1.0
[Validation] Batch ID = 17940, loss = 0.0350385, acc = 0.96
[Train] Batch ID = 17950, loss = 0.00797606, acc = 1.0
[Validation] Batch ID = 17950, loss = 0.03458, acc = 0.98
[Train] Batch ID = 17960, loss = 0.00722717, acc = 1.0
[Validation] Batch ID = 17960, loss = 0.0523331, acc = 1.0
[Train] Batch ID = 17970, loss = 0.185005, acc = 0.88
[Validation] Batch ID = 17970, loss = 0.0382238, acc = 0.96
[Train] Batch ID = 17980, loss = 0.0193121, acc = 1.0
[Validation] Batch ID = 17980, loss = 0.072578, acc = 0.92
[Train] Batch ID = 17990, loss = 0.210694, acc = 0.8
[Validation] Batch ID = 17990, loss = 0.0476215, acc = 0.98
[Train] Batch ID = 18000, loss = 0.0102234, acc = 1.0
[Validation] Batch ID = 18000, loss = 0.0604841, acc = 0.96
Evaluate full validation dataset ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Saving model ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Current loss: 0.0424544 Best loss: 0.0435779
[TOTAL Validation] Batch ID = 18000, loss = 0.0424544, acc = 0.971655328798
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Model successfully saved here: outputs/checkpoints/c1s_9_c1n_256_c2s_6_c2n_64_c2d_0.7_c1vl_16_c1s_5_c1nf_16_c2vl_32_lr_0.0001_rs_1--TrafficSign--1510487290.423481
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Augmented Factor = 0.13373432004962627
[Train] Batch ID = 18010, loss = 0.228132, acc = 0.86
[Validation] Batch ID = 18010, loss = 0.0244347, acc = 0.98
[Train] Batch ID = 18020, loss = 0.0103401, acc = 1.0
[Validation] Batch ID = 18020, loss = 0.0459979, acc = 0.96
[Train] Batch ID = 18030, loss = 0.0149227, acc = 1.0
[Validation] Batch ID = 18030, loss = 0.0525117, acc = 0.96
[Train] Batch ID = 18040, loss = 0.0111569, acc = 1.0
[Validation] Batch ID = 18040, loss = 0.0251993, acc = 1.0
[Train] Batch ID = 18050, loss = 0.250529, acc = 0.74
[Validation] Batch ID = 18050, loss = 0.0445635, acc = 0.96
[Train] Batch ID = 18060, loss = 0.0100271, acc = 1.0
[Validation] Batch ID = 18060, loss = 0.0301659, acc = 1.0
[Train] Batch ID = 18070, loss = 0.0148217, acc = 1.0
[Validation] Batch ID = 18070, loss = 0.0297111, acc = 0.98
[Train] Batch ID = 18080, loss = 0.0102784, acc = 1.0
[Validation] Batch ID = 18080, loss = 0.0589889, acc = 0.96
[Train] Batch ID = 18090, loss = 0.24178, acc = 0.74
[Validation] Batch ID = 18090, loss = 0.0485644, acc = 1.0
[Train] Batch ID = 18100, loss = 0.00797078, acc = 1.0
[Validation] Batch ID = 18100, loss = 0.0756436, acc = 0.9
[Train] Batch ID = 18110, loss = 0.00493511, acc = 1.0
[Validation] Batch ID = 18110, loss = 0.015748, acc = 1.0
[Train] Batch ID = 18120, loss = 0.00914968, acc = 1.0
[Validation] Batch ID = 18120, loss = 0.0473936, acc = 0.96
[Train] Batch ID = 18130, loss = 0.00809062, acc = 1.0
[Validation] Batch ID = 18130, loss = 0.0370665, acc = 0.96
[Train] Batch ID = 18140, loss = 0.00731355, acc = 1.0
[Validation] Batch ID = 18140, loss = 0.0351754, acc = 0.98
[Train] Batch ID = 18150, loss = 0.0109304, acc = 1.0
[Validation] Batch ID = 18150, loss = 0.0272152, acc = 1.0
[Train] Batch ID = 18160, loss = 0.00475705, acc = 1.0
[Validation] Batch ID = 18160, loss = 0.0466098, acc = 1.0
[Train] Batch ID = 18170, loss = 0.00650133, acc = 1.0
[Validation] Batch ID = 18170, loss = 0.0490063, acc = 0.96
[Train] Batch ID = 18180, loss = 0.0164809, acc = 1.0
[Validation] Batch ID = 18180, loss = 0.0403389, acc = 1.0
[Train] Batch ID = 18190, loss = 0.00604222, acc = 1.0
[Validation] Batch ID = 18190, loss = 0.0182917, acc = 1.0
[Train] Batch ID = 18200, loss = 0.220453, acc = 0.78
[Validation] Batch ID = 18200, loss = 0.047733, acc = 0.98
[Train] Batch ID = 18210, loss = 0.0157971, acc = 1.0
[Validation] Batch ID = 18210, loss = 0.0375407, acc = 0.98
[Train] Batch ID = 18220, loss = 0.0107326, acc = 1.0
[Validation] Batch ID = 18220, loss = 0.0402672, acc = 1.0
[Train] Batch ID = 18230, loss = 0.213379, acc = 0.84
[Validation] Batch ID = 18230, loss = 0.0510303, acc = 0.94
[Train] Batch ID = 18240, loss = 0.0106287, acc = 1.0
[Validation] Batch ID = 18240, loss = 0.0276124, acc = 1.0
[Train] Batch ID = 18250, loss = 0.00733206, acc = 1.0
[Validation] Batch ID = 18250, loss = 0.0329807, acc = 1.0
[Train] Batch ID = 18260, loss = 0.00668964, acc = 1.0
[Validation] Batch ID = 18260, loss = 0.0308212, acc = 0.98
[Train] Batch ID = 18270, loss = 0.0122097, acc = 1.0
[Validation] Batch ID = 18270, loss = 0.0462206, acc = 0.96
[Train] Batch ID = 18280, loss = 0.00854039, acc = 1.0
[Validation] Batch ID = 18280, loss = 0.0362162, acc = 0.96
[Train] Batch ID = 18290, loss = 0.0117648, acc = 1.0
[Validation] Batch ID = 18290, loss = 0.0349981, acc = 1.0
[Train] Batch ID = 18300, loss = 0.011895, acc = 1.0
[Validation] Batch ID = 18300, loss = 0.0329333, acc = 1.0
[Train] Batch ID = 18310, loss = 0.00626644, acc = 1.0
[Validation] Batch ID = 18310, loss = 0.0225427, acc = 1.0
[Train] Batch ID = 18320, loss = 0.00833453, acc = 1.0
[Validation] Batch ID = 18320, loss = 0.0225264, acc = 1.0
[Train] Batch ID = 18330, loss = 0.013801, acc = 1.0
[Validation] Batch ID = 18330, loss = 0.0280655, acc = 0.98
[Train] Batch ID = 18340, loss = 0.00765351, acc = 1.0
[Validation] Batch ID = 18340, loss = 0.0180686, acc = 1.0
[Train] Batch ID = 18350, loss = 0.00608416, acc = 1.0
[Validation] Batch ID = 18350, loss = 0.0304539, acc = 1.0
[Train] Batch ID = 18360, loss = 0.00620292, acc = 1.0
[Validation] Batch ID = 18360, loss = 0.0335051, acc = 0.96
[Train] Batch ID = 18370, loss = 0.00804905, acc = 1.0
[Validation] Batch ID = 18370, loss = 0.0382686, acc = 0.96
[Train] Batch ID = 18380, loss = 0.014835, acc = 0.98
[Validation] Batch ID = 18380, loss = 0.0437417, acc = 0.94
[Train] Batch ID = 18390, loss = 0.230178, acc = 0.76
[Validation] Batch ID = 18390, loss = 0.0205305, acc = 1.0
[Train] Batch ID = 18400, loss = 0.183337, acc = 0.84
[Validation] Batch ID = 18400, loss = 0.046115, acc = 0.96
[Train] Batch ID = 18410, loss = 0.00778262, acc = 1.0
[Validation] Batch ID = 18410, loss = 0.0280853, acc = 0.98
[Train] Batch ID = 18420, loss = 0.201551, acc = 0.72
[Validation] Batch ID = 18420, loss = 0.0263137, acc = 0.96
[Train] Batch ID = 18430, loss = 0.00607394, acc = 1.0
[Validation] Batch ID = 18430, loss = 0.0471367, acc = 0.96
[Train] Batch ID = 18440, loss = 0.00964198, acc = 1.0
[Validation] Batch ID = 18440, loss = 0.0473484, acc = 0.94
[Train] Batch ID = 18450, loss = 0.0042911, acc = 1.0
[Validation] Batch ID = 18450, loss = 0.0646073, acc = 0.94
[Train] Batch ID = 18460, loss = 0.00649284, acc = 1.0
[Validation] Batch ID = 18460, loss = 0.0558958, acc = 0.94
[Train] Batch ID = 18470, loss = 0.0162379, acc = 1.0
[Validation] Batch ID = 18470, loss = 0.0218326, acc = 1.0
[Train] Batch ID = 18480, loss = 0.0116299, acc = 1.0
[Validation] Batch ID = 18480, loss = 0.0293012, acc = 0.98
[Train] Batch ID = 18490, loss = 0.0133133, acc = 1.0
[Validation] Batch ID = 18490, loss = 0.0419711, acc = 0.98
[Train] Batch ID = 18500, loss = 0.0123012, acc = 1.0
[Validation] Batch ID = 18500, loss = 0.0285383, acc = 1.0
[Train] Batch ID = 18510, loss = 0.00774852, acc = 1.0
[Validation] Batch ID = 18510, loss = 0.0563268, acc = 0.94
[Train] Batch ID = 18520, loss = 0.221411, acc = 0.8
[Validation] Batch ID = 18520, loss = 0.0546522, acc = 0.96
[Train] Batch ID = 18530, loss = 0.00624003, acc = 1.0
[Validation] Batch ID = 18530, loss = 0.0299986, acc = 0.98
[Train] Batch ID = 18540, loss = 0.239112, acc = 0.7
[Validation] Batch ID = 18540, loss = 0.0338565, acc = 1.0
[Train] Batch ID = 18550, loss = 0.213682, acc = 0.84
[Validation] Batch ID = 18550, loss = 0.0458016, acc = 0.98
[Train] Batch ID = 18560, loss = 0.0154747, acc = 1.0
[Validation] Batch ID = 18560, loss = 0.0197975, acc = 1.0
[Train] Batch ID = 18570, loss = 0.0101185, acc = 1.0
[Validation] Batch ID = 18570, loss = 0.0197229, acc = 1.0
[Train] Batch ID = 18580, loss = 0.00850679, acc = 1.0
[Validation] Batch ID = 18580, loss = 0.0431962, acc = 0.98
[Train] Batch ID = 18590, loss = 0.0120361, acc = 1.0
[Validation] Batch ID = 18590, loss = 0.032789, acc = 1.0
[Train] Batch ID = 18600, loss = 0.00980887, acc = 1.0
[Validation] Batch ID = 18600, loss = 0.0222257, acc = 1.0
[Train] Batch ID = 18610, loss = 0.00594966, acc = 1.0
[Validation] Batch ID = 18610, loss = 0.0428224, acc = 0.96
[Train] Batch ID = 18620, loss = 0.00849739, acc = 1.0
[Validation] Batch ID = 18620, loss = 0.0436938, acc = 0.98
[Train] Batch ID = 18630, loss = 0.177508, acc = 0.88
[Validation] Batch ID = 18630, loss = 0.0377336, acc = 0.98
[Train] Batch ID = 18640, loss = 0.00769659, acc = 1.0
[Validation] Batch ID = 18640, loss = 0.0259619, acc = 1.0
[Train] Batch ID = 18650, loss = 0.00803511, acc = 1.0
[Validation] Batch ID = 18650, loss = 0.0653051, acc = 0.92
[Train] Batch ID = 18660, loss = 0.00975562, acc = 1.0
[Validation] Batch ID = 18660, loss = 0.0335881, acc = 0.96
[Train] Batch ID = 18670, loss = 0.199579, acc = 0.8
[Validation] Batch ID = 18670, loss = 0.0315993, acc = 0.98
[Train] Batch ID = 18680, loss = 0.01301, acc = 1.0
[Validation] Batch ID = 18680, loss = 0.0461032, acc = 0.98
[Train] Batch ID = 18690, loss = 0.0120116, acc = 1.0
[Validation] Batch ID = 18690, loss = 0.0350087, acc = 0.96
[Train] Batch ID = 18700, loss = 0.0096466, acc = 1.0
[Validation] Batch ID = 18700, loss = 0.0317747, acc = 1.0
[Train] Batch ID = 18710, loss = 0.00397952, acc = 1.0
[Validation] Batch ID = 18710, loss = 0.0408255, acc = 0.98
[Train] Batch ID = 18720, loss = 0.00825438, acc = 1.0
[Validation] Batch ID = 18720, loss = 0.0144541, acc = 1.0
[Train] Batch ID = 18730, loss = 0.00760175, acc = 1.0
[Validation] Batch ID = 18730, loss = 0.0363982, acc = 0.96
[Train] Batch ID = 18740, loss = 0.00904103, acc = 1.0
[Validation] Batch ID = 18740, loss = 0.0513596, acc = 0.96
[Train] Batch ID = 18750, loss = 0.0154375, acc = 1.0
[Validation] Batch ID = 18750, loss = 0.0225518, acc = 0.98
[Train] Batch ID = 18760, loss = 0.0088225, acc = 1.0
[Validation] Batch ID = 18760, loss = 0.0300064, acc = 0.98
[Train] Batch ID = 18770, loss = 0.0132343, acc = 1.0
[Validation] Batch ID = 18770, loss = 0.0285188, acc = 1.0
[Train] Batch ID = 18780, loss = 0.209026, acc = 0.86
[Validation] Batch ID = 18780, loss = 0.0604442, acc = 0.96
[Train] Batch ID = 18790, loss = 0.00696319, acc = 1.0
[Validation] Batch ID = 18790, loss = 0.0331932, acc = 0.96
[Train] Batch ID = 18800, loss = 0.00568265, acc = 1.0
[Validation] Batch ID = 18800, loss = 0.021478, acc = 0.98
[Train] Batch ID = 18810, loss = 0.009537, acc = 1.0
[Validation] Batch ID = 18810, loss = 0.026033, acc = 1.0
[Train] Batch ID = 18820, loss = 0.00796829, acc = 1.0
[Validation] Batch ID = 18820, loss = 0.0219744, acc = 0.98
[Train] Batch ID = 18830, loss = 0.188369, acc = 0.8
[Validation] Batch ID = 18830, loss = 0.0316925, acc = 0.98
[Train] Batch ID = 18840, loss = 0.00704996, acc = 1.0
[Validation] Batch ID = 18840, loss = 0.0356097, acc = 0.98
[Train] Batch ID = 18850, loss = 0.16931, acc = 0.9
[Validation] Batch ID = 18850, loss = 0.0395927, acc = 0.94
[Train] Batch ID = 18860, loss = 0.00776523, acc = 1.0
[Validation] Batch ID = 18860, loss = 0.0465741, acc = 0.98
[Train] Batch ID = 18870, loss = 0.00953969, acc = 1.0
[Validation] Batch ID = 18870, loss = 0.0664633, acc = 0.96
[Train] Batch ID = 18880, loss = 0.00804948, acc = 1.0
[Validation] Batch ID = 18880, loss = 0.0512156, acc = 0.94
[Train] Batch ID = 18890, loss = 0.0102249, acc = 1.0
[Validation] Batch ID = 18890, loss = 0.057554, acc = 0.96
[Train] Batch ID = 18900, loss = 0.00914846, acc = 1.0
[Validation] Batch ID = 18900, loss = 0.0496042, acc = 0.94
[Train] Batch ID = 18910, loss = 0.185639, acc = 0.86
[Validation] Batch ID = 18910, loss = 0.0385823, acc = 0.94
[Train] Batch ID = 18920, loss = 0.0103829, acc = 1.0
[Validation] Batch ID = 18920, loss = 0.0283785, acc = 0.98
[Train] Batch ID = 18930, loss = 0.0152379, acc = 1.0
[Validation] Batch ID = 18930, loss = 0.0486571, acc = 0.96
[Train] Batch ID = 18940, loss = 0.0120799, acc = 1.0
[Validation] Batch ID = 18940, loss = 0.0264706, acc = 0.96
[Train] Batch ID = 18950, loss = 0.0125708, acc = 1.0
[Validation] Batch ID = 18950, loss = 0.0302521, acc = 1.0
[Train] Batch ID = 18960, loss = 0.0109831, acc = 1.0
[Validation] Batch ID = 18960, loss = 0.0496431, acc = 0.96
[Train] Batch ID = 18970, loss = 0.00794598, acc = 1.0
[Validation] Batch ID = 18970, loss = 0.0472635, acc = 0.98
[Train] Batch ID = 18980, loss = 0.0168584, acc = 1.0
[Validation] Batch ID = 18980, loss = 0.0358551, acc = 0.98
[Train] Batch ID = 18990, loss = 0.00900583, acc = 1.0
[Validation] Batch ID = 18990, loss = 0.0343539, acc = 0.98
[Train] Batch ID = 19000, loss = 0.00812799, acc = 1.0
[Validation] Batch ID = 19000, loss = 0.049676, acc = 0.98
Evaluate full validation dataset ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Saving model ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Current loss: 0.04133 Best loss: 0.0424544
[TOTAL Validation] Batch ID = 19000, loss = 0.04133, acc = 0.968027210884
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Model successfully saved here: outputs/checkpoints/c1s_9_c1n_256_c2s_6_c2n_64_c2d_0.7_c1vl_16_c1s_5_c1nf_16_c2vl_32_lr_0.0001_rs_1--TrafficSign--1510487290.423481
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Augmented Factor = 0.12036088804466365
[Train] Batch ID = 19010, loss = 0.00829884, acc = 1.0
[Validation] Batch ID = 19010, loss = 0.0244568, acc = 0.98
[Train] Batch ID = 19020, loss = 0.00281226, acc = 1.0
[Validation] Batch ID = 19020, loss = 0.0304167, acc = 0.96
[Train] Batch ID = 19030, loss = 0.00811216, acc = 1.0
[Validation] Batch ID = 19030, loss = 0.0430402, acc = 0.94
[Train] Batch ID = 19040, loss = 0.190728, acc = 0.88
[Validation] Batch ID = 19040, loss = 0.0323349, acc = 0.98
[Train] Batch ID = 19050, loss = 0.00935074, acc = 1.0
[Validation] Batch ID = 19050, loss = 0.049192, acc = 0.96
[Train] Batch ID = 19060, loss = 0.00853486, acc = 1.0
[Validation] Batch ID = 19060, loss = 0.0433526, acc = 0.98
[Train] Batch ID = 19070, loss = 0.00619371, acc = 1.0
[Validation] Batch ID = 19070, loss = 0.0507182, acc = 0.98
[Train] Batch ID = 19080, loss = 0.0114892, acc = 1.0
[Validation] Batch ID = 19080, loss = 0.0321919, acc = 1.0
[Train] Batch ID = 19090, loss = 0.00625952, acc = 1.0
[Validation] Batch ID = 19090, loss = 0.0314531, acc = 1.0
[Train] Batch ID = 19100, loss = 0.00625073, acc = 1.0
[Validation] Batch ID = 19100, loss = 0.0509139, acc = 0.96
[Train] Batch ID = 19110, loss = 0.0149874, acc = 1.0
[Validation] Batch ID = 19110, loss = 0.0168863, acc = 1.0
[Train] Batch ID = 19120, loss = 0.00975929, acc = 1.0
[Validation] Batch ID = 19120, loss = 0.0285963, acc = 1.0
[Train] Batch ID = 19130, loss = 0.0061408, acc = 1.0
[Validation] Batch ID = 19130, loss = 0.0350475, acc = 1.0
[Train] Batch ID = 19140, loss = 0.00851196, acc = 1.0
[Validation] Batch ID = 19140, loss = 0.0522259, acc = 0.96
[Train] Batch ID = 19150, loss = 0.00802327, acc = 1.0
[Validation] Batch ID = 19150, loss = 0.026807, acc = 1.0
[Train] Batch ID = 19160, loss = 0.210208, acc = 0.78
[Validation] Batch ID = 19160, loss = 0.0298205, acc = 0.98
[Train] Batch ID = 19170, loss = 0.00617634, acc = 1.0
[Validation] Batch ID = 19170, loss = 0.035324, acc = 1.0
[Train] Batch ID = 19180, loss = 0.0102403, acc = 1.0
[Validation] Batch ID = 19180, loss = 0.031316, acc = 1.0
[Train] Batch ID = 19190, loss = 0.00891839, acc = 1.0
[Validation] Batch ID = 19190, loss = 0.0325516, acc = 0.98
[Train] Batch ID = 19200, loss = 0.00520552, acc = 1.0
[Validation] Batch ID = 19200, loss = 0.0243014, acc = 1.0
[Train] Batch ID = 19210, loss = 0.0128635, acc = 1.0
[Validation] Batch ID = 19210, loss = 0.0212604, acc = 1.0
[Train] Batch ID = 19220, loss = 0.00673032, acc = 1.0
[Validation] Batch ID = 19220, loss = 0.0321117, acc = 0.98
[Train] Batch ID = 19230, loss = 0.00621, acc = 1.0
[Validation] Batch ID = 19230, loss = 0.0308013, acc = 0.98
[Train] Batch ID = 19240, loss = 0.00514033, acc = 1.0
[Validation] Batch ID = 19240, loss = 0.0306084, acc = 0.98
[Train] Batch ID = 19250, loss = 0.00746286, acc = 1.0
[Validation] Batch ID = 19250, loss = 0.04212, acc = 0.96
[Train] Batch ID = 19260, loss = 0.00535506, acc = 1.0
[Validation] Batch ID = 19260, loss = 0.0494259, acc = 0.96
[Train] Batch ID = 19270, loss = 0.00556423, acc = 1.0
[Validation] Batch ID = 19270, loss = 0.0388948, acc = 0.96
[Train] Batch ID = 19280, loss = 0.00446363, acc = 1.0
[Validation] Batch ID = 19280, loss = 0.0445765, acc = 1.0
[Train] Batch ID = 19290, loss = 0.00513445, acc = 1.0
[Validation] Batch ID = 19290, loss = 0.032167, acc = 0.98
[Train] Batch ID = 19300, loss = 0.0116354, acc = 1.0
[Validation] Batch ID = 19300, loss = 0.0170416, acc = 1.0
[Train] Batch ID = 19310, loss = 0.0110989, acc = 1.0
[Validation] Batch ID = 19310, loss = 0.0327947, acc = 0.98
[Train] Batch ID = 19320, loss = 0.011688, acc = 1.0
[Validation] Batch ID = 19320, loss = 0.0455786, acc = 0.96
[Train] Batch ID = 19330, loss = 0.00967927, acc = 1.0
[Validation] Batch ID = 19330, loss = 0.048881, acc = 0.96
[Train] Batch ID = 19340, loss = 0.00774668, acc = 1.0
[Validation] Batch ID = 19340, loss = 0.0326324, acc = 0.96
[Train] Batch ID = 19350, loss = 0.00438985, acc = 1.0
[Validation] Batch ID = 19350, loss = 0.0255781, acc = 1.0
[Train] Batch ID = 19360, loss = 0.214245, acc = 0.72
[Validation] Batch ID = 19360, loss = 0.035841, acc = 0.98
[Train] Batch ID = 19370, loss = 0.00575926, acc = 1.0
[Validation] Batch ID = 19370, loss = 0.0345744, acc = 0.98
[Train] Batch ID = 19380, loss = 0.00518546, acc = 1.0
[Validation] Batch ID = 19380, loss = 0.0400761, acc = 0.98
[Train] Batch ID = 19390, loss = 0.0110998, acc = 1.0
[Validation] Batch ID = 19390, loss = 0.0401665, acc = 0.98
[Train] Batch ID = 19400, loss = 0.0106186, acc = 1.0
[Validation] Batch ID = 19400, loss = 0.027817, acc = 0.98
[Train] Batch ID = 19410, loss = 0.0172628, acc = 0.98
[Validation] Batch ID = 19410, loss = 0.0154824, acc = 1.0
[Train] Batch ID = 19420, loss = 0.0035282, acc = 1.0
[Validation] Batch ID = 19420, loss = 0.0501599, acc = 0.96
[Train] Batch ID = 19430, loss = 0.0114891, acc = 1.0
[Validation] Batch ID = 19430, loss = 0.0343084, acc = 0.98
[Train] Batch ID = 19440, loss = 0.00827822, acc = 1.0
[Validation] Batch ID = 19440, loss = 0.0290019, acc = 0.98
[Train] Batch ID = 19450, loss = 0.198542, acc = 0.88
[Validation] Batch ID = 19450, loss = 0.0233754, acc = 1.0
[Train] Batch ID = 19460, loss = 0.224371, acc = 0.8
[Validation] Batch ID = 19460, loss = 0.0364395, acc = 0.98
[Train] Batch ID = 19470, loss = 0.00996934, acc = 1.0
[Validation] Batch ID = 19470, loss = 0.0203768, acc = 1.0
[Train] Batch ID = 19480, loss = 0.00833579, acc = 1.0
[Validation] Batch ID = 19480, loss = 0.0745356, acc = 0.92
[Train] Batch ID = 19490, loss = 0.00599639, acc = 1.0
[Validation] Batch ID = 19490, loss = 0.0206385, acc = 1.0
[Train] Batch ID = 19500, loss = 0.00624416, acc = 1.0
[Validation] Batch ID = 19500, loss = 0.0363185, acc = 0.96
[Train] Batch ID = 19510, loss = 0.00862065, acc = 1.0
[Validation] Batch ID = 19510, loss = 0.0741523, acc = 0.96
[Train] Batch ID = 19520, loss = 0.0107056, acc = 1.0
[Validation] Batch ID = 19520, loss = 0.0603137, acc = 0.96
[Train] Batch ID = 19530, loss = 0.00527332, acc = 1.0
[Validation] Batch ID = 19530, loss = 0.0222762, acc = 1.0
[Train] Batch ID = 19540, loss = 0.0126581, acc = 1.0
[Validation] Batch ID = 19540, loss = 0.0525481, acc = 0.94
[Train] Batch ID = 19550, loss = 0.00686756, acc = 1.0
[Validation] Batch ID = 19550, loss = 0.0325457, acc = 0.98
[Train] Batch ID = 19560, loss = 0.009601, acc = 1.0
[Validation] Batch ID = 19560, loss = 0.0533486, acc = 0.96
[Train] Batch ID = 19570, loss = 0.00630613, acc = 1.0
[Validation] Batch ID = 19570, loss = 0.0239219, acc = 1.0
[Train] Batch ID = 19580, loss = 0.221834, acc = 0.78
[Validation] Batch ID = 19580, loss = 0.0315201, acc = 0.98
[Train] Batch ID = 19590, loss = 0.0175049, acc = 1.0
[Validation] Batch ID = 19590, loss = 0.0414703, acc = 0.98
[Train] Batch ID = 19600, loss = 0.00681674, acc = 1.0
[Validation] Batch ID = 19600, loss = 0.022439, acc = 1.0
[Train] Batch ID = 19610, loss = 0.0108275, acc = 1.0
[Validation] Batch ID = 19610, loss = 0.0349966, acc = 0.98
[Train] Batch ID = 19620, loss = 0.0106411, acc = 1.0
[Validation] Batch ID = 19620, loss = 0.0600635, acc = 0.94
[Train] Batch ID = 19630, loss = 0.0130105, acc = 1.0
[Validation] Batch ID = 19630, loss = 0.0545283, acc = 0.88
[Train] Batch ID = 19640, loss = 0.00427922, acc = 1.0
[Validation] Batch ID = 19640, loss = 0.0353706, acc = 0.98
[Train] Batch ID = 19650, loss = 0.00727035, acc = 1.0
[Validation] Batch ID = 19650, loss = 0.0380934, acc = 1.0
[Train] Batch ID = 19660, loss = 0.010646, acc = 1.0
[Validation] Batch ID = 19660, loss = 0.0462218, acc = 0.96
[Train] Batch ID = 19670, loss = 0.183529, acc = 0.86
[Validation] Batch ID = 19670, loss = 0.040916, acc = 1.0
[Train] Batch ID = 19680, loss = 0.222216, acc = 0.9
[Validation] Batch ID = 19680, loss = 0.0518942, acc = 0.98
[Train] Batch ID = 19690, loss = 0.0069439, acc = 1.0
[Validation] Batch ID = 19690, loss = 0.0602985, acc = 0.94
[Train] Batch ID = 19700, loss = 0.00520478, acc = 1.0
[Validation] Batch ID = 19700, loss = 0.0441358, acc = 0.98
[Train] Batch ID = 19710, loss = 0.0100754, acc = 1.0
[Validation] Batch ID = 19710, loss = 0.0286411, acc = 0.98
[Train] Batch ID = 19720, loss = 0.0104091, acc = 1.0
[Validation] Batch ID = 19720, loss = 0.0767592, acc = 0.9
[Train] Batch ID = 19730, loss = 0.0116919, acc = 1.0
[Validation] Batch ID = 19730, loss = 0.0181293, acc = 1.0
[Train] Batch ID = 19740, loss = 0.00531142, acc = 1.0
[Validation] Batch ID = 19740, loss = 0.0339181, acc = 0.98
[Train] Batch ID = 19750, loss = 0.233918, acc = 0.74
[Validation] Batch ID = 19750, loss = 0.0486291, acc = 0.96
[Train] Batch ID = 19760, loss = 0.0074021, acc = 1.0
[Validation] Batch ID = 19760, loss = 0.018361, acc = 1.0
[Train] Batch ID = 19770, loss = 0.00606004, acc = 1.0
[Validation] Batch ID = 19770, loss = 0.0298072, acc = 0.98
[Train] Batch ID = 19780, loss = 0.207894, acc = 0.78
[Validation] Batch ID = 19780, loss = 0.0674197, acc = 0.92
[Train] Batch ID = 19790, loss = 0.00641519, acc = 1.0
[Validation] Batch ID = 19790, loss = 0.0661805, acc = 0.9
[Train] Batch ID = 19800, loss = 0.013629, acc = 1.0
[Validation] Batch ID = 19800, loss = 0.0746337, acc = 0.92
[Train] Batch ID = 19810, loss = 0.202612, acc = 0.8
[Validation] Batch ID = 19810, loss = 0.0728207, acc = 0.94
[Train] Batch ID = 19820, loss = 0.00946282, acc = 1.0
[Validation] Batch ID = 19820, loss = 0.0329975, acc = 0.98
[Train] Batch ID = 19830, loss = 0.00883393, acc = 1.0
[Validation] Batch ID = 19830, loss = 0.0407063, acc = 0.98
[Train] Batch ID = 19840, loss = 0.00462411, acc = 1.0
[Validation] Batch ID = 19840, loss = 0.0242194, acc = 0.98
[Train] Batch ID = 19850, loss = 0.00922284, acc = 1.0
[Validation] Batch ID = 19850, loss = 0.0522201, acc = 0.94
[Train] Batch ID = 19860, loss = 0.204102, acc = 0.74
[Validation] Batch ID = 19860, loss = 0.0444661, acc = 0.96
[Train] Batch ID = 19870, loss = 0.196496, acc = 0.84
[Validation] Batch ID = 19870, loss = 0.0584654, acc = 0.96
[Train] Batch ID = 19880, loss = 0.0106054, acc = 1.0
[Validation] Batch ID = 19880, loss = 0.0491776, acc = 0.96
[Train] Batch ID = 19890, loss = 0.209501, acc = 0.8
[Validation] Batch ID = 19890, loss = 0.0457294, acc = 0.94
[Train] Batch ID = 19900, loss = 0.00547643, acc = 1.0
[Validation] Batch ID = 19900, loss = 0.0377415, acc = 0.96
[Train] Batch ID = 19910, loss = 0.00756409, acc = 1.0
[Validation] Batch ID = 19910, loss = 0.0408649, acc = 0.98
[Train] Batch ID = 19920, loss = 0.00516333, acc = 1.0
[Validation] Batch ID = 19920, loss = 0.0392364, acc = 0.98
[Train] Batch ID = 19930, loss = 0.0118275, acc = 1.0
[Validation] Batch ID = 19930, loss = 0.0384568, acc = 0.98
[Train] Batch ID = 19940, loss = 0.0162089, acc = 0.98
[Validation] Batch ID = 19940, loss = 0.0264268, acc = 0.98
[Train] Batch ID = 19950, loss = 0.23852, acc = 0.76
[Validation] Batch ID = 19950, loss = 0.0439335, acc = 0.96
[Train] Batch ID = 19960, loss = 0.0120941, acc = 1.0
[Validation] Batch ID = 19960, loss = 0.0560773, acc = 0.96
[Train] Batch ID = 19970, loss = 0.00970779, acc = 1.0
[Validation] Batch ID = 19970, loss = 0.0310208, acc = 1.0
[Train] Batch ID = 19980, loss = 0.00542317, acc = 1.0
[Validation] Batch ID = 19980, loss = 0.0466412, acc = 0.98
[Train] Batch ID = 19990, loss = 0.00734296, acc = 1.0
[Validation] Batch ID = 19990, loss = 0.0440015, acc = 0.96
[Train] Batch ID = 20000, loss = 0.225339, acc = 0.76
[Validation] Batch ID = 20000, loss = 0.0204207, acc = 1.0
Evaluate full validation dataset ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Saving model ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Current loss: 0.0408133 Best loss: 0.04133
[TOTAL Validation] Batch ID = 20000, loss = 0.0408133, acc = 0.969387755102
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Model successfully saved here: outputs/checkpoints/c1s_9_c1n_256_c2s_6_c2n_64_c2d_0.7_c1vl_16_c1s_5_c1nf_16_c2vl_32_lr_0.0001_rs_1--TrafficSign--1510487290.423481
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Augmented Factor = 0.10832479924019728
[Train] Batch ID = 20010, loss = 0.0121621, acc = 1.0
[Validation] Batch ID = 20010, loss = 0.0591486, acc = 0.96
[Train] Batch ID = 20020, loss = 0.00480423, acc = 1.0
[Validation] Batch ID = 20020, loss = 0.0150694, acc = 1.0
[Train] Batch ID = 20030, loss = 0.00492804, acc = 1.0
[Validation] Batch ID = 20030, loss = 0.0209972, acc = 1.0
[Train] Batch ID = 20040, loss = 0.00766971, acc = 1.0
[Validation] Batch ID = 20040, loss = 0.0376517, acc = 0.98
[Train] Batch ID = 20050, loss = 0.00550816, acc = 1.0
[Validation] Batch ID = 20050, loss = 0.0319362, acc = 1.0
[Train] Batch ID = 20060, loss = 0.011221, acc = 1.0
[Validation] Batch ID = 20060, loss = 0.0436221, acc = 0.98
[Train] Batch ID = 20070, loss = 0.00795804, acc = 1.0
[Validation] Batch ID = 20070, loss = 0.0520479, acc = 0.96
[Train] Batch ID = 20080, loss = 0.00787, acc = 1.0
[Validation] Batch ID = 20080, loss = 0.0704649, acc = 0.92
[Train] Batch ID = 20090, loss = 0.00772897, acc = 1.0
[Validation] Batch ID = 20090, loss = 0.0586643, acc = 0.94
[Train] Batch ID = 20100, loss = 0.00774926, acc = 1.0
[Validation] Batch ID = 20100, loss = 0.0289221, acc = 1.0
[Train] Batch ID = 20110, loss = 0.00551302, acc = 1.0
[Validation] Batch ID = 20110, loss = 0.049123, acc = 0.96
[Train] Batch ID = 20120, loss = 0.00561796, acc = 1.0
[Validation] Batch ID = 20120, loss = 0.0725273, acc = 0.92
[Train] Batch ID = 20130, loss = 0.00634792, acc = 1.0
[Validation] Batch ID = 20130, loss = 0.0231948, acc = 0.98
[Train] Batch ID = 20140, loss = 0.00705518, acc = 1.0
[Validation] Batch ID = 20140, loss = 0.0348869, acc = 0.98
[Train] Batch ID = 20150, loss = 0.00427323, acc = 1.0
[Validation] Batch ID = 20150, loss = 0.0156809, acc = 1.0
[Train] Batch ID = 20160, loss = 0.00735411, acc = 1.0
[Validation] Batch ID = 20160, loss = 0.0435082, acc = 0.98
[Train] Batch ID = 20170, loss = 0.00650522, acc = 1.0
[Validation] Batch ID = 20170, loss = 0.0352256, acc = 0.96
[Train] Batch ID = 20180, loss = 0.00547402, acc = 1.0
[Validation] Batch ID = 20180, loss = 0.035118, acc = 1.0
[Train] Batch ID = 20190, loss = 0.15671, acc = 0.9
[Validation] Batch ID = 20190, loss = 0.0343312, acc = 0.96
[Train] Batch ID = 20200, loss = 0.00999631, acc = 1.0
[Validation] Batch ID = 20200, loss = 0.0285852, acc = 0.98
[Train] Batch ID = 20210, loss = 0.00336887, acc = 1.0
[Validation] Batch ID = 20210, loss = 0.0198216, acc = 1.0
[Train] Batch ID = 20220, loss = 0.00530345, acc = 1.0
[Validation] Batch ID = 20220, loss = 0.0456875, acc = 0.98
[Train] Batch ID = 20230, loss = 0.00605041, acc = 1.0
[Validation] Batch ID = 20230, loss = 0.0300056, acc = 0.96
[Train] Batch ID = 20240, loss = 0.00620132, acc = 1.0
[Validation] Batch ID = 20240, loss = 0.0413816, acc = 0.98
[Train] Batch ID = 20250, loss = 0.00831628, acc = 1.0
[Validation] Batch ID = 20250, loss = 0.0414614, acc = 0.96
[Train] Batch ID = 20260, loss = 0.0050357, acc = 1.0
[Validation] Batch ID = 20260, loss = 0.0247127, acc = 0.98
[Train] Batch ID = 20270, loss = 0.00407688, acc = 1.0
[Validation] Batch ID = 20270, loss = 0.0390399, acc = 0.96
[Train] Batch ID = 20280, loss = 0.00334446, acc = 1.0
[Validation] Batch ID = 20280, loss = 0.0212297, acc = 1.0
[Train] Batch ID = 20290, loss = 0.222736, acc = 0.8
[Validation] Batch ID = 20290, loss = 0.0459547, acc = 0.96
[Train] Batch ID = 20300, loss = 0.194667, acc = 0.8
[Validation] Batch ID = 20300, loss = 0.0214653, acc = 1.0
[Train] Batch ID = 20310, loss = 0.00975947, acc = 1.0
[Validation] Batch ID = 20310, loss = 0.0414093, acc = 0.96
[Train] Batch ID = 20320, loss = 0.00802601, acc = 1.0
[Validation] Batch ID = 20320, loss = 0.0223646, acc = 1.0
[Train] Batch ID = 20330, loss = 0.00492601, acc = 1.0
[Validation] Batch ID = 20330, loss = 0.0472553, acc = 0.96
[Train] Batch ID = 20340, loss = 0.00417772, acc = 1.0
[Validation] Batch ID = 20340, loss = 0.0310175, acc = 0.96
[Train] Batch ID = 20350, loss = 0.191255, acc = 0.86
[Validation] Batch ID = 20350, loss = 0.0371954, acc = 0.98
[Train] Batch ID = 20360, loss = 0.00456744, acc = 1.0
[Validation] Batch ID = 20360, loss = 0.0228792, acc = 1.0
[Train] Batch ID = 20370, loss = 0.198478, acc = 0.78
[Validation] Batch ID = 20370, loss = 0.0282234, acc = 0.98
[Train] Batch ID = 20380, loss = 0.00521678, acc = 1.0
[Validation] Batch ID = 20380, loss = 0.0126037, acc = 1.0
[Train] Batch ID = 20390, loss = 0.00319034, acc = 1.0
[Validation] Batch ID = 20390, loss = 0.0265952, acc = 0.98
[Train] Batch ID = 20400, loss = 0.00769903, acc = 1.0
[Validation] Batch ID = 20400, loss = 0.0362417, acc = 0.98
[Train] Batch ID = 20410, loss = 0.00902145, acc = 1.0
[Validation] Batch ID = 20410, loss = 0.0570795, acc = 0.94
[Train] Batch ID = 20420, loss = 0.193253, acc = 0.88
[Validation] Batch ID = 20420, loss = 0.0213505, acc = 0.98
[Train] Batch ID = 20430, loss = 0.00455042, acc = 1.0
[Validation] Batch ID = 20430, loss = 0.0342416, acc = 1.0
[Train] Batch ID = 20440, loss = 0.00540219, acc = 1.0
[Validation] Batch ID = 20440, loss = 0.0325335, acc = 0.96
[Train] Batch ID = 20450, loss = 0.181073, acc = 0.86
[Validation] Batch ID = 20450, loss = 0.0223338, acc = 1.0
[Train] Batch ID = 20460, loss = 0.00766363, acc = 1.0
[Validation] Batch ID = 20460, loss = 0.0261662, acc = 0.98
[Train] Batch ID = 20470, loss = 0.00537412, acc = 1.0
[Validation] Batch ID = 20470, loss = 0.0493043, acc = 0.94
[Train] Batch ID = 20480, loss = 0.00675913, acc = 1.0
[Validation] Batch ID = 20480, loss = 0.0405768, acc = 0.94
[Train] Batch ID = 20490, loss = 0.0061647, acc = 1.0
[Validation] Batch ID = 20490, loss = 0.034673, acc = 0.98
[Train] Batch ID = 20500, loss = 0.00453477, acc = 1.0
[Validation] Batch ID = 20500, loss = 0.0274262, acc = 0.98
[Train] Batch ID = 20510, loss = 0.00350715, acc = 1.0
[Validation] Batch ID = 20510, loss = 0.0270086, acc = 1.0
[Train] Batch ID = 20520, loss = 0.00755004, acc = 1.0
[Validation] Batch ID = 20520, loss = 0.0203623, acc = 0.98
[Train] Batch ID = 20530, loss = 0.009068, acc = 0.98
[Validation] Batch ID = 20530, loss = 0.0379256, acc = 0.96
[Train] Batch ID = 20540, loss = 0.00219789, acc = 1.0
[Validation] Batch ID = 20540, loss = 0.0219598, acc = 0.98
[Train] Batch ID = 20550, loss = 0.00390856, acc = 1.0
[Validation] Batch ID = 20550, loss = 0.0370144, acc = 0.96
[Train] Batch ID = 20560, loss = 0.245962, acc = 0.76
[Validation] Batch ID = 20560, loss = 0.0272631, acc = 1.0
[Train] Batch ID = 20570, loss = 0.00575062, acc = 1.0
[Validation] Batch ID = 20570, loss = 0.0368936, acc = 0.98
[Train] Batch ID = 20580, loss = 0.00955593, acc = 1.0
[Validation] Batch ID = 20580, loss = 0.0127142, acc = 1.0
[Train] Batch ID = 20590, loss = 0.0080051, acc = 1.0
[Validation] Batch ID = 20590, loss = 0.0342584, acc = 0.98
[Train] Batch ID = 20600, loss = 0.00939621, acc = 1.0
[Validation] Batch ID = 20600, loss = 0.0483837, acc = 0.96
[Train] Batch ID = 20610, loss = 0.00983075, acc = 1.0
[Validation] Batch ID = 20610, loss = 0.0550517, acc = 0.94
[Train] Batch ID = 20620, loss = 0.00426098, acc = 1.0
[Validation] Batch ID = 20620, loss = 0.0235564, acc = 1.0
[Train] Batch ID = 20630, loss = 0.00686548, acc = 1.0
[Validation] Batch ID = 20630, loss = 0.0230309, acc = 1.0
[Train] Batch ID = 20640, loss = 0.00705257, acc = 1.0
[Validation] Batch ID = 20640, loss = 0.0427395, acc = 0.98
[Train] Batch ID = 20650, loss = 0.00557387, acc = 1.0
[Validation] Batch ID = 20650, loss = 0.0177188, acc = 1.0
[Train] Batch ID = 20660, loss = 0.00582847, acc = 1.0
[Validation] Batch ID = 20660, loss = 0.0465941, acc = 0.96
[Train] Batch ID = 20670, loss = 0.00516201, acc = 1.0
[Validation] Batch ID = 20670, loss = 0.0317679, acc = 0.96
[Train] Batch ID = 20680, loss = 0.217427, acc = 0.88
[Validation] Batch ID = 20680, loss = 0.025204, acc = 0.98
[Train] Batch ID = 20690, loss = 0.0123076, acc = 1.0
[Validation] Batch ID = 20690, loss = 0.0552725, acc = 0.96
[Train] Batch ID = 20700, loss = 0.00655903, acc = 1.0
[Validation] Batch ID = 20700, loss = 0.0344553, acc = 0.98
[Train] Batch ID = 20710, loss = 0.00746698, acc = 1.0
[Validation] Batch ID = 20710, loss = 0.0227591, acc = 0.98
[Train] Batch ID = 20720, loss = 0.0110315, acc = 1.0
[Validation] Batch ID = 20720, loss = 0.0206049, acc = 1.0
[Train] Batch ID = 20730, loss = 0.00851594, acc = 1.0
[Validation] Batch ID = 20730, loss = 0.0396499, acc = 0.98
[Train] Batch ID = 20740, loss = 0.0115291, acc = 1.0
[Validation] Batch ID = 20740, loss = 0.048915, acc = 0.94
[Train] Batch ID = 20750, loss = 0.00939869, acc = 1.0
[Validation] Batch ID = 20750, loss = 0.0433844, acc = 0.98
[Train] Batch ID = 20760, loss = 0.189632, acc = 0.88
[Validation] Batch ID = 20760, loss = 0.0395905, acc = 0.98
[Train] Batch ID = 20770, loss = 0.00678353, acc = 1.0
[Validation] Batch ID = 20770, loss = 0.0294514, acc = 0.98
[Train] Batch ID = 20780, loss = 0.00929747, acc = 1.0
[Validation] Batch ID = 20780, loss = 0.0319454, acc = 0.98
[Train] Batch ID = 20790, loss = 0.00438841, acc = 1.0
[Validation] Batch ID = 20790, loss = 0.0323237, acc = 0.98
[Train] Batch ID = 20800, loss = 0.00659886, acc = 1.0
[Validation] Batch ID = 20800, loss = 0.0405213, acc = 0.98
[Train] Batch ID = 20810, loss = 0.010327, acc = 1.0
[Validation] Batch ID = 20810, loss = 0.0420512, acc = 0.96
[Train] Batch ID = 20820, loss = 0.19306, acc = 0.84
[Validation] Batch ID = 20820, loss = 0.053638, acc = 0.94
[Train] Batch ID = 20830, loss = 0.00845104, acc = 1.0
[Validation] Batch ID = 20830, loss = 0.0292836, acc = 0.98
[Train] Batch ID = 20840, loss = 0.00874292, acc = 1.0
[Validation] Batch ID = 20840, loss = 0.0370622, acc = 0.94
[Train] Batch ID = 20850, loss = 0.00738273, acc = 1.0
[Validation] Batch ID = 20850, loss = 0.017642, acc = 0.98
[Train] Batch ID = 20860, loss = 0.00575704, acc = 1.0
[Validation] Batch ID = 20860, loss = 0.0482965, acc = 0.98
[Train] Batch ID = 20870, loss = 0.00539798, acc = 1.0
[Validation] Batch ID = 20870, loss = 0.0752459, acc = 0.92
[Train] Batch ID = 20880, loss = 0.19607, acc = 0.82
[Validation] Batch ID = 20880, loss = 0.0252192, acc = 0.98
[Train] Batch ID = 20890, loss = 0.00597661, acc = 1.0
[Validation] Batch ID = 20890, loss = 0.043592, acc = 0.98
[Train] Batch ID = 20900, loss = 0.0101745, acc = 1.0
[Validation] Batch ID = 20900, loss = 0.0232427, acc = 1.0
[Train] Batch ID = 20910, loss = 0.22139, acc = 0.84
[Validation] Batch ID = 20910, loss = 0.0352304, acc = 0.96
[Train] Batch ID = 20920, loss = 0.0114474, acc = 1.0
[Validation] Batch ID = 20920, loss = 0.0706945, acc = 0.9
[Train] Batch ID = 20930, loss = 0.00519587, acc = 1.0
[Validation] Batch ID = 20930, loss = 0.0287194, acc = 0.98
[Train] Batch ID = 20940, loss = 0.00789449, acc = 1.0
[Validation] Batch ID = 20940, loss = 0.0279124, acc = 0.98
[Train] Batch ID = 20950, loss = 0.00591379, acc = 1.0
[Validation] Batch ID = 20950, loss = 0.0503473, acc = 0.96
[Train] Batch ID = 20960, loss = 0.00515597, acc = 1.0
[Validation] Batch ID = 20960, loss = 0.0435386, acc = 0.94
[Train] Batch ID = 20970, loss = 0.231183, acc = 0.76
[Validation] Batch ID = 20970, loss = 0.0418741, acc = 0.98
[Train] Batch ID = 20980, loss = 0.00501432, acc = 1.0
[Validation] Batch ID = 20980, loss = 0.0235779, acc = 1.0
[Train] Batch ID = 20990, loss = 0.0125432, acc = 1.0
[Validation] Batch ID = 20990, loss = 0.0442443, acc = 0.94
[Train] Batch ID = 21000, loss = 0.00539237, acc = 1.0
[Validation] Batch ID = 21000, loss = 0.0342983, acc = 0.98
Evaluate full validation dataset ...
Current loss: 0.0431974 Best loss: 0.0408133
[TOTAL Validation] Batch ID = 21000, loss = 0.0431974, acc = 0.97074829932
Augmented Factor = 0.09749231931617755
[Train] Batch ID = 21010, loss = 0.00592436, acc = 1.0
[Validation] Batch ID = 21010, loss = 0.0442082, acc = 0.96
[Train] Batch ID = 21020, loss = 0.00853046, acc = 1.0
[Validation] Batch ID = 21020, loss = 0.021082, acc = 1.0
[Train] Batch ID = 21030, loss = 0.00612076, acc = 1.0
[Validation] Batch ID = 21030, loss = 0.0386014, acc = 1.0
[Train] Batch ID = 21040, loss = 0.00284419, acc = 1.0
[Validation] Batch ID = 21040, loss = 0.050859, acc = 0.94
[Train] Batch ID = 21050, loss = 0.215822, acc = 0.8
[Validation] Batch ID = 21050, loss = 0.0445488, acc = 0.98
[Train] Batch ID = 21060, loss = 0.00784949, acc = 1.0
[Validation] Batch ID = 21060, loss = 0.0266466, acc = 1.0
[Train] Batch ID = 21070, loss = 0.00580367, acc = 1.0
[Validation] Batch ID = 21070, loss = 0.0348349, acc = 0.98
[Train] Batch ID = 21080, loss = 0.00470474, acc = 1.0
[Validation] Batch ID = 21080, loss = 0.0411613, acc = 0.98
[Train] Batch ID = 21090, loss = 0.00392595, acc = 1.0
[Validation] Batch ID = 21090, loss = 0.0277769, acc = 0.98
[Train] Batch ID = 21100, loss = 0.00685797, acc = 1.0
[Validation] Batch ID = 21100, loss = 0.0348169, acc = 0.98
[Train] Batch ID = 21110, loss = 0.010224, acc = 1.0
[Validation] Batch ID = 21110, loss = 0.0382668, acc = 0.96
[Train] Batch ID = 21120, loss = 0.0101437, acc = 1.0
[Validation] Batch ID = 21120, loss = 0.0196411, acc = 1.0
[Train] Batch ID = 21130, loss = 0.00685346, acc = 1.0
[Validation] Batch ID = 21130, loss = 0.0361198, acc = 1.0
[Train] Batch ID = 21140, loss = 0.00427253, acc = 1.0
[Validation] Batch ID = 21140, loss = 0.0258955, acc = 1.0
[Train] Batch ID = 21150, loss = 0.00844198, acc = 1.0
[Validation] Batch ID = 21150, loss = 0.0191694, acc = 0.98
[Train] Batch ID = 21160, loss = 0.00512653, acc = 1.0
[Validation] Batch ID = 21160, loss = 0.0374565, acc = 0.98
[Train] Batch ID = 21170, loss = 0.00696004, acc = 1.0
[Validation] Batch ID = 21170, loss = 0.0454637, acc = 0.96
[Train] Batch ID = 21180, loss = 0.00375915, acc = 1.0
[Validation] Batch ID = 21180, loss = 0.046177, acc = 0.96
[Train] Batch ID = 21190, loss = 0.00579243, acc = 1.0
[Validation] Batch ID = 21190, loss = 0.0327552, acc = 0.98
[Train] Batch ID = 21200, loss = 0.00328368, acc = 1.0
[Validation] Batch ID = 21200, loss = 0.0422119, acc = 0.96
[Train] Batch ID = 21210, loss = 0.0100822, acc = 1.0
[Validation] Batch ID = 21210, loss = 0.0453153, acc = 0.96
[Train] Batch ID = 21220, loss = 0.300039, acc = 0.64
[Validation] Batch ID = 21220, loss = 0.0481353, acc = 0.94
[Train] Batch ID = 21230, loss = 0.00564377, acc = 1.0
[Validation] Batch ID = 21230, loss = 0.018417, acc = 1.0
[Train] Batch ID = 21240, loss = 0.00638278, acc = 1.0
[Validation] Batch ID = 21240, loss = 0.0289168, acc = 1.0
[Train] Batch ID = 21250, loss = 0.0151131, acc = 1.0
[Validation] Batch ID = 21250, loss = 0.0152897, acc = 1.0
[Train] Batch ID = 21260, loss = 0.00540018, acc = 1.0
[Validation] Batch ID = 21260, loss = 0.0486957, acc = 0.92
[Train] Batch ID = 21270, loss = 0.00416173, acc = 1.0
[Validation] Batch ID = 21270, loss = 0.02185, acc = 1.0
[Train] Batch ID = 21280, loss = 0.00424879, acc = 1.0
[Validation] Batch ID = 21280, loss = 0.0267887, acc = 1.0
[Train] Batch ID = 21290, loss = 0.00989814, acc = 1.0
[Validation] Batch ID = 21290, loss = 0.0395895, acc = 0.98
[Train] Batch ID = 21300, loss = 0.00658225, acc = 1.0
[Validation] Batch ID = 21300, loss = 0.0221687, acc = 1.0
[Train] Batch ID = 21310, loss = 0.00279934, acc = 1.0
[Validation] Batch ID = 21310, loss = 0.0341257, acc = 0.98
[Train] Batch ID = 21320, loss = 0.00695036, acc = 1.0
[Validation] Batch ID = 21320, loss = 0.0231302, acc = 1.0
[Train] Batch ID = 21330, loss = 0.00335412, acc = 1.0
[Validation] Batch ID = 21330, loss = 0.0368639, acc = 0.98
[Train] Batch ID = 21340, loss = 0.00415824, acc = 1.0
[Validation] Batch ID = 21340, loss = 0.0314373, acc = 0.98
[Train] Batch ID = 21350, loss = 0.00730634, acc = 1.0
[Validation] Batch ID = 21350, loss = 0.0306796, acc = 1.0
[Train] Batch ID = 21360, loss = 0.0113712, acc = 1.0
[Validation] Batch ID = 21360, loss = 0.0193513, acc = 1.0
[Train] Batch ID = 21370, loss = 0.0118525, acc = 1.0
[Validation] Batch ID = 21370, loss = 0.0336994, acc = 0.98
[Train] Batch ID = 21380, loss = 0.227269, acc = 0.84
[Validation] Batch ID = 21380, loss = 0.0185052, acc = 1.0
[Train] Batch ID = 21390, loss = 0.00752672, acc = 1.0
[Validation] Batch ID = 21390, loss = 0.0422564, acc = 0.98
[Train] Batch ID = 21400, loss = 0.00426913, acc = 1.0
[Validation] Batch ID = 21400, loss = 0.0480888, acc = 0.94
[Train] Batch ID = 21410, loss = 0.00875716, acc = 1.0
[Validation] Batch ID = 21410, loss = 0.0318833, acc = 0.98
[Train] Batch ID = 21420, loss = 0.00469748, acc = 1.0
[Validation] Batch ID = 21420, loss = 0.0326736, acc = 0.96
[Train] Batch ID = 21430, loss = 0.0107814, acc = 1.0
[Validation] Batch ID = 21430, loss = 0.0587397, acc = 0.94
[Train] Batch ID = 21440, loss = 0.00819353, acc = 1.0
[Validation] Batch ID = 21440, loss = 0.0722991, acc = 0.94
[Train] Batch ID = 21450, loss = 0.00703784, acc = 1.0
[Validation] Batch ID = 21450, loss = 0.0249033, acc = 0.98
[Train] Batch ID = 21460, loss = 0.00469719, acc = 1.0
[Validation] Batch ID = 21460, loss = 0.0303085, acc = 0.98
[Train] Batch ID = 21470, loss = 0.0093959, acc = 1.0
[Validation] Batch ID = 21470, loss = 0.0357923, acc = 0.96
[Train] Batch ID = 21480, loss = 0.00955168, acc = 1.0
[Validation] Batch ID = 21480, loss = 0.0534843, acc = 0.96
[Train] Batch ID = 21490, loss = 0.00721632, acc = 1.0
[Validation] Batch ID = 21490, loss = 0.0456211, acc = 0.98
[Train] Batch ID = 21500, loss = 0.237272, acc = 0.74
[Validation] Batch ID = 21500, loss = 0.0496843, acc = 0.96
[Train] Batch ID = 21510, loss = 0.00778127, acc = 1.0
[Validation] Batch ID = 21510, loss = 0.0422689, acc = 0.98
[Train] Batch ID = 21520, loss = 0.00959985, acc = 1.0
[Validation] Batch ID = 21520, loss = 0.0235647, acc = 1.0
[Train] Batch ID = 21530, loss = 0.0068779, acc = 1.0
[Validation] Batch ID = 21530, loss = 0.0246928, acc = 1.0
[Train] Batch ID = 21540, loss = 0.00397836, acc = 1.0
[Validation] Batch ID = 21540, loss = 0.0326337, acc = 0.98
[Train] Batch ID = 21550, loss = 0.00487709, acc = 1.0
[Validation] Batch ID = 21550, loss = 0.0297762, acc = 0.96
[Train] Batch ID = 21560, loss = 0.0097123, acc = 1.0
[Validation] Batch ID = 21560, loss = 0.02665, acc = 0.98
[Train] Batch ID = 21570, loss = 0.0133579, acc = 1.0
[Validation] Batch ID = 21570, loss = 0.0276386, acc = 1.0
[Train] Batch ID = 21580, loss = 0.00470994, acc = 1.0
[Validation] Batch ID = 21580, loss = 0.0287187, acc = 0.98
[Train] Batch ID = 21590, loss = 0.00426484, acc = 1.0
[Validation] Batch ID = 21590, loss = 0.0251738, acc = 1.0
[Train] Batch ID = 21600, loss = 0.00622298, acc = 1.0
[Validation] Batch ID = 21600, loss = 0.0271167, acc = 1.0
[Train] Batch ID = 21610, loss = 0.00735414, acc = 1.0
[Validation] Batch ID = 21610, loss = 0.0335143, acc = 0.96
[Train] Batch ID = 21620, loss = 0.0116956, acc = 1.0
[Validation] Batch ID = 21620, loss = 0.0272462, acc = 1.0
[Train] Batch ID = 21630, loss = 0.00832986, acc = 1.0
[Validation] Batch ID = 21630, loss = 0.0345959, acc = 0.98
[Train] Batch ID = 21640, loss = 0.00510451, acc = 1.0
[Validation] Batch ID = 21640, loss = 0.020501, acc = 1.0
[Train] Batch ID = 21650, loss = 0.00390019, acc = 1.0
[Validation] Batch ID = 21650, loss = 0.0172508, acc = 1.0
[Train] Batch ID = 21660, loss = 0.00835681, acc = 1.0
[Validation] Batch ID = 21660, loss = 0.0300294, acc = 0.98
[Train] Batch ID = 21670, loss = 0.00759623, acc = 1.0
[Validation] Batch ID = 21670, loss = 0.0248139, acc = 0.98
[Train] Batch ID = 21680, loss = 0.193899, acc = 0.84
[Validation] Batch ID = 21680, loss = 0.040721, acc = 0.98
[Train] Batch ID = 21690, loss = 0.0104687, acc = 1.0
[Validation] Batch ID = 21690, loss = 0.039279, acc = 0.98
[Train] Batch ID = 21700, loss = 0.00675484, acc = 1.0
[Validation] Batch ID = 21700, loss = 0.0225968, acc = 1.0
[Train] Batch ID = 21710, loss = 0.00623222, acc = 1.0
[Validation] Batch ID = 21710, loss = 0.0178677, acc = 1.0
[Train] Batch ID = 21720, loss = 0.00749648, acc = 1.0
[Validation] Batch ID = 21720, loss = 0.0230085, acc = 0.98
[Train] Batch ID = 21730, loss = 0.00276606, acc = 1.0
[Validation] Batch ID = 21730, loss = 0.0549673, acc = 0.94
[Train] Batch ID = 21740, loss = 0.0135969, acc = 1.0
[Validation] Batch ID = 21740, loss = 0.0340798, acc = 0.98
[Train] Batch ID = 21750, loss = 0.00821518, acc = 1.0
[Validation] Batch ID = 21750, loss = 0.0306354, acc = 0.98
[Train] Batch ID = 21760, loss = 0.00762272, acc = 1.0
[Validation] Batch ID = 21760, loss = 0.0364297, acc = 0.98
[Train] Batch ID = 21770, loss = 0.00434228, acc = 1.0
[Validation] Batch ID = 21770, loss = 0.0254823, acc = 1.0
[Train] Batch ID = 21780, loss = 0.00801967, acc = 1.0
[Validation] Batch ID = 21780, loss = 0.0243194, acc = 0.98
[Train] Batch ID = 21790, loss = 0.191941, acc = 0.86
[Validation] Batch ID = 21790, loss = 0.0414873, acc = 0.96
[Train] Batch ID = 21800, loss = 0.00564439, acc = 1.0
[Validation] Batch ID = 21800, loss = 0.0345359, acc = 1.0
[Train] Batch ID = 21810, loss = 0.00623545, acc = 1.0
[Validation] Batch ID = 21810, loss = 0.053455, acc = 0.94
[Train] Batch ID = 21820, loss = 0.00478596, acc = 1.0
[Validation] Batch ID = 21820, loss = 0.0407292, acc = 0.96
[Train] Batch ID = 21830, loss = 0.00727211, acc = 1.0
[Validation] Batch ID = 21830, loss = 0.0221803, acc = 1.0
[Train] Batch ID = 21840, loss = 0.00499463, acc = 1.0
[Validation] Batch ID = 21840, loss = 0.0414901, acc = 0.98
[Train] Batch ID = 21850, loss = 0.00431849, acc = 1.0
[Validation] Batch ID = 21850, loss = 0.0279297, acc = 0.96
[Train] Batch ID = 21860, loss = 0.00340977, acc = 1.0
[Validation] Batch ID = 21860, loss = 0.0304325, acc = 1.0
[Train] Batch ID = 21870, loss = 0.00696346, acc = 1.0
[Validation] Batch ID = 21870, loss = 0.042514, acc = 0.94
[Train] Batch ID = 21880, loss = 0.00543841, acc = 1.0
[Validation] Batch ID = 21880, loss = 0.0156339, acc = 1.0
[Train] Batch ID = 21890, loss = 0.00613783, acc = 1.0
[Validation] Batch ID = 21890, loss = 0.0588162, acc = 0.94
[Train] Batch ID = 21900, loss = 0.0102281, acc = 1.0
[Validation] Batch ID = 21900, loss = 0.0152144, acc = 1.0
[Train] Batch ID = 21910, loss = 0.0106926, acc = 1.0
[Validation] Batch ID = 21910, loss = 0.0208854, acc = 1.0
[Train] Batch ID = 21920, loss = 0.00315863, acc = 1.0
[Validation] Batch ID = 21920, loss = 0.0327086, acc = 0.96
[Train] Batch ID = 21930, loss = 0.00495168, acc = 1.0
[Validation] Batch ID = 21930, loss = 0.0304635, acc = 0.96
[Train] Batch ID = 21940, loss = 0.00887312, acc = 1.0
[Validation] Batch ID = 21940, loss = 0.0522316, acc = 0.92
[Train] Batch ID = 21950, loss = 0.00834389, acc = 1.0
[Validation] Batch ID = 21950, loss = 0.0461208, acc = 0.96
[Train] Batch ID = 21960, loss = 0.00461226, acc = 1.0
[Validation] Batch ID = 21960, loss = 0.0254629, acc = 0.98
[Train] Batch ID = 21970, loss = 0.00934333, acc = 1.0
[Validation] Batch ID = 21970, loss = 0.0391716, acc = 0.96
[Train] Batch ID = 21980, loss = 0.00504281, acc = 1.0
[Validation] Batch ID = 21980, loss = 0.0285056, acc = 1.0
[Train] Batch ID = 21990, loss = 0.00461622, acc = 1.0
[Validation] Batch ID = 21990, loss = 0.0301025, acc = 0.98
[Train] Batch ID = 22000, loss = 0.275685, acc = 0.7
[Validation] Batch ID = 22000, loss = 0.0314925, acc = 0.98
Evaluate full validation dataset ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Saving model ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Current loss: 0.0364358 Best loss: 0.0408133
[TOTAL Validation] Batch ID = 22000, loss = 0.0364358, acc = 0.971201814059
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Model successfully saved here: outputs/checkpoints/c1s_9_c1n_256_c2s_6_c2n_64_c2d_0.7_c1vl_16_c1s_5_c1nf_16_c2vl_32_lr_0.0001_rs_1--TrafficSign--1510487290.423481
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Augmented Factor = 0.0877430873845598
[Train] Batch ID = 22010, loss = 0.00551307, acc = 1.0
[Validation] Batch ID = 22010, loss = 0.0424847, acc = 0.98
[Train] Batch ID = 22020, loss = 0.00857473, acc = 1.0
[Validation] Batch ID = 22020, loss = 0.0304986, acc = 0.98
[Train] Batch ID = 22030, loss = 0.203924, acc = 0.82
[Validation] Batch ID = 22030, loss = 0.0314662, acc = 0.98
[Train] Batch ID = 22040, loss = 0.00704941, acc = 1.0
[Validation] Batch ID = 22040, loss = 0.0315909, acc = 0.96
[Train] Batch ID = 22050, loss = 0.00411784, acc = 1.0
[Validation] Batch ID = 22050, loss = 0.0529924, acc = 0.98
[Train] Batch ID = 22060, loss = 0.00745677, acc = 1.0
[Validation] Batch ID = 22060, loss = 0.0383155, acc = 0.98
[Train] Batch ID = 22070, loss = 0.00996044, acc = 1.0
[Validation] Batch ID = 22070, loss = 0.0193286, acc = 1.0
[Train] Batch ID = 22080, loss = 0.0041457, acc = 1.0
[Validation] Batch ID = 22080, loss = 0.046597, acc = 0.98
[Train] Batch ID = 22090, loss = 0.00480041, acc = 1.0
[Validation] Batch ID = 22090, loss = 0.0534372, acc = 0.96
[Train] Batch ID = 22100, loss = 0.00452239, acc = 1.0
[Validation] Batch ID = 22100, loss = 0.0200988, acc = 1.0
[Train] Batch ID = 22110, loss = 0.0052098, acc = 1.0
[Validation] Batch ID = 22110, loss = 0.0391209, acc = 0.94
[Train] Batch ID = 22120, loss = 0.0030478, acc = 1.0
[Validation] Batch ID = 22120, loss = 0.0168888, acc = 1.0
[Train] Batch ID = 22130, loss = 0.0073088, acc = 1.0
[Validation] Batch ID = 22130, loss = 0.0226463, acc = 0.98
[Train] Batch ID = 22140, loss = 0.00954484, acc = 1.0
[Validation] Batch ID = 22140, loss = 0.0444011, acc = 0.94
[Train] Batch ID = 22150, loss = 0.00649994, acc = 1.0
[Validation] Batch ID = 22150, loss = 0.0337414, acc = 0.96
[Train] Batch ID = 22160, loss = 0.00776088, acc = 1.0
[Validation] Batch ID = 22160, loss = 0.0146413, acc = 1.0
[Train] Batch ID = 22170, loss = 0.00502375, acc = 1.0
[Validation] Batch ID = 22170, loss = 0.034073, acc = 0.98
[Train] Batch ID = 22180, loss = 0.00557847, acc = 1.0
[Validation] Batch ID = 22180, loss = 0.0495318, acc = 0.96
[Train] Batch ID = 22190, loss = 0.00745926, acc = 1.0
[Validation] Batch ID = 22190, loss = 0.0480313, acc = 0.96
[Train] Batch ID = 22200, loss = 0.00775216, acc = 1.0
[Validation] Batch ID = 22200, loss = 0.0501152, acc = 0.96
[Train] Batch ID = 22210, loss = 0.00577299, acc = 1.0
[Validation] Batch ID = 22210, loss = 0.0321411, acc = 0.96
[Train] Batch ID = 22220, loss = 0.00846182, acc = 1.0
[Validation] Batch ID = 22220, loss = 0.0481242, acc = 0.96
[Train] Batch ID = 22230, loss = 0.00587592, acc = 1.0
[Validation] Batch ID = 22230, loss = 0.0636888, acc = 0.92
[Train] Batch ID = 22240, loss = 0.00468166, acc = 1.0
[Validation] Batch ID = 22240, loss = 0.0444666, acc = 0.96
[Train] Batch ID = 22250, loss = 0.00633408, acc = 1.0
[Validation] Batch ID = 22250, loss = 0.0234161, acc = 1.0
[Train] Batch ID = 22260, loss = 0.0066373, acc = 1.0
[Validation] Batch ID = 22260, loss = 0.0299362, acc = 1.0
[Train] Batch ID = 22270, loss = 0.00517482, acc = 1.0
[Validation] Batch ID = 22270, loss = 0.046774, acc = 0.98
[Train] Batch ID = 22280, loss = 0.00672987, acc = 1.0
[Validation] Batch ID = 22280, loss = 0.0196621, acc = 0.98
[Train] Batch ID = 22290, loss = 0.197103, acc = 0.84
[Validation] Batch ID = 22290, loss = 0.0201664, acc = 1.0
[Train] Batch ID = 22300, loss = 0.00548969, acc = 1.0
[Validation] Batch ID = 22300, loss = 0.0414805, acc = 0.96
[Train] Batch ID = 22310, loss = 0.00563474, acc = 1.0
[Validation] Batch ID = 22310, loss = 0.0419719, acc = 0.98
[Train] Batch ID = 22320, loss = 0.00188945, acc = 1.0
[Validation] Batch ID = 22320, loss = 0.0500314, acc = 0.96
[Train] Batch ID = 22330, loss = 0.00647365, acc = 1.0
[Validation] Batch ID = 22330, loss = 0.0454189, acc = 0.96
[Train] Batch ID = 22340, loss = 0.00295725, acc = 1.0
[Validation] Batch ID = 22340, loss = 0.0139679, acc = 1.0
[Train] Batch ID = 22350, loss = 0.00473694, acc = 1.0
[Validation] Batch ID = 22350, loss = 0.0200681, acc = 1.0
[Train] Batch ID = 22360, loss = 0.00505677, acc = 1.0
[Validation] Batch ID = 22360, loss = 0.0598724, acc = 0.92
[Train] Batch ID = 22370, loss = 0.00829745, acc = 1.0
[Validation] Batch ID = 22370, loss = 0.027589, acc = 0.98
[Train] Batch ID = 22380, loss = 0.00293998, acc = 1.0
[Validation] Batch ID = 22380, loss = 0.0544859, acc = 0.96
[Train] Batch ID = 22390, loss = 0.00713597, acc = 1.0
[Validation] Batch ID = 22390, loss = 0.055765, acc = 0.96
[Train] Batch ID = 22400, loss = 0.00628488, acc = 1.0
[Validation] Batch ID = 22400, loss = 0.0335789, acc = 0.96
[Train] Batch ID = 22410, loss = 0.00506182, acc = 1.0
[Validation] Batch ID = 22410, loss = 0.0396103, acc = 0.96
[Train] Batch ID = 22420, loss = 0.0046131, acc = 1.0
[Validation] Batch ID = 22420, loss = 0.0546499, acc = 0.94
[Train] Batch ID = 22430, loss = 0.00563878, acc = 1.0
[Validation] Batch ID = 22430, loss = 0.0548461, acc = 0.94
[Train] Batch ID = 22440, loss = 0.00653127, acc = 1.0
[Validation] Batch ID = 22440, loss = 0.0381548, acc = 0.98
[Train] Batch ID = 22450, loss = 0.00823087, acc = 1.0
[Validation] Batch ID = 22450, loss = 0.0215168, acc = 0.98
[Train] Batch ID = 22460, loss = 0.0050966, acc = 1.0
[Validation] Batch ID = 22460, loss = 0.0457356, acc = 0.96
[Train] Batch ID = 22470, loss = 0.00785023, acc = 1.0
[Validation] Batch ID = 22470, loss = 0.0516294, acc = 0.94
[Train] Batch ID = 22480, loss = 0.0086699, acc = 1.0
[Validation] Batch ID = 22480, loss = 0.0384347, acc = 0.98
[Train] Batch ID = 22490, loss = 0.00317992, acc = 1.0
[Validation] Batch ID = 22490, loss = 0.0338401, acc = 0.98
[Train] Batch ID = 22500, loss = 0.00430499, acc = 1.0
[Validation] Batch ID = 22500, loss = 0.0261521, acc = 0.98
[Train] Batch ID = 22510, loss = 0.00938016, acc = 1.0
[Validation] Batch ID = 22510, loss = 0.0397136, acc = 0.98
[Train] Batch ID = 22520, loss = 0.0062831, acc = 1.0
[Validation] Batch ID = 22520, loss = 0.0509953, acc = 0.94
[Train] Batch ID = 22530, loss = 0.00607588, acc = 1.0
[Validation] Batch ID = 22530, loss = 0.0261833, acc = 0.98
[Train] Batch ID = 22540, loss = 0.00718033, acc = 1.0
[Validation] Batch ID = 22540, loss = 0.0277302, acc = 0.98
[Train] Batch ID = 22550, loss = 0.00505912, acc = 1.0
[Validation] Batch ID = 22550, loss = 0.0516167, acc = 0.94
[Train] Batch ID = 22560, loss = 0.00351145, acc = 1.0
[Validation] Batch ID = 22560, loss = 0.0349169, acc = 0.98
[Train] Batch ID = 22570, loss = 0.00576437, acc = 1.0
[Validation] Batch ID = 22570, loss = 0.0687605, acc = 0.92
[Train] Batch ID = 22580, loss = 0.00734377, acc = 1.0
[Validation] Batch ID = 22580, loss = 0.0217323, acc = 1.0
[Train] Batch ID = 22590, loss = 0.00500316, acc = 1.0
[Validation] Batch ID = 22590, loss = 0.0191992, acc = 0.98
[Train] Batch ID = 22600, loss = 0.00650448, acc = 1.0
[Validation] Batch ID = 22600, loss = 0.0485845, acc = 0.94
[Train] Batch ID = 22610, loss = 0.00536948, acc = 1.0
[Validation] Batch ID = 22610, loss = 0.0406054, acc = 0.96
[Train] Batch ID = 22620, loss = 0.00509968, acc = 1.0
[Validation] Batch ID = 22620, loss = 0.0291728, acc = 0.98
[Train] Batch ID = 22630, loss = 0.00534438, acc = 1.0
[Validation] Batch ID = 22630, loss = 0.0585336, acc = 0.96
[Train] Batch ID = 22640, loss = 0.00662317, acc = 1.0
[Validation] Batch ID = 22640, loss = 0.0328691, acc = 0.96
[Train] Batch ID = 22650, loss = 0.0058527, acc = 1.0
[Validation] Batch ID = 22650, loss = 0.00898803, acc = 1.0
[Train] Batch ID = 22660, loss = 0.00481715, acc = 1.0
[Validation] Batch ID = 22660, loss = 0.0394216, acc = 0.96
[Train] Batch ID = 22670, loss = 0.00393814, acc = 1.0
[Validation] Batch ID = 22670, loss = 0.0197517, acc = 0.96
[Train] Batch ID = 22680, loss = 0.00688012, acc = 1.0
[Validation] Batch ID = 22680, loss = 0.0171295, acc = 1.0
[Train] Batch ID = 22690, loss = 0.00440038, acc = 1.0
[Validation] Batch ID = 22690, loss = 0.0425247, acc = 0.98
[Train] Batch ID = 22700, loss = 0.00569062, acc = 1.0
[Validation] Batch ID = 22700, loss = 0.0246355, acc = 1.0
[Train] Batch ID = 22710, loss = 0.00353526, acc = 1.0
[Validation] Batch ID = 22710, loss = 0.0161825, acc = 1.0
[Train] Batch ID = 22720, loss = 0.195191, acc = 0.86
[Validation] Batch ID = 22720, loss = 0.0248042, acc = 0.98
[Train] Batch ID = 22730, loss = 0.00520167, acc = 1.0
[Validation] Batch ID = 22730, loss = 0.0372026, acc = 0.96
[Train] Batch ID = 22740, loss = 0.00261571, acc = 1.0
[Validation] Batch ID = 22740, loss = 0.0210723, acc = 0.98
[Train] Batch ID = 22750, loss = 0.00690142, acc = 1.0
[Validation] Batch ID = 22750, loss = 0.0358433, acc = 0.98
[Train] Batch ID = 22760, loss = 0.00585432, acc = 1.0
[Validation] Batch ID = 22760, loss = 0.03298, acc = 0.98
[Train] Batch ID = 22770, loss = 0.00440441, acc = 1.0
[Validation] Batch ID = 22770, loss = 0.023753, acc = 0.96
[Train] Batch ID = 22780, loss = 0.00607835, acc = 1.0
[Validation] Batch ID = 22780, loss = 0.0355079, acc = 0.98
[Train] Batch ID = 22790, loss = 0.00600801, acc = 1.0
[Validation] Batch ID = 22790, loss = 0.028895, acc = 0.96
[Train] Batch ID = 22800, loss = 0.00502466, acc = 1.0
[Validation] Batch ID = 22800, loss = 0.0373409, acc = 0.94
[Train] Batch ID = 22810, loss = 0.00609741, acc = 1.0
[Validation] Batch ID = 22810, loss = 0.0306922, acc = 0.96
[Train] Batch ID = 22820, loss = 0.00899805, acc = 1.0
[Validation] Batch ID = 22820, loss = 0.0414447, acc = 1.0
[Train] Batch ID = 22830, loss = 0.00446882, acc = 1.0
[Validation] Batch ID = 22830, loss = 0.0190036, acc = 0.98
[Train] Batch ID = 22840, loss = 0.00984922, acc = 1.0
[Validation] Batch ID = 22840, loss = 0.0617702, acc = 0.96
[Train] Batch ID = 22850, loss = 0.00438874, acc = 1.0
[Validation] Batch ID = 22850, loss = 0.0407172, acc = 0.94
[Train] Batch ID = 22860, loss = 0.00674205, acc = 1.0
[Validation] Batch ID = 22860, loss = 0.0213648, acc = 1.0
[Train] Batch ID = 22870, loss = 0.00715968, acc = 1.0
[Validation] Batch ID = 22870, loss = 0.0495591, acc = 0.98
[Train] Batch ID = 22880, loss = 0.00942658, acc = 1.0
[Validation] Batch ID = 22880, loss = 0.0140981, acc = 1.0
[Train] Batch ID = 22890, loss = 0.00653552, acc = 1.0
[Validation] Batch ID = 22890, loss = 0.0455365, acc = 0.94
[Train] Batch ID = 22900, loss = 0.00530616, acc = 1.0
[Validation] Batch ID = 22900, loss = 0.052123, acc = 0.96
[Train] Batch ID = 22910, loss = 0.00610637, acc = 1.0
[Validation] Batch ID = 22910, loss = 0.0244052, acc = 0.98
[Train] Batch ID = 22920, loss = 0.00387799, acc = 1.0
[Validation] Batch ID = 22920, loss = 0.0544203, acc = 0.94
[Train] Batch ID = 22930, loss = 0.00690842, acc = 1.0
[Validation] Batch ID = 22930, loss = 0.029389, acc = 1.0
[Train] Batch ID = 22940, loss = 0.00701489, acc = 1.0
[Validation] Batch ID = 22940, loss = 0.0221939, acc = 0.98
[Train] Batch ID = 22950, loss = 0.00764623, acc = 1.0
[Validation] Batch ID = 22950, loss = 0.0285962, acc = 0.98
[Train] Batch ID = 22960, loss = 0.00337209, acc = 1.0
[Validation] Batch ID = 22960, loss = 0.0340476, acc = 0.98
[Train] Batch ID = 22970, loss = 0.00475364, acc = 1.0
[Validation] Batch ID = 22970, loss = 0.0300634, acc = 0.98
[Train] Batch ID = 22980, loss = 0.00324629, acc = 1.0
[Validation] Batch ID = 22980, loss = 0.0355735, acc = 0.98
[Train] Batch ID = 22990, loss = 0.214933, acc = 0.76
[Validation] Batch ID = 22990, loss = 0.0280351, acc = 0.98
[Train] Batch ID = 23000, loss = 0.0091363, acc = 1.0
[Validation] Batch ID = 23000, loss = 0.0264136, acc = 0.98
Evaluate full validation dataset ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Saving model ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Current loss: 0.0357922 Best loss: 0.0364358
[TOTAL Validation] Batch ID = 23000, loss = 0.0357922, acc = 0.971655328798
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Model successfully saved here: outputs/checkpoints/c1s_9_c1n_256_c2s_6_c2n_64_c2d_0.7_c1vl_16_c1s_5_c1nf_16_c2vl_32_lr_0.0001_rs_1--TrafficSign--1510487290.423481
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Augmented Factor = 0.07896877864610383
[Train] Batch ID = 23010, loss = 0.00660331, acc = 1.0
[Validation] Batch ID = 23010, loss = 0.0485754, acc = 0.98
[Train] Batch ID = 23020, loss = 0.00442421, acc = 1.0
[Validation] Batch ID = 23020, loss = 0.0418112, acc = 0.96
[Train] Batch ID = 23030, loss = 0.0066666, acc = 1.0
[Validation] Batch ID = 23030, loss = 0.0336958, acc = 0.98
[Train] Batch ID = 23040, loss = 0.00516861, acc = 1.0
[Validation] Batch ID = 23040, loss = 0.0514943, acc = 0.94
[Train] Batch ID = 23050, loss = 0.0038622, acc = 1.0
[Validation] Batch ID = 23050, loss = 0.113327, acc = 0.8
[Train] Batch ID = 23060, loss = 0.00431931, acc = 1.0
[Validation] Batch ID = 23060, loss = 0.0316894, acc = 0.98
[Train] Batch ID = 23070, loss = 0.187926, acc = 0.84
[Validation] Batch ID = 23070, loss = 0.0262045, acc = 0.98
[Train] Batch ID = 23080, loss = 0.00529092, acc = 1.0
[Validation] Batch ID = 23080, loss = 0.0492435, acc = 0.96
[Train] Batch ID = 23090, loss = 0.00331653, acc = 1.0
[Validation] Batch ID = 23090, loss = 0.0330777, acc = 1.0
[Train] Batch ID = 23100, loss = 0.00375787, acc = 1.0
[Validation] Batch ID = 23100, loss = 0.0325624, acc = 0.96
[Train] Batch ID = 23110, loss = 0.00493896, acc = 1.0
[Validation] Batch ID = 23110, loss = 0.0194393, acc = 1.0
[Train] Batch ID = 23120, loss = 0.00607216, acc = 1.0
[Validation] Batch ID = 23120, loss = 0.0554626, acc = 0.92
[Train] Batch ID = 23130, loss = 0.0109877, acc = 1.0
[Validation] Batch ID = 23130, loss = 0.0602483, acc = 0.96
[Train] Batch ID = 23140, loss = 0.0051292, acc = 1.0
[Validation] Batch ID = 23140, loss = 0.0219392, acc = 1.0
[Train] Batch ID = 23150, loss = 0.00388309, acc = 1.0
[Validation] Batch ID = 23150, loss = 0.024183, acc = 0.98
[Train] Batch ID = 23160, loss = 0.00345644, acc = 1.0
[Validation] Batch ID = 23160, loss = 0.011019, acc = 1.0
[Train] Batch ID = 23170, loss = 0.00435262, acc = 1.0
[Validation] Batch ID = 23170, loss = 0.043503, acc = 0.96
[Train] Batch ID = 23180, loss = 0.00482166, acc = 1.0
[Validation] Batch ID = 23180, loss = 0.0394002, acc = 0.98
[Train] Batch ID = 23190, loss = 0.00339746, acc = 1.0
[Validation] Batch ID = 23190, loss = 0.0299335, acc = 0.98
[Train] Batch ID = 23200, loss = 0.00785526, acc = 1.0
[Validation] Batch ID = 23200, loss = 0.0400259, acc = 0.98
[Train] Batch ID = 23210, loss = 0.214057, acc = 0.84
[Validation] Batch ID = 23210, loss = 0.0160131, acc = 1.0
[Train] Batch ID = 23220, loss = 0.00519621, acc = 1.0
[Validation] Batch ID = 23220, loss = 0.0250011, acc = 0.98
[Train] Batch ID = 23230, loss = 0.00554828, acc = 1.0
[Validation] Batch ID = 23230, loss = 0.0487912, acc = 0.92
[Train] Batch ID = 23240, loss = 0.0046311, acc = 1.0
[Validation] Batch ID = 23240, loss = 0.0268337, acc = 0.98
[Train] Batch ID = 23250, loss = 0.00228803, acc = 1.0
[Validation] Batch ID = 23250, loss = 0.0441184, acc = 0.98
[Train] Batch ID = 23260, loss = 0.00305359, acc = 1.0
[Validation] Batch ID = 23260, loss = 0.0318816, acc = 0.96
[Train] Batch ID = 23270, loss = 0.00618312, acc = 1.0
[Validation] Batch ID = 23270, loss = 0.0313141, acc = 0.96
[Train] Batch ID = 23280, loss = 0.00651635, acc = 1.0
[Validation] Batch ID = 23280, loss = 0.0382159, acc = 0.96
[Train] Batch ID = 23290, loss = 0.00688975, acc = 1.0
[Validation] Batch ID = 23290, loss = 0.0227398, acc = 1.0
[Train] Batch ID = 23300, loss = 0.00549423, acc = 1.0
[Validation] Batch ID = 23300, loss = 0.0340732, acc = 0.94
[Train] Batch ID = 23310, loss = 0.00317489, acc = 1.0
[Validation] Batch ID = 23310, loss = 0.0697988, acc = 0.9
[Train] Batch ID = 23320, loss = 0.00393973, acc = 1.0
[Validation] Batch ID = 23320, loss = 0.0439772, acc = 0.98
[Train] Batch ID = 23330, loss = 0.00437341, acc = 1.0
[Validation] Batch ID = 23330, loss = 0.0355969, acc = 0.98
[Train] Batch ID = 23340, loss = 0.00675147, acc = 1.0
[Validation] Batch ID = 23340, loss = 0.00877169, acc = 1.0
[Train] Batch ID = 23350, loss = 0.199488, acc = 0.88
[Validation] Batch ID = 23350, loss = 0.0495391, acc = 0.94
[Train] Batch ID = 23360, loss = 0.00754198, acc = 1.0
[Validation] Batch ID = 23360, loss = 0.0241928, acc = 0.98
[Train] Batch ID = 23370, loss = 0.195322, acc = 0.84
[Validation] Batch ID = 23370, loss = 0.0497776, acc = 0.96
[Train] Batch ID = 23380, loss = 0.228287, acc = 0.78
[Validation] Batch ID = 23380, loss = 0.0334007, acc = 1.0
[Train] Batch ID = 23390, loss = 0.0101259, acc = 1.0
[Validation] Batch ID = 23390, loss = 0.0147533, acc = 1.0
[Train] Batch ID = 23400, loss = 0.00712865, acc = 1.0
[Validation] Batch ID = 23400, loss = 0.0568539, acc = 0.9
[Train] Batch ID = 23410, loss = 0.00421961, acc = 1.0
[Validation] Batch ID = 23410, loss = 0.0280702, acc = 0.98
[Train] Batch ID = 23420, loss = 0.00391576, acc = 1.0
[Validation] Batch ID = 23420, loss = 0.0618954, acc = 0.92
[Train] Batch ID = 23430, loss = 0.0127039, acc = 1.0
[Validation] Batch ID = 23430, loss = 0.0539598, acc = 0.94
[Train] Batch ID = 23440, loss = 0.00655749, acc = 1.0
[Validation] Batch ID = 23440, loss = 0.025256, acc = 0.98
[Train] Batch ID = 23450, loss = 0.00790948, acc = 1.0
[Validation] Batch ID = 23450, loss = 0.0600409, acc = 0.94
[Train] Batch ID = 23460, loss = 0.00729581, acc = 1.0
[Validation] Batch ID = 23460, loss = 0.0288129, acc = 1.0
[Train] Batch ID = 23470, loss = 0.00562447, acc = 1.0
[Validation] Batch ID = 23470, loss = 0.0439066, acc = 0.96
[Train] Batch ID = 23480, loss = 0.187612, acc = 0.82
[Validation] Batch ID = 23480, loss = 0.0223645, acc = 0.98
[Train] Batch ID = 23490, loss = 0.00629397, acc = 1.0
[Validation] Batch ID = 23490, loss = 0.0420102, acc = 0.96
[Train] Batch ID = 23500, loss = 0.00721004, acc = 1.0
[Validation] Batch ID = 23500, loss = 0.0407961, acc = 0.96
[Train] Batch ID = 23510, loss = 0.00899995, acc = 1.0
[Validation] Batch ID = 23510, loss = 0.0467837, acc = 0.98
[Train] Batch ID = 23520, loss = 0.00634343, acc = 1.0
[Validation] Batch ID = 23520, loss = 0.0144673, acc = 1.0
[Train] Batch ID = 23530, loss = 0.00897011, acc = 1.0
[Validation] Batch ID = 23530, loss = 0.0447142, acc = 0.96
[Train] Batch ID = 23540, loss = 0.00417968, acc = 1.0
[Validation] Batch ID = 23540, loss = 0.0353222, acc = 0.96
[Train] Batch ID = 23550, loss = 0.257915, acc = 0.7
[Validation] Batch ID = 23550, loss = 0.0273358, acc = 0.98
[Train] Batch ID = 23560, loss = 0.00520934, acc = 1.0
[Validation] Batch ID = 23560, loss = 0.0471971, acc = 0.98
[Train] Batch ID = 23570, loss = 0.00538207, acc = 1.0
[Validation] Batch ID = 23570, loss = 0.0194026, acc = 1.0
[Train] Batch ID = 23580, loss = 0.00752144, acc = 1.0
[Validation] Batch ID = 23580, loss = 0.0320699, acc = 0.98
[Train] Batch ID = 23590, loss = 0.00349439, acc = 1.0
[Validation] Batch ID = 23590, loss = 0.0227085, acc = 1.0
[Train] Batch ID = 23600, loss = 0.00879489, acc = 1.0
[Validation] Batch ID = 23600, loss = 0.053784, acc = 0.98
[Train] Batch ID = 23610, loss = 0.00492119, acc = 1.0
[Validation] Batch ID = 23610, loss = 0.0552925, acc = 0.92
[Train] Batch ID = 23620, loss = 0.00460741, acc = 1.0
[Validation] Batch ID = 23620, loss = 0.0355489, acc = 0.96
[Train] Batch ID = 23630, loss = 0.00531274, acc = 1.0
[Validation] Batch ID = 23630, loss = 0.0269508, acc = 0.98
[Train] Batch ID = 23640, loss = 0.00845728, acc = 1.0
[Validation] Batch ID = 23640, loss = 0.0279656, acc = 1.0
[Train] Batch ID = 23650, loss = 0.00447639, acc = 1.0
[Validation] Batch ID = 23650, loss = 0.0342031, acc = 0.96
[Train] Batch ID = 23660, loss = 0.00609825, acc = 1.0
[Validation] Batch ID = 23660, loss = 0.047885, acc = 0.96
[Train] Batch ID = 23670, loss = 0.00897005, acc = 1.0
[Validation] Batch ID = 23670, loss = 0.0402215, acc = 0.98
[Train] Batch ID = 23680, loss = 0.00389002, acc = 1.0
[Validation] Batch ID = 23680, loss = 0.0234225, acc = 1.0
[Train] Batch ID = 23690, loss = 0.1706, acc = 0.86
[Validation] Batch ID = 23690, loss = 0.0249534, acc = 1.0
[Train] Batch ID = 23700, loss = 0.00830525, acc = 1.0
[Validation] Batch ID = 23700, loss = 0.0424039, acc = 0.96
[Train] Batch ID = 23710, loss = 0.00545218, acc = 1.0
[Validation] Batch ID = 23710, loss = 0.0316907, acc = 0.96
[Train] Batch ID = 23720, loss = 0.0059038, acc = 1.0
[Validation] Batch ID = 23720, loss = 0.0139169, acc = 1.0
[Train] Batch ID = 23730, loss = 0.00578118, acc = 1.0
[Validation] Batch ID = 23730, loss = 0.0261535, acc = 1.0
[Train] Batch ID = 23740, loss = 0.00336587, acc = 1.0
[Validation] Batch ID = 23740, loss = 0.0474843, acc = 0.96
[Train] Batch ID = 23750, loss = 0.00602477, acc = 1.0
[Validation] Batch ID = 23750, loss = 0.0291934, acc = 1.0
[Train] Batch ID = 23760, loss = 0.0108792, acc = 1.0
[Validation] Batch ID = 23760, loss = 0.0428995, acc = 0.98
[Train] Batch ID = 23770, loss = 0.00570094, acc = 1.0
[Validation] Batch ID = 23770, loss = 0.0266108, acc = 0.98
[Train] Batch ID = 23780, loss = 0.00327943, acc = 1.0
[Validation] Batch ID = 23780, loss = 0.0362104, acc = 0.98
[Train] Batch ID = 23790, loss = 0.00398458, acc = 1.0
[Validation] Batch ID = 23790, loss = 0.0598628, acc = 0.92
[Train] Batch ID = 23800, loss = 0.00302706, acc = 1.0
[Validation] Batch ID = 23800, loss = 0.0450767, acc = 0.94
[Train] Batch ID = 23810, loss = 0.00617636, acc = 1.0
[Validation] Batch ID = 23810, loss = 0.0245737, acc = 0.98
[Train] Batch ID = 23820, loss = 0.00520702, acc = 1.0
[Validation] Batch ID = 23820, loss = 0.0556911, acc = 0.92
[Train] Batch ID = 23830, loss = 0.00331261, acc = 1.0
[Validation] Batch ID = 23830, loss = 0.0245318, acc = 1.0
[Train] Batch ID = 23840, loss = 0.226168, acc = 0.76
[Validation] Batch ID = 23840, loss = 0.0409855, acc = 0.96
[Train] Batch ID = 23850, loss = 0.00995898, acc = 1.0
[Validation] Batch ID = 23850, loss = 0.0427193, acc = 0.98
[Train] Batch ID = 23860, loss = 0.00738019, acc = 1.0
[Validation] Batch ID = 23860, loss = 0.0294154, acc = 0.98
[Train] Batch ID = 23870, loss = 0.00544425, acc = 1.0
[Validation] Batch ID = 23870, loss = 0.0300088, acc = 0.98
[Train] Batch ID = 23880, loss = 0.00675394, acc = 1.0
[Validation] Batch ID = 23880, loss = 0.030962, acc = 0.98
[Train] Batch ID = 23890, loss = 0.00468673, acc = 1.0
[Validation] Batch ID = 23890, loss = 0.0479049, acc = 0.94
[Train] Batch ID = 23900, loss = 0.00556584, acc = 1.0
[Validation] Batch ID = 23900, loss = 0.027891, acc = 1.0
[Train] Batch ID = 23910, loss = 0.00457006, acc = 1.0
[Validation] Batch ID = 23910, loss = 0.0389271, acc = 0.96
[Train] Batch ID = 23920, loss = 0.22496, acc = 0.74
[Validation] Batch ID = 23920, loss = 0.0389296, acc = 0.98
[Train] Batch ID = 23930, loss = 0.174914, acc = 0.9
[Validation] Batch ID = 23930, loss = 0.0535488, acc = 0.96
[Train] Batch ID = 23940, loss = 0.00701756, acc = 1.0
[Validation] Batch ID = 23940, loss = 0.0354619, acc = 1.0
[Train] Batch ID = 23950, loss = 0.00323051, acc = 1.0
[Validation] Batch ID = 23950, loss = 0.0490318, acc = 0.94
[Train] Batch ID = 23960, loss = 0.00730346, acc = 1.0
[Validation] Batch ID = 23960, loss = 0.0443647, acc = 0.96
[Train] Batch ID = 23970, loss = 0.00872781, acc = 1.0
[Validation] Batch ID = 23970, loss = 0.0220032, acc = 1.0
[Train] Batch ID = 23980, loss = 0.18005, acc = 0.86
[Validation] Batch ID = 23980, loss = 0.0303295, acc = 1.0
[Train] Batch ID = 23990, loss = 0.20618, acc = 0.84
[Validation] Batch ID = 23990, loss = 0.0363862, acc = 0.96
[Train] Batch ID = 24000, loss = 0.00449326, acc = 1.0
[Validation] Batch ID = 24000, loss = 0.0423407, acc = 0.98
Evaluate full validation dataset ...
Current loss: 0.0367299 Best loss: 0.0357922
[TOTAL Validation] Batch ID = 24000, loss = 0.0367299, acc = 0.97619047619
Augmented Factor = 0.07107190078149345
[Train] Batch ID = 24010, loss = 0.00352486, acc = 1.0
[Validation] Batch ID = 24010, loss = 0.0334499, acc = 0.96
[Train] Batch ID = 24020, loss = 0.005968, acc = 1.0
[Validation] Batch ID = 24020, loss = 0.032706, acc = 0.98
[Train] Batch ID = 24030, loss = 0.0057694, acc = 1.0
[Validation] Batch ID = 24030, loss = 0.0322401, acc = 0.98
[Train] Batch ID = 24040, loss = 0.004735, acc = 1.0
[Validation] Batch ID = 24040, loss = 0.035968, acc = 0.98
[Train] Batch ID = 24050, loss = 0.00428464, acc = 1.0
[Validation] Batch ID = 24050, loss = 0.0484945, acc = 0.96
[Train] Batch ID = 24060, loss = 0.00583416, acc = 1.0
[Validation] Batch ID = 24060, loss = 0.0413706, acc = 0.96
[Train] Batch ID = 24070, loss = 0.00213506, acc = 1.0
[Validation] Batch ID = 24070, loss = 0.042967, acc = 0.94
[Train] Batch ID = 24080, loss = 0.00687046, acc = 1.0
[Validation] Batch ID = 24080, loss = 0.0495778, acc = 0.96
[Train] Batch ID = 24090, loss = 0.00750339, acc = 1.0
[Validation] Batch ID = 24090, loss = 0.0225326, acc = 1.0
[Train] Batch ID = 24100, loss = 0.0035057, acc = 1.0
[Validation] Batch ID = 24100, loss = 0.022375, acc = 1.0
[Train] Batch ID = 24110, loss = 0.00570989, acc = 1.0
[Validation] Batch ID = 24110, loss = 0.0286189, acc = 0.98
[Train] Batch ID = 24120, loss = 0.00629952, acc = 1.0
[Validation] Batch ID = 24120, loss = 0.0216584, acc = 0.98
[Train] Batch ID = 24130, loss = 0.00520103, acc = 1.0
[Validation] Batch ID = 24130, loss = 0.0443877, acc = 0.96
[Train] Batch ID = 24140, loss = 0.223145, acc = 0.72
[Validation] Batch ID = 24140, loss = 0.0372075, acc = 0.98
[Train] Batch ID = 24150, loss = 0.00567802, acc = 1.0
[Validation] Batch ID = 24150, loss = 0.0517043, acc = 0.94
[Train] Batch ID = 24160, loss = 0.00600864, acc = 1.0
[Validation] Batch ID = 24160, loss = 0.0243798, acc = 0.98
[Train] Batch ID = 24170, loss = 0.00395606, acc = 1.0
[Validation] Batch ID = 24170, loss = 0.0345373, acc = 0.98
[Train] Batch ID = 24180, loss = 0.00185226, acc = 1.0
[Validation] Batch ID = 24180, loss = 0.0144064, acc = 1.0
[Train] Batch ID = 24190, loss = 0.00225131, acc = 1.0
[Validation] Batch ID = 24190, loss = 0.0281935, acc = 1.0
[Train] Batch ID = 24200, loss = 0.178447, acc = 0.94
[Validation] Batch ID = 24200, loss = 0.0412097, acc = 0.94
[Train] Batch ID = 24210, loss = 0.00513449, acc = 1.0
[Validation] Batch ID = 24210, loss = 0.0167854, acc = 1.0
[Train] Batch ID = 24220, loss = 0.00358039, acc = 1.0
[Validation] Batch ID = 24220, loss = 0.0322637, acc = 0.96
[Train] Batch ID = 24230, loss = 0.00973643, acc = 1.0
[Validation] Batch ID = 24230, loss = 0.0245861, acc = 0.98
[Train] Batch ID = 24240, loss = 0.00385076, acc = 1.0
[Validation] Batch ID = 24240, loss = 0.0240778, acc = 1.0
[Train] Batch ID = 24250, loss = 0.00662441, acc = 1.0
[Validation] Batch ID = 24250, loss = 0.0597829, acc = 0.92
[Train] Batch ID = 24260, loss = 0.00625236, acc = 1.0
[Validation] Batch ID = 24260, loss = 0.0430678, acc = 0.96
[Train] Batch ID = 24270, loss = 0.00745797, acc = 1.0
[Validation] Batch ID = 24270, loss = 0.0274199, acc = 0.98
[Train] Batch ID = 24280, loss = 0.00653947, acc = 1.0
[Validation] Batch ID = 24280, loss = 0.029208, acc = 0.98
[Train] Batch ID = 24290, loss = 0.00401116, acc = 1.0
[Validation] Batch ID = 24290, loss = 0.012159, acc = 1.0
[Train] Batch ID = 24300, loss = 0.00492428, acc = 1.0
[Validation] Batch ID = 24300, loss = 0.0304341, acc = 0.98
[Train] Batch ID = 24310, loss = 0.00364542, acc = 1.0
[Validation] Batch ID = 24310, loss = 0.0369927, acc = 0.96
[Train] Batch ID = 24320, loss = 0.00292067, acc = 1.0
[Validation] Batch ID = 24320, loss = 0.0210507, acc = 1.0
[Train] Batch ID = 24330, loss = 0.00395551, acc = 1.0
[Validation] Batch ID = 24330, loss = 0.0267802, acc = 0.98
[Train] Batch ID = 24340, loss = 0.00802353, acc = 1.0
[Validation] Batch ID = 24340, loss = 0.0112831, acc = 1.0
[Train] Batch ID = 24350, loss = 0.00469307, acc = 1.0
[Validation] Batch ID = 24350, loss = 0.0127294, acc = 1.0
[Train] Batch ID = 24360, loss = 0.00981909, acc = 1.0
[Validation] Batch ID = 24360, loss = 0.0298972, acc = 1.0
[Train] Batch ID = 24370, loss = 0.00593166, acc = 1.0
[Validation] Batch ID = 24370, loss = 0.0196194, acc = 1.0
[Train] Batch ID = 24380, loss = 0.0048641, acc = 1.0
[Validation] Batch ID = 24380, loss = 0.0133046, acc = 1.0
[Train] Batch ID = 24390, loss = 0.00301852, acc = 1.0
[Validation] Batch ID = 24390, loss = 0.0251501, acc = 0.98
[Train] Batch ID = 24400, loss = 0.00410531, acc = 1.0
[Validation] Batch ID = 24400, loss = 0.026933, acc = 1.0
[Train] Batch ID = 24410, loss = 0.00392793, acc = 1.0
[Validation] Batch ID = 24410, loss = 0.0256165, acc = 0.96
[Train] Batch ID = 24420, loss = 0.00416732, acc = 1.0
[Validation] Batch ID = 24420, loss = 0.0273996, acc = 1.0
[Train] Batch ID = 24430, loss = 0.00578181, acc = 1.0
[Validation] Batch ID = 24430, loss = 0.0380136, acc = 0.98
[Train] Batch ID = 24440, loss = 0.00579406, acc = 1.0
[Validation] Batch ID = 24440, loss = 0.0539137, acc = 0.96
[Train] Batch ID = 24450, loss = 0.00885114, acc = 1.0
[Validation] Batch ID = 24450, loss = 0.0381758, acc = 0.98
[Train] Batch ID = 24460, loss = 0.00778931, acc = 1.0
[Validation] Batch ID = 24460, loss = 0.0217391, acc = 1.0
[Train] Batch ID = 24470, loss = 0.193765, acc = 0.92
[Validation] Batch ID = 24470, loss = 0.041658, acc = 0.98
[Train] Batch ID = 24480, loss = 0.00529989, acc = 1.0
[Validation] Batch ID = 24480, loss = 0.0308775, acc = 0.98
[Train] Batch ID = 24490, loss = 0.00640004, acc = 1.0
[Validation] Batch ID = 24490, loss = 0.0175122, acc = 0.98
[Train] Batch ID = 24500, loss = 0.00694058, acc = 1.0
[Validation] Batch ID = 24500, loss = 0.0322712, acc = 0.98
[Train] Batch ID = 24510, loss = 0.00552657, acc = 1.0
[Validation] Batch ID = 24510, loss = 0.0194014, acc = 1.0
[Train] Batch ID = 24520, loss = 0.00286053, acc = 1.0
[Validation] Batch ID = 24520, loss = 0.0430332, acc = 0.98
[Train] Batch ID = 24530, loss = 0.0150452, acc = 1.0
[Validation] Batch ID = 24530, loss = 0.0275533, acc = 1.0
[Train] Batch ID = 24540, loss = 0.00293442, acc = 1.0
[Validation] Batch ID = 24540, loss = 0.0446893, acc = 0.96
[Train] Batch ID = 24550, loss = 0.00932711, acc = 1.0
[Validation] Batch ID = 24550, loss = 0.0112964, acc = 1.0
[Train] Batch ID = 24560, loss = 0.00550307, acc = 1.0
[Validation] Batch ID = 24560, loss = 0.0194865, acc = 0.98
[Train] Batch ID = 24570, loss = 0.00969744, acc = 1.0
[Validation] Batch ID = 24570, loss = 0.0400699, acc = 0.96
[Train] Batch ID = 24580, loss = 0.0103241, acc = 1.0
[Validation] Batch ID = 24580, loss = 0.0575275, acc = 0.94
[Train] Batch ID = 24590, loss = 0.204736, acc = 0.86
[Validation] Batch ID = 24590, loss = 0.026332, acc = 0.98
[Train] Batch ID = 24600, loss = 0.186629, acc = 0.84
[Validation] Batch ID = 24600, loss = 0.0205656, acc = 1.0
[Train] Batch ID = 24610, loss = 0.00900012, acc = 1.0
[Validation] Batch ID = 24610, loss = 0.0312581, acc = 0.96
[Train] Batch ID = 24620, loss = 0.00410627, acc = 1.0
[Validation] Batch ID = 24620, loss = 0.04332, acc = 0.96
[Train] Batch ID = 24630, loss = 0.00727379, acc = 1.0
[Validation] Batch ID = 24630, loss = 0.03893, acc = 0.98
[Train] Batch ID = 24640, loss = 0.00247582, acc = 1.0
[Validation] Batch ID = 24640, loss = 0.0158418, acc = 1.0
[Train] Batch ID = 24650, loss = 0.00353379, acc = 1.0
[Validation] Batch ID = 24650, loss = 0.0304606, acc = 0.98
[Train] Batch ID = 24660, loss = 0.00429027, acc = 1.0
[Validation] Batch ID = 24660, loss = 0.0252816, acc = 1.0
[Train] Batch ID = 24670, loss = 0.00526662, acc = 1.0
[Validation] Batch ID = 24670, loss = 0.0178285, acc = 1.0
[Train] Batch ID = 24680, loss = 0.00707979, acc = 1.0
[Validation] Batch ID = 24680, loss = 0.048138, acc = 0.96
[Train] Batch ID = 24690, loss = 0.00580515, acc = 1.0
[Validation] Batch ID = 24690, loss = 0.0355851, acc = 0.98
[Train] Batch ID = 24700, loss = 0.00231191, acc = 1.0
[Validation] Batch ID = 24700, loss = 0.038812, acc = 0.96
[Train] Batch ID = 24710, loss = 0.0043974, acc = 1.0
[Validation] Batch ID = 24710, loss = 0.0373893, acc = 0.96
[Train] Batch ID = 24720, loss = 0.0029025, acc = 1.0
[Validation] Batch ID = 24720, loss = 0.0465178, acc = 0.96
[Train] Batch ID = 24730, loss = 0.00647107, acc = 1.0
[Validation] Batch ID = 24730, loss = 0.0322894, acc = 0.98
[Train] Batch ID = 24740, loss = 0.00485711, acc = 1.0
[Validation] Batch ID = 24740, loss = 0.0520731, acc = 0.94
[Train] Batch ID = 24750, loss = 0.00324136, acc = 1.0
[Validation] Batch ID = 24750, loss = 0.0290797, acc = 0.98
[Train] Batch ID = 24760, loss = 0.00346774, acc = 1.0
[Validation] Batch ID = 24760, loss = 0.0474462, acc = 0.94
[Train] Batch ID = 24770, loss = 0.0089573, acc = 1.0
[Validation] Batch ID = 24770, loss = 0.0485758, acc = 0.94
[Train] Batch ID = 24780, loss = 0.00987406, acc = 1.0
[Validation] Batch ID = 24780, loss = 0.0370981, acc = 0.96
[Train] Batch ID = 24790, loss = 0.00806436, acc = 1.0
[Validation] Batch ID = 24790, loss = 0.0454963, acc = 1.0
[Train] Batch ID = 24800, loss = 0.00577064, acc = 1.0
[Validation] Batch ID = 24800, loss = 0.044444, acc = 0.96
[Train] Batch ID = 24810, loss = 0.159194, acc = 0.88
[Validation] Batch ID = 24810, loss = 0.0312028, acc = 1.0
[Train] Batch ID = 24820, loss = 0.010516, acc = 1.0
[Validation] Batch ID = 24820, loss = 0.0466342, acc = 0.96
[Train] Batch ID = 24830, loss = 0.00417545, acc = 1.0
[Validation] Batch ID = 24830, loss = 0.0965958, acc = 0.8
[Train] Batch ID = 24840, loss = 0.00264482, acc = 1.0
[Validation] Batch ID = 24840, loss = 0.0378908, acc = 0.98
[Train] Batch ID = 24850, loss = 0.00336255, acc = 1.0
[Validation] Batch ID = 24850, loss = 0.0324793, acc = 0.98
[Train] Batch ID = 24860, loss = 0.00567321, acc = 1.0
[Validation] Batch ID = 24860, loss = 0.0796566, acc = 0.92
[Train] Batch ID = 24870, loss = 0.0054318, acc = 1.0
[Validation] Batch ID = 24870, loss = 0.0339976, acc = 0.94
[Train] Batch ID = 24880, loss = 0.0064051, acc = 1.0
[Validation] Batch ID = 24880, loss = 0.0337051, acc = 0.96
[Train] Batch ID = 24890, loss = 0.00642756, acc = 1.0
[Validation] Batch ID = 24890, loss = 0.0206096, acc = 1.0
[Train] Batch ID = 24900, loss = 0.00491377, acc = 1.0
[Validation] Batch ID = 24900, loss = 0.0325694, acc = 0.98
[Train] Batch ID = 24910, loss = 0.00598879, acc = 1.0
[Validation] Batch ID = 24910, loss = 0.0184886, acc = 1.0
[Train] Batch ID = 24920, loss = 0.00784798, acc = 1.0
[Validation] Batch ID = 24920, loss = 0.0289651, acc = 0.98
[Train] Batch ID = 24930, loss = 0.00403902, acc = 1.0
[Validation] Batch ID = 24930, loss = 0.0106058, acc = 1.0
[Train] Batch ID = 24940, loss = 0.00668513, acc = 1.0
[Validation] Batch ID = 24940, loss = 0.0147243, acc = 1.0
[Train] Batch ID = 24950, loss = 0.00278266, acc = 1.0
[Validation] Batch ID = 24950, loss = 0.035463, acc = 0.96
[Train] Batch ID = 24960, loss = 0.00522582, acc = 1.0
[Validation] Batch ID = 24960, loss = 0.0327158, acc = 0.98
[Train] Batch ID = 24970, loss = 0.222803, acc = 0.76
[Validation] Batch ID = 24970, loss = 0.0254868, acc = 1.0
[Train] Batch ID = 24980, loss = 0.00747713, acc = 1.0
[Validation] Batch ID = 24980, loss = 0.0340503, acc = 0.98
[Train] Batch ID = 24990, loss = 0.00232613, acc = 1.0
[Validation] Batch ID = 24990, loss = 0.0392842, acc = 0.94
[Train] Batch ID = 25000, loss = 0.0035359, acc = 1.0
[Validation] Batch ID = 25000, loss = 0.0661726, acc = 0.92
Evaluate full validation dataset ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Saving model ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Current loss: 0.0344537 Best loss: 0.0357922
[TOTAL Validation] Batch ID = 25000, loss = 0.0344537, acc = 0.973242630385
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Model successfully saved here: outputs/checkpoints/c1s_9_c1n_256_c2s_6_c2n_64_c2d_0.7_c1vl_16_c1s_5_c1nf_16_c2vl_32_lr_0.0001_rs_1--TrafficSign--1510487290.423481
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Augmented Factor = 0.0639647107033441
[Train] Batch ID = 25010, loss = 0.00639635, acc = 1.0
[Validation] Batch ID = 25010, loss = 0.0449188, acc = 0.96
[Train] Batch ID = 25020, loss = 0.00420539, acc = 1.0
[Validation] Batch ID = 25020, loss = 0.027596, acc = 0.98
[Train] Batch ID = 25030, loss = 0.00459945, acc = 1.0
[Validation] Batch ID = 25030, loss = 0.00974723, acc = 1.0
[Train] Batch ID = 25040, loss = 0.0034657, acc = 1.0
[Validation] Batch ID = 25040, loss = 0.0230413, acc = 0.98
[Train] Batch ID = 25050, loss = 0.00362659, acc = 1.0
[Validation] Batch ID = 25050, loss = 0.0260174, acc = 0.98
[Train] Batch ID = 25060, loss = 0.0032951, acc = 1.0
[Validation] Batch ID = 25060, loss = 0.0320628, acc = 0.96
[Train] Batch ID = 25070, loss = 0.210708, acc = 0.82
[Validation] Batch ID = 25070, loss = 0.0326852, acc = 0.98
[Train] Batch ID = 25080, loss = 0.00708059, acc = 1.0
[Validation] Batch ID = 25080, loss = 0.0180377, acc = 0.98
[Train] Batch ID = 25090, loss = 0.00390868, acc = 1.0
[Validation] Batch ID = 25090, loss = 0.0409415, acc = 0.96
[Train] Batch ID = 25100, loss = 0.00501257, acc = 1.0
[Validation] Batch ID = 25100, loss = 0.0196659, acc = 0.98
[Train] Batch ID = 25110, loss = 0.00551312, acc = 1.0
[Validation] Batch ID = 25110, loss = 0.0655031, acc = 0.94
[Train] Batch ID = 25120, loss = 0.0080233, acc = 1.0
[Validation] Batch ID = 25120, loss = 0.0378634, acc = 0.96
[Train] Batch ID = 25130, loss = 0.00290751, acc = 1.0
[Validation] Batch ID = 25130, loss = 0.0284173, acc = 1.0
[Train] Batch ID = 25140, loss = 0.00486272, acc = 1.0
[Validation] Batch ID = 25140, loss = 0.0596583, acc = 0.92
[Train] Batch ID = 25150, loss = 0.00660316, acc = 1.0
[Validation] Batch ID = 25150, loss = 0.0335855, acc = 0.98
[Train] Batch ID = 25160, loss = 0.00487435, acc = 1.0
[Validation] Batch ID = 25160, loss = 0.0176225, acc = 0.98
[Train] Batch ID = 25170, loss = 0.00379892, acc = 1.0
[Validation] Batch ID = 25170, loss = 0.0265738, acc = 0.98
[Train] Batch ID = 25180, loss = 0.00209184, acc = 1.0
[Validation] Batch ID = 25180, loss = 0.0495574, acc = 0.94
[Train] Batch ID = 25190, loss = 0.00273337, acc = 1.0
[Validation] Batch ID = 25190, loss = 0.0283798, acc = 0.98
[Train] Batch ID = 25200, loss = 0.00353634, acc = 1.0
[Validation] Batch ID = 25200, loss = 0.0542001, acc = 0.92
[Train] Batch ID = 25210, loss = 0.00700817, acc = 1.0
[Validation] Batch ID = 25210, loss = 0.0185768, acc = 1.0
[Train] Batch ID = 25220, loss = 0.00763123, acc = 1.0
[Validation] Batch ID = 25220, loss = 0.0338626, acc = 0.96
[Train] Batch ID = 25230, loss = 0.0051291, acc = 1.0
[Validation] Batch ID = 25230, loss = 0.0368175, acc = 0.96
[Train] Batch ID = 25240, loss = 0.00337264, acc = 1.0
[Validation] Batch ID = 25240, loss = 0.0319448, acc = 0.98
[Train] Batch ID = 25250, loss = 0.00593421, acc = 1.0
[Validation] Batch ID = 25250, loss = 0.0259666, acc = 1.0
[Train] Batch ID = 25260, loss = 0.162756, acc = 0.86
[Validation] Batch ID = 25260, loss = 0.0151578, acc = 1.0
[Train] Batch ID = 25270, loss = 0.0049257, acc = 1.0
[Validation] Batch ID = 25270, loss = 0.0197664, acc = 1.0
[Train] Batch ID = 25280, loss = 0.00463759, acc = 1.0
[Validation] Batch ID = 25280, loss = 0.021977, acc = 0.98
[Train] Batch ID = 25290, loss = 0.00465225, acc = 1.0
[Validation] Batch ID = 25290, loss = 0.0479826, acc = 0.98
[Train] Batch ID = 25300, loss = 0.00332115, acc = 1.0
[Validation] Batch ID = 25300, loss = 0.0698038, acc = 0.94
[Train] Batch ID = 25310, loss = 0.0049848, acc = 1.0
[Validation] Batch ID = 25310, loss = 0.0351909, acc = 1.0
[Train] Batch ID = 25320, loss = 0.00539496, acc = 1.0
[Validation] Batch ID = 25320, loss = 0.0426134, acc = 0.96
[Train] Batch ID = 25330, loss = 0.173396, acc = 0.8
[Validation] Batch ID = 25330, loss = 0.0190018, acc = 1.0
[Train] Batch ID = 25340, loss = 0.0039035, acc = 1.0
[Validation] Batch ID = 25340, loss = 0.0289742, acc = 0.96
[Train] Batch ID = 25350, loss = 0.00565386, acc = 1.0
[Validation] Batch ID = 25350, loss = 0.0464901, acc = 0.94
[Train] Batch ID = 25360, loss = 0.00457536, acc = 1.0
[Validation] Batch ID = 25360, loss = 0.0356388, acc = 0.96
[Train] Batch ID = 25370, loss = 0.00369901, acc = 1.0
[Validation] Batch ID = 25370, loss = 0.0343777, acc = 1.0
[Train] Batch ID = 25380, loss = 0.180355, acc = 0.88
[Validation] Batch ID = 25380, loss = 0.0190102, acc = 1.0
[Train] Batch ID = 25390, loss = 0.00403948, acc = 1.0
[Validation] Batch ID = 25390, loss = 0.028232, acc = 0.98
[Train] Batch ID = 25400, loss = 0.193305, acc = 0.88
[Validation] Batch ID = 25400, loss = 0.035811, acc = 0.98
[Train] Batch ID = 25410, loss = 0.00609214, acc = 1.0
[Validation] Batch ID = 25410, loss = 0.0647143, acc = 0.92
[Train] Batch ID = 25420, loss = 0.00308192, acc = 1.0
[Validation] Batch ID = 25420, loss = 0.0310692, acc = 0.98
[Train] Batch ID = 25430, loss = 0.19626, acc = 0.8
[Validation] Batch ID = 25430, loss = 0.0129089, acc = 1.0
[Train] Batch ID = 25440, loss = 0.00638872, acc = 1.0
[Validation] Batch ID = 25440, loss = 0.0121976, acc = 1.0
[Train] Batch ID = 25450, loss = 0.00268359, acc = 1.0
[Validation] Batch ID = 25450, loss = 0.0378624, acc = 0.96
[Train] Batch ID = 25460, loss = 0.00537644, acc = 1.0
[Validation] Batch ID = 25460, loss = 0.030431, acc = 0.98
[Train] Batch ID = 25470, loss = 0.00548412, acc = 1.0
[Validation] Batch ID = 25470, loss = 0.0218575, acc = 0.98
[Train] Batch ID = 25480, loss = 0.00518644, acc = 1.0
[Validation] Batch ID = 25480, loss = 0.0207428, acc = 0.98
[Train] Batch ID = 25490, loss = 0.00867511, acc = 1.0
[Validation] Batch ID = 25490, loss = 0.0461688, acc = 0.96
[Train] Batch ID = 25500, loss = 0.00511404, acc = 1.0
[Validation] Batch ID = 25500, loss = 0.0377125, acc = 0.94
[Train] Batch ID = 25510, loss = 0.00521858, acc = 1.0
[Validation] Batch ID = 25510, loss = 0.0253516, acc = 1.0
[Train] Batch ID = 25520, loss = 0.00641138, acc = 1.0
[Validation] Batch ID = 25520, loss = 0.0476274, acc = 0.98
[Train] Batch ID = 25530, loss = 0.00449936, acc = 1.0
[Validation] Batch ID = 25530, loss = 0.0245405, acc = 0.98
[Train] Batch ID = 25540, loss = 0.00409921, acc = 1.0
[Validation] Batch ID = 25540, loss = 0.0515231, acc = 0.96
[Train] Batch ID = 25550, loss = 0.00419816, acc = 1.0
[Validation] Batch ID = 25550, loss = 0.0396991, acc = 0.94
[Train] Batch ID = 25560, loss = 0.00483512, acc = 1.0
[Validation] Batch ID = 25560, loss = 0.0252135, acc = 0.98
[Train] Batch ID = 25570, loss = 0.00738272, acc = 1.0
[Validation] Batch ID = 25570, loss = 0.0450878, acc = 0.98
[Train] Batch ID = 25580, loss = 0.00627595, acc = 1.0
[Validation] Batch ID = 25580, loss = 0.0144401, acc = 1.0
[Train] Batch ID = 25590, loss = 0.00204619, acc = 1.0
[Validation] Batch ID = 25590, loss = 0.0351245, acc = 0.96
[Train] Batch ID = 25600, loss = 0.153193, acc = 0.94
[Validation] Batch ID = 25600, loss = 0.0326385, acc = 1.0
[Train] Batch ID = 25610, loss = 0.00663038, acc = 1.0
[Validation] Batch ID = 25610, loss = 0.0232786, acc = 1.0
[Train] Batch ID = 25620, loss = 0.00416398, acc = 1.0
[Validation] Batch ID = 25620, loss = 0.0339643, acc = 0.96
[Train] Batch ID = 25630, loss = 0.00577202, acc = 1.0
[Validation] Batch ID = 25630, loss = 0.0429454, acc = 0.96
[Train] Batch ID = 25640, loss = 0.00381897, acc = 1.0
[Validation] Batch ID = 25640, loss = 0.0234658, acc = 0.98
[Train] Batch ID = 25650, loss = 0.00503051, acc = 1.0
[Validation] Batch ID = 25650, loss = 0.0512088, acc = 0.96
[Train] Batch ID = 25660, loss = 0.00575399, acc = 1.0
[Validation] Batch ID = 25660, loss = 0.0181857, acc = 0.98
[Train] Batch ID = 25670, loss = 0.00437739, acc = 1.0
[Validation] Batch ID = 25670, loss = 0.0374583, acc = 0.96
[Train] Batch ID = 25680, loss = 0.00392275, acc = 1.0
[Validation] Batch ID = 25680, loss = 0.0643692, acc = 0.9
[Train] Batch ID = 25690, loss = 0.00262643, acc = 1.0
[Validation] Batch ID = 25690, loss = 0.0221178, acc = 0.98
[Train] Batch ID = 25700, loss = 0.0066677, acc = 1.0
[Validation] Batch ID = 25700, loss = 0.0535426, acc = 0.92
[Train] Batch ID = 25710, loss = 0.0064405, acc = 1.0
[Validation] Batch ID = 25710, loss = 0.0438907, acc = 0.96
[Train] Batch ID = 25720, loss = 0.00399391, acc = 1.0
[Validation] Batch ID = 25720, loss = 0.00851319, acc = 1.0
[Train] Batch ID = 25730, loss = 0.00533695, acc = 1.0
[Validation] Batch ID = 25730, loss = 0.0134686, acc = 1.0
[Train] Batch ID = 25740, loss = 0.00425786, acc = 1.0
[Validation] Batch ID = 25740, loss = 0.0144386, acc = 1.0
[Train] Batch ID = 25750, loss = 0.00332391, acc = 1.0
[Validation] Batch ID = 25750, loss = 0.0175227, acc = 1.0
[Train] Batch ID = 25760, loss = 0.00227195, acc = 1.0
[Validation] Batch ID = 25760, loss = 0.0430957, acc = 0.96
[Train] Batch ID = 25770, loss = 0.00387504, acc = 1.0
[Validation] Batch ID = 25770, loss = 0.0271849, acc = 0.98
[Train] Batch ID = 25780, loss = 0.00297543, acc = 1.0
[Validation] Batch ID = 25780, loss = 0.0315987, acc = 0.98
[Train] Batch ID = 25790, loss = 0.00331605, acc = 1.0
[Validation] Batch ID = 25790, loss = 0.0251438, acc = 1.0
[Train] Batch ID = 25800, loss = 0.00301288, acc = 1.0
[Validation] Batch ID = 25800, loss = 0.0361691, acc = 0.96
[Train] Batch ID = 25810, loss = 0.00305112, acc = 1.0
[Validation] Batch ID = 25810, loss = 0.0370814, acc = 0.98
[Train] Batch ID = 25820, loss = 0.00353276, acc = 1.0
[Validation] Batch ID = 25820, loss = 0.0361633, acc = 1.0
[Train] Batch ID = 25830, loss = 0.00934081, acc = 1.0
[Validation] Batch ID = 25830, loss = 0.0271243, acc = 0.98
[Train] Batch ID = 25840, loss = 0.00581993, acc = 1.0
[Validation] Batch ID = 25840, loss = 0.0441077, acc = 0.96
[Train] Batch ID = 25850, loss = 0.00750682, acc = 1.0
[Validation] Batch ID = 25850, loss = 0.0347248, acc = 0.98
[Train] Batch ID = 25860, loss = 0.00838789, acc = 1.0
[Validation] Batch ID = 25860, loss = 0.0270179, acc = 1.0
[Train] Batch ID = 25870, loss = 0.006683, acc = 1.0
[Validation] Batch ID = 25870, loss = 0.0347112, acc = 0.98
[Train] Batch ID = 25880, loss = 0.00275969, acc = 1.0
[Validation] Batch ID = 25880, loss = 0.0367162, acc = 0.96
[Train] Batch ID = 25890, loss = 0.00343216, acc = 1.0
[Validation] Batch ID = 25890, loss = 0.0538582, acc = 0.92
[Train] Batch ID = 25900, loss = 0.00772962, acc = 1.0
[Validation] Batch ID = 25900, loss = 0.0259975, acc = 0.98
[Train] Batch ID = 25910, loss = 0.00433735, acc = 1.0
[Validation] Batch ID = 25910, loss = 0.0115889, acc = 1.0
[Train] Batch ID = 25920, loss = 0.00337505, acc = 1.0
[Validation] Batch ID = 25920, loss = 0.0115876, acc = 1.0
[Train] Batch ID = 25930, loss = 0.00403224, acc = 1.0
[Validation] Batch ID = 25930, loss = 0.0147867, acc = 1.0
[Train] Batch ID = 25940, loss = 0.185585, acc = 0.82
[Validation] Batch ID = 25940, loss = 0.0270805, acc = 0.98
[Train] Batch ID = 25950, loss = 0.00718152, acc = 1.0
[Validation] Batch ID = 25950, loss = 0.0189938, acc = 1.0
[Train] Batch ID = 25960, loss = 0.00611538, acc = 1.0
[Validation] Batch ID = 25960, loss = 0.0266209, acc = 0.98
[Train] Batch ID = 25970, loss = 0.0044575, acc = 1.0
[Validation] Batch ID = 25970, loss = 0.0418553, acc = 0.94
[Train] Batch ID = 25980, loss = 0.00801087, acc = 1.0
[Validation] Batch ID = 25980, loss = 0.0621258, acc = 0.96
[Train] Batch ID = 25990, loss = 0.197612, acc = 0.82
[Validation] Batch ID = 25990, loss = 0.0345656, acc = 0.96
[Train] Batch ID = 26000, loss = 0.00912309, acc = 1.0
[Validation] Batch ID = 26000, loss = 0.0419714, acc = 0.96
Evaluate full validation dataset ...
Current loss: 0.0366307 Best loss: 0.0344537
[TOTAL Validation] Batch ID = 26000, loss = 0.0366307, acc = 0.97664399093
Augmented Factor = 0.057568239633009693
[Train] Batch ID = 26010, loss = 0.00578859, acc = 1.0
[Validation] Batch ID = 26010, loss = 0.0370199, acc = 0.94
[Train] Batch ID = 26020, loss = 0.00342464, acc = 1.0
[Validation] Batch ID = 26020, loss = 0.0341786, acc = 0.96
[Train] Batch ID = 26030, loss = 0.00453978, acc = 1.0
[Validation] Batch ID = 26030, loss = 0.0197331, acc = 1.0
[Train] Batch ID = 26040, loss = 0.00256224, acc = 1.0
[Validation] Batch ID = 26040, loss = 0.0196859, acc = 1.0
[Train] Batch ID = 26050, loss = 0.00340631, acc = 1.0
[Validation] Batch ID = 26050, loss = 0.0452105, acc = 0.94
[Train] Batch ID = 26060, loss = 0.00225872, acc = 1.0
[Validation] Batch ID = 26060, loss = 0.0155485, acc = 1.0
[Train] Batch ID = 26070, loss = 0.00560962, acc = 1.0
[Validation] Batch ID = 26070, loss = 0.0266955, acc = 1.0
[Train] Batch ID = 26080, loss = 0.00393269, acc = 1.0
[Validation] Batch ID = 26080, loss = 0.0303223, acc = 1.0
[Train] Batch ID = 26090, loss = 0.0048605, acc = 1.0
[Validation] Batch ID = 26090, loss = 0.0414392, acc = 0.98
[Train] Batch ID = 26100, loss = 0.00979519, acc = 1.0
[Validation] Batch ID = 26100, loss = 0.0479835, acc = 0.94
[Train] Batch ID = 26110, loss = 0.00481187, acc = 1.0
[Validation] Batch ID = 26110, loss = 0.027029, acc = 0.96
[Train] Batch ID = 26120, loss = 0.00537806, acc = 1.0
[Validation] Batch ID = 26120, loss = 0.0250419, acc = 0.98
[Train] Batch ID = 26130, loss = 0.00388486, acc = 1.0
[Validation] Batch ID = 26130, loss = 0.0148263, acc = 0.98
[Train] Batch ID = 26140, loss = 0.0059843, acc = 1.0
[Validation] Batch ID = 26140, loss = 0.034666, acc = 0.98
[Train] Batch ID = 26150, loss = 0.0045862, acc = 1.0
[Validation] Batch ID = 26150, loss = 0.0215482, acc = 1.0
[Train] Batch ID = 26160, loss = 0.00302086, acc = 1.0
[Validation] Batch ID = 26160, loss = 0.0185783, acc = 0.98
[Train] Batch ID = 26170, loss = 0.00269747, acc = 1.0
[Validation] Batch ID = 26170, loss = 0.0086549, acc = 1.0
[Train] Batch ID = 26180, loss = 0.00266846, acc = 1.0
[Validation] Batch ID = 26180, loss = 0.0519928, acc = 0.94
[Train] Batch ID = 26190, loss = 0.00209302, acc = 1.0
[Validation] Batch ID = 26190, loss = 0.0202654, acc = 0.98
[Train] Batch ID = 26200, loss = 0.00907939, acc = 1.0
[Validation] Batch ID = 26200, loss = 0.0224886, acc = 0.98
[Train] Batch ID = 26210, loss = 0.0026054, acc = 1.0
[Validation] Batch ID = 26210, loss = 0.0332879, acc = 0.98
[Train] Batch ID = 26220, loss = 0.00269661, acc = 1.0
[Validation] Batch ID = 26220, loss = 0.0238039, acc = 0.98
[Train] Batch ID = 26230, loss = 0.0035253, acc = 1.0
[Validation] Batch ID = 26230, loss = 0.034603, acc = 0.98
[Train] Batch ID = 26240, loss = 0.00399141, acc = 1.0
[Validation] Batch ID = 26240, loss = 0.0519859, acc = 0.94
[Train] Batch ID = 26250, loss = 0.00169044, acc = 1.0
[Validation] Batch ID = 26250, loss = 0.0365988, acc = 0.98
[Train] Batch ID = 26260, loss = 0.00282942, acc = 1.0
[Validation] Batch ID = 26260, loss = 0.0296884, acc = 0.98
[Train] Batch ID = 26270, loss = 0.18625, acc = 0.86
[Validation] Batch ID = 26270, loss = 0.0567259, acc = 0.92
[Train] Batch ID = 26280, loss = 0.00668649, acc = 1.0
[Validation] Batch ID = 26280, loss = 0.0542342, acc = 0.94
[Train] Batch ID = 26290, loss = 0.189436, acc = 0.77551
[Validation] Batch ID = 26290, loss = 0.0218903, acc = 1.0
[Train] Batch ID = 26300, loss = 0.00955191, acc = 1.0
[Validation] Batch ID = 26300, loss = 0.0240006, acc = 0.98
[Train] Batch ID = 26310, loss = 0.00536634, acc = 1.0
[Validation] Batch ID = 26310, loss = 0.0181581, acc = 0.98
[Train] Batch ID = 26320, loss = 0.0076938, acc = 1.0
[Validation] Batch ID = 26320, loss = 0.0237479, acc = 0.98
[Train] Batch ID = 26330, loss = 0.00301295, acc = 1.0
[Validation] Batch ID = 26330, loss = 0.0271867, acc = 1.0
[Train] Batch ID = 26340, loss = 0.00397235, acc = 1.0
[Validation] Batch ID = 26340, loss = 0.0459381, acc = 0.94
[Train] Batch ID = 26350, loss = 0.00645607, acc = 1.0
[Validation] Batch ID = 26350, loss = 0.028852, acc = 1.0
[Train] Batch ID = 26360, loss = 0.00282513, acc = 1.0
[Validation] Batch ID = 26360, loss = 0.0278333, acc = 0.98
[Train] Batch ID = 26370, loss = 0.00559427, acc = 1.0
[Validation] Batch ID = 26370, loss = 0.0239033, acc = 1.0
[Train] Batch ID = 26380, loss = 0.00523777, acc = 1.0
[Validation] Batch ID = 26380, loss = 0.0280567, acc = 0.98
[Train] Batch ID = 26390, loss = 0.0033703, acc = 1.0
[Validation] Batch ID = 26390, loss = 0.0260484, acc = 0.98
[Train] Batch ID = 26400, loss = 0.00215853, acc = 1.0
[Validation] Batch ID = 26400, loss = 0.00590714, acc = 1.0
[Train] Batch ID = 26410, loss = 0.00703167, acc = 1.0
[Validation] Batch ID = 26410, loss = 0.0243345, acc = 1.0
[Train] Batch ID = 26420, loss = 0.00475593, acc = 1.0
[Validation] Batch ID = 26420, loss = 0.0320021, acc = 0.98
[Train] Batch ID = 26430, loss = 0.00396824, acc = 1.0
[Validation] Batch ID = 26430, loss = 0.0541277, acc = 0.94
[Train] Batch ID = 26440, loss = 0.00328267, acc = 1.0
[Validation] Batch ID = 26440, loss = 0.0369022, acc = 0.96
[Train] Batch ID = 26450, loss = 0.00263134, acc = 1.0
[Validation] Batch ID = 26450, loss = 0.0278014, acc = 0.98
[Train] Batch ID = 26460, loss = 0.00421793, acc = 1.0
[Validation] Batch ID = 26460, loss = 0.0217491, acc = 0.98
[Train] Batch ID = 26470, loss = 0.200859, acc = 0.84
[Validation] Batch ID = 26470, loss = 0.0306074, acc = 0.98
[Train] Batch ID = 26480, loss = 0.00522908, acc = 1.0
[Validation] Batch ID = 26480, loss = 0.0188927, acc = 1.0
[Train] Batch ID = 26490, loss = 0.00466273, acc = 1.0
[Validation] Batch ID = 26490, loss = 0.0113572, acc = 1.0
[Train] Batch ID = 26500, loss = 0.00286973, acc = 1.0
[Validation] Batch ID = 26500, loss = 0.0316676, acc = 1.0
[Train] Batch ID = 26510, loss = 0.00175133, acc = 1.0
[Validation] Batch ID = 26510, loss = 0.0251474, acc = 0.98
[Train] Batch ID = 26520, loss = 0.00279293, acc = 1.0
[Validation] Batch ID = 26520, loss = 0.0336185, acc = 0.98
[Train] Batch ID = 26530, loss = 0.00484142, acc = 1.0
[Validation] Batch ID = 26530, loss = 0.0672743, acc = 0.92
[Train] Batch ID = 26540, loss = 0.00493622, acc = 1.0
[Validation] Batch ID = 26540, loss = 0.0370524, acc = 0.96
[Train] Batch ID = 26550, loss = 0.168307, acc = 0.86
[Validation] Batch ID = 26550, loss = 0.0385802, acc = 0.96
[Train] Batch ID = 26560, loss = 0.00593387, acc = 1.0
[Validation] Batch ID = 26560, loss = 0.0115282, acc = 1.0
[Train] Batch ID = 26570, loss = 0.00370316, acc = 1.0
[Validation] Batch ID = 26570, loss = 0.0406835, acc = 0.96
[Train] Batch ID = 26580, loss = 0.00291659, acc = 1.0
[Validation] Batch ID = 26580, loss = 0.0204569, acc = 0.98
[Train] Batch ID = 26590, loss = 0.00291656, acc = 1.0
[Validation] Batch ID = 26590, loss = 0.0260496, acc = 1.0
[Train] Batch ID = 26600, loss = 0.00436872, acc = 1.0
[Validation] Batch ID = 26600, loss = 0.0369429, acc = 0.96
[Train] Batch ID = 26610, loss = 0.00292887, acc = 1.0
[Validation] Batch ID = 26610, loss = 0.052785, acc = 0.9
[Train] Batch ID = 26620, loss = 0.182779, acc = 0.84
[Validation] Batch ID = 26620, loss = 0.0529491, acc = 0.96
[Train] Batch ID = 26630, loss = 0.00462629, acc = 1.0
[Validation] Batch ID = 26630, loss = 0.0496139, acc = 0.94
[Train] Batch ID = 26640, loss = 0.00323106, acc = 1.0
[Validation] Batch ID = 26640, loss = 0.0357215, acc = 1.0
[Train] Batch ID = 26650, loss = 0.00396145, acc = 1.0
[Validation] Batch ID = 26650, loss = 0.0460461, acc = 0.96
[Train] Batch ID = 26660, loss = 0.00480894, acc = 1.0
[Validation] Batch ID = 26660, loss = 0.0358499, acc = 0.98
[Train] Batch ID = 26670, loss = 0.00657377, acc = 1.0
[Validation] Batch ID = 26670, loss = 0.0281682, acc = 0.98
[Train] Batch ID = 26680, loss = 0.00332897, acc = 1.0
[Validation] Batch ID = 26680, loss = 0.0234043, acc = 0.96
[Train] Batch ID = 26690, loss = 0.00337948, acc = 1.0
[Validation] Batch ID = 26690, loss = 0.0234602, acc = 0.96
[Train] Batch ID = 26700, loss = 0.00346916, acc = 1.0
[Validation] Batch ID = 26700, loss = 0.023408, acc = 1.0
[Train] Batch ID = 26710, loss = 0.00478993, acc = 1.0
[Validation] Batch ID = 26710, loss = 0.0358729, acc = 0.96
[Train] Batch ID = 26720, loss = 0.00496879, acc = 1.0
[Validation] Batch ID = 26720, loss = 0.0274833, acc = 0.98
[Train] Batch ID = 26730, loss = 0.00416248, acc = 1.0
[Validation] Batch ID = 26730, loss = 0.0214859, acc = 0.98
[Train] Batch ID = 26740, loss = 0.00582328, acc = 1.0
[Validation] Batch ID = 26740, loss = 0.060164, acc = 0.92
[Train] Batch ID = 26750, loss = 0.00265176, acc = 1.0
[Validation] Batch ID = 26750, loss = 0.0254673, acc = 0.98
[Train] Batch ID = 26760, loss = 0.174635, acc = 0.94
[Validation] Batch ID = 26760, loss = 0.0408336, acc = 0.96
[Train] Batch ID = 26770, loss = 0.00392071, acc = 1.0
[Validation] Batch ID = 26770, loss = 0.0337866, acc = 0.96
[Train] Batch ID = 26780, loss = 0.00369409, acc = 1.0
[Validation] Batch ID = 26780, loss = 0.0106499, acc = 1.0
[Train] Batch ID = 26790, loss = 0.00324345, acc = 1.0
[Validation] Batch ID = 26790, loss = 0.0303946, acc = 0.96
[Train] Batch ID = 26800, loss = 0.00568823, acc = 1.0
[Validation] Batch ID = 26800, loss = 0.0131908, acc = 1.0
[Train] Batch ID = 26810, loss = 0.00564457, acc = 1.0
[Validation] Batch ID = 26810, loss = 0.0651951, acc = 0.94
[Train] Batch ID = 26820, loss = 0.00590674, acc = 1.0
[Validation] Batch ID = 26820, loss = 0.0508425, acc = 0.94
[Train] Batch ID = 26830, loss = 0.00483907, acc = 1.0
[Validation] Batch ID = 26830, loss = 0.0384995, acc = 0.96
[Train] Batch ID = 26840, loss = 0.00542458, acc = 1.0
[Validation] Batch ID = 26840, loss = 0.0316136, acc = 0.98
[Train] Batch ID = 26850, loss = 0.00505711, acc = 1.0
[Validation] Batch ID = 26850, loss = 0.0617723, acc = 0.94
[Train] Batch ID = 26860, loss = 0.00412953, acc = 1.0
[Validation] Batch ID = 26860, loss = 0.0155764, acc = 1.0
[Train] Batch ID = 26870, loss = 0.00201616, acc = 1.0
[Validation] Batch ID = 26870, loss = 0.0493092, acc = 0.94
[Train] Batch ID = 26880, loss = 0.23393, acc = 0.78
[Validation] Batch ID = 26880, loss = 0.05607, acc = 0.96
[Train] Batch ID = 26890, loss = 0.00445797, acc = 1.0
[Validation] Batch ID = 26890, loss = 0.0248622, acc = 0.98
[Train] Batch ID = 26900, loss = 0.00403341, acc = 1.0
[Validation] Batch ID = 26900, loss = 0.0247395, acc = 0.98
[Train] Batch ID = 26910, loss = 0.00226296, acc = 1.0
[Validation] Batch ID = 26910, loss = 0.00926258, acc = 1.0
[Train] Batch ID = 26920, loss = 0.00215366, acc = 1.0
[Validation] Batch ID = 26920, loss = 0.0303627, acc = 0.98
[Train] Batch ID = 26930, loss = 0.00133493, acc = 1.0
[Validation] Batch ID = 26930, loss = 0.014699, acc = 1.0
[Train] Batch ID = 26940, loss = 0.00125113, acc = 1.0
[Validation] Batch ID = 26940, loss = 0.0439244, acc = 0.98
[Train] Batch ID = 26950, loss = 0.00288408, acc = 1.0
[Validation] Batch ID = 26950, loss = 0.0448899, acc = 0.94
[Train] Batch ID = 26960, loss = 0.00600772, acc = 1.0
[Validation] Batch ID = 26960, loss = 0.0274735, acc = 0.98
[Train] Batch ID = 26970, loss = 0.00206654, acc = 1.0
[Validation] Batch ID = 26970, loss = 0.0220249, acc = 1.0
[Train] Batch ID = 26980, loss = 0.00154794, acc = 1.0
[Validation] Batch ID = 26980, loss = 0.0188516, acc = 1.0
[Train] Batch ID = 26990, loss = 0.00463967, acc = 1.0
[Validation] Batch ID = 26990, loss = 0.0280851, acc = 0.98
[Train] Batch ID = 27000, loss = 0.00306024, acc = 1.0
[Validation] Batch ID = 27000, loss = 0.0241877, acc = 0.98
Evaluate full validation dataset ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Saving model ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Current loss: 0.0288538 Best loss: 0.0344537
[TOTAL Validation] Batch ID = 27000, loss = 0.0288538, acc = 0.975283446712
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Model successfully saved here: outputs/checkpoints/c1s_9_c1n_256_c2s_6_c2n_64_c2d_0.7_c1vl_16_c1s_5_c1nf_16_c2vl_32_lr_0.0001_rs_1--TrafficSign--1510487290.423481
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Augmented Factor = 0.051811415669708726
[Train] Batch ID = 27010, loss = 0.00511028, acc = 1.0
[Validation] Batch ID = 27010, loss = 0.0165535, acc = 1.0
[Train] Batch ID = 27020, loss = 0.00426955, acc = 1.0
[Validation] Batch ID = 27020, loss = 0.0351558, acc = 0.98
[Train] Batch ID = 27030, loss = 0.00411893, acc = 1.0
[Validation] Batch ID = 27030, loss = 0.0209745, acc = 0.98
[Train] Batch ID = 27040, loss = 0.00332543, acc = 1.0
[Validation] Batch ID = 27040, loss = 0.0352275, acc = 0.96
[Train] Batch ID = 27050, loss = 0.00368007, acc = 1.0
[Validation] Batch ID = 27050, loss = 0.0459675, acc = 0.96
[Train] Batch ID = 27060, loss = 0.00379479, acc = 1.0
[Validation] Batch ID = 27060, loss = 0.025172, acc = 0.98
[Train] Batch ID = 27070, loss = 0.0038915, acc = 1.0
[Validation] Batch ID = 27070, loss = 0.0343857, acc = 0.96
[Train] Batch ID = 27080, loss = 0.00317512, acc = 1.0
[Validation] Batch ID = 27080, loss = 0.0245631, acc = 1.0
[Train] Batch ID = 27090, loss = 0.00547263, acc = 1.0
[Validation] Batch ID = 27090, loss = 0.054059, acc = 0.92
[Train] Batch ID = 27100, loss = 0.00289482, acc = 1.0
[Validation] Batch ID = 27100, loss = 0.0119446, acc = 1.0
[Train] Batch ID = 27110, loss = 0.00858852, acc = 1.0
[Validation] Batch ID = 27110, loss = 0.0456612, acc = 0.96
[Train] Batch ID = 27120, loss = 0.00525914, acc = 1.0
[Validation] Batch ID = 27120, loss = 0.0401797, acc = 0.96
[Train] Batch ID = 27130, loss = 0.00853301, acc = 1.0
[Validation] Batch ID = 27130, loss = 0.031492, acc = 0.96
[Train] Batch ID = 27140, loss = 0.00509303, acc = 1.0
[Validation] Batch ID = 27140, loss = 0.0521615, acc = 0.96
[Train] Batch ID = 27150, loss = 0.00506715, acc = 1.0
[Validation] Batch ID = 27150, loss = 0.0284795, acc = 0.96
[Train] Batch ID = 27160, loss = 0.00174473, acc = 1.0
[Validation] Batch ID = 27160, loss = 0.0249244, acc = 0.98
[Train] Batch ID = 27170, loss = 0.00213509, acc = 1.0
[Validation] Batch ID = 27170, loss = 0.0141826, acc = 1.0
[Train] Batch ID = 27180, loss = 0.00329272, acc = 1.0
[Validation] Batch ID = 27180, loss = 0.0212482, acc = 0.98
[Train] Batch ID = 27190, loss = 0.00468888, acc = 1.0
[Validation] Batch ID = 27190, loss = 0.0308753, acc = 1.0
[Train] Batch ID = 27200, loss = 0.00497168, acc = 1.0
[Validation] Batch ID = 27200, loss = 0.0155546, acc = 1.0
[Train] Batch ID = 27210, loss = 0.0040175, acc = 1.0
[Validation] Batch ID = 27210, loss = 0.0166102, acc = 1.0
[Train] Batch ID = 27220, loss = 0.00439152, acc = 1.0
[Validation] Batch ID = 27220, loss = 0.0392602, acc = 0.96
[Train] Batch ID = 27230, loss = 0.162589, acc = 0.84
[Validation] Batch ID = 27230, loss = 0.0393884, acc = 0.98
[Train] Batch ID = 27240, loss = 0.00438648, acc = 1.0
[Validation] Batch ID = 27240, loss = 0.0274206, acc = 1.0
[Train] Batch ID = 27250, loss = 0.00161945, acc = 1.0
[Validation] Batch ID = 27250, loss = 0.0400404, acc = 0.98
[Train] Batch ID = 27260, loss = 0.00240711, acc = 1.0
[Validation] Batch ID = 27260, loss = 0.0264643, acc = 1.0
[Train] Batch ID = 27270, loss = 0.00205574, acc = 1.0
[Validation] Batch ID = 27270, loss = 0.0308662, acc = 0.96
[Train] Batch ID = 27280, loss = 0.00210773, acc = 1.0
[Validation] Batch ID = 27280, loss = 0.0250496, acc = 1.0
[Train] Batch ID = 27290, loss = 0.00264712, acc = 1.0
[Validation] Batch ID = 27290, loss = 0.0227238, acc = 1.0
[Train] Batch ID = 27300, loss = 0.00321466, acc = 1.0
[Validation] Batch ID = 27300, loss = 0.0184655, acc = 1.0
[Train] Batch ID = 27310, loss = 0.00538398, acc = 1.0
[Validation] Batch ID = 27310, loss = 0.0323665, acc = 0.98
[Train] Batch ID = 27320, loss = 0.00256569, acc = 1.0
[Validation] Batch ID = 27320, loss = 0.0418785, acc = 0.96
[Train] Batch ID = 27330, loss = 0.00428335, acc = 1.0
[Validation] Batch ID = 27330, loss = 0.018436, acc = 1.0
[Train] Batch ID = 27340, loss = 0.0043995, acc = 1.0
[Validation] Batch ID = 27340, loss = 0.0174451, acc = 1.0
[Train] Batch ID = 27350, loss = 0.00282584, acc = 1.0
[Validation] Batch ID = 27350, loss = 0.0342281, acc = 0.96
[Train] Batch ID = 27360, loss = 0.00249544, acc = 1.0
[Validation] Batch ID = 27360, loss = 0.0408371, acc = 0.96
[Train] Batch ID = 27370, loss = 0.00713182, acc = 1.0
[Validation] Batch ID = 27370, loss = 0.0283601, acc = 0.98
[Train] Batch ID = 27380, loss = 0.00484642, acc = 1.0
[Validation] Batch ID = 27380, loss = 0.0623501, acc = 0.96
[Train] Batch ID = 27390, loss = 0.00440441, acc = 1.0
[Validation] Batch ID = 27390, loss = 0.0734918, acc = 0.94
[Train] Batch ID = 27400, loss = 0.0040726, acc = 1.0
[Validation] Batch ID = 27400, loss = 0.0245252, acc = 1.0
[Train] Batch ID = 27410, loss = 0.00184892, acc = 1.0
[Validation] Batch ID = 27410, loss = 0.0475885, acc = 0.94
[Train] Batch ID = 27420, loss = 0.00294766, acc = 1.0
[Validation] Batch ID = 27420, loss = 0.0276553, acc = 1.0
[Train] Batch ID = 27430, loss = 0.00348575, acc = 1.0
[Validation] Batch ID = 27430, loss = 0.0535204, acc = 0.96
[Train] Batch ID = 27440, loss = 0.00377619, acc = 1.0
[Validation] Batch ID = 27440, loss = 0.0260394, acc = 0.98
[Train] Batch ID = 27450, loss = 0.00398294, acc = 1.0
[Validation] Batch ID = 27450, loss = 0.0253127, acc = 1.0
[Train] Batch ID = 27460, loss = 0.00179457, acc = 1.0
[Validation] Batch ID = 27460, loss = 0.0368867, acc = 0.98
[Train] Batch ID = 27470, loss = 0.00485747, acc = 1.0
[Validation] Batch ID = 27470, loss = 0.0436458, acc = 0.96
[Train] Batch ID = 27480, loss = 0.00582817, acc = 1.0
[Validation] Batch ID = 27480, loss = 0.0342999, acc = 0.98
[Train] Batch ID = 27490, loss = 0.00277406, acc = 1.0
[Validation] Batch ID = 27490, loss = 0.0544706, acc = 0.94
[Train] Batch ID = 27500, loss = 0.00381071, acc = 1.0
[Validation] Batch ID = 27500, loss = 0.00362776, acc = 1.0
[Train] Batch ID = 27510, loss = 0.00379636, acc = 1.0
[Validation] Batch ID = 27510, loss = 0.0264396, acc = 1.0
[Train] Batch ID = 27520, loss = 0.0028638, acc = 1.0
[Validation] Batch ID = 27520, loss = 0.0228713, acc = 1.0
[Train] Batch ID = 27530, loss = 0.00693576, acc = 1.0
[Validation] Batch ID = 27530, loss = 0.0201265, acc = 1.0
[Train] Batch ID = 27540, loss = 0.00420036, acc = 1.0
[Validation] Batch ID = 27540, loss = 0.0309738, acc = 0.98
[Train] Batch ID = 27550, loss = 0.00283662, acc = 1.0
[Validation] Batch ID = 27550, loss = 0.0179669, acc = 1.0
[Train] Batch ID = 27560, loss = 0.00240371, acc = 1.0
[Validation] Batch ID = 27560, loss = 0.0258558, acc = 0.98
[Train] Batch ID = 27570, loss = 0.00252555, acc = 1.0
[Validation] Batch ID = 27570, loss = 0.0318374, acc = 0.98
[Train] Batch ID = 27580, loss = 0.00141832, acc = 1.0
[Validation] Batch ID = 27580, loss = 0.0205535, acc = 0.98
[Train] Batch ID = 27590, loss = 0.00298626, acc = 1.0
[Validation] Batch ID = 27590, loss = 0.0381441, acc = 0.96
[Train] Batch ID = 27600, loss = 0.0025265, acc = 1.0
[Validation] Batch ID = 27600, loss = 0.0240987, acc = 0.98
[Train] Batch ID = 27610, loss = 0.00269176, acc = 1.0
[Validation] Batch ID = 27610, loss = 0.0294533, acc = 0.98
[Train] Batch ID = 27620, loss = 0.00349637, acc = 1.0
[Validation] Batch ID = 27620, loss = 0.0456181, acc = 0.96
[Train] Batch ID = 27630, loss = 0.00553599, acc = 1.0
[Validation] Batch ID = 27630, loss = 0.0502782, acc = 0.96
[Train] Batch ID = 27640, loss = 0.00286797, acc = 1.0
[Validation] Batch ID = 27640, loss = 0.0266564, acc = 0.96
[Train] Batch ID = 27650, loss = 0.00177842, acc = 1.0
[Validation] Batch ID = 27650, loss = 0.0208164, acc = 1.0
[Train] Batch ID = 27660, loss = 0.00337631, acc = 1.0
[Validation] Batch ID = 27660, loss = 0.0487182, acc = 0.96
[Train] Batch ID = 27670, loss = 0.00450622, acc = 1.0
[Validation] Batch ID = 27670, loss = 0.0354008, acc = 0.98
[Train] Batch ID = 27680, loss = 0.00501884, acc = 1.0
[Validation] Batch ID = 27680, loss = 0.0233731, acc = 0.98
[Train] Batch ID = 27690, loss = 0.00395974, acc = 1.0
[Validation] Batch ID = 27690, loss = 0.0156231, acc = 1.0
[Train] Batch ID = 27700, loss = 0.0020192, acc = 1.0
[Validation] Batch ID = 27700, loss = 0.0284574, acc = 0.98
[Train] Batch ID = 27710, loss = 0.00354789, acc = 1.0
[Validation] Batch ID = 27710, loss = 0.0225502, acc = 0.98
[Train] Batch ID = 27720, loss = 0.00342917, acc = 1.0
[Validation] Batch ID = 27720, loss = 0.0314516, acc = 0.96
[Train] Batch ID = 27730, loss = 0.00876324, acc = 1.0
[Validation] Batch ID = 27730, loss = 0.0208891, acc = 1.0
[Train] Batch ID = 27740, loss = 0.00735486, acc = 1.0
[Validation] Batch ID = 27740, loss = 0.0456446, acc = 0.98
[Train] Batch ID = 27750, loss = 0.19702, acc = 0.82
[Validation] Batch ID = 27750, loss = 0.0072705, acc = 1.0
[Train] Batch ID = 27760, loss = 0.00326728, acc = 1.0
[Validation] Batch ID = 27760, loss = 0.0170011, acc = 1.0
[Train] Batch ID = 27770, loss = 0.00552057, acc = 1.0
[Validation] Batch ID = 27770, loss = 0.0403789, acc = 0.96
[Train] Batch ID = 27780, loss = 0.00320928, acc = 1.0
[Validation] Batch ID = 27780, loss = 0.044519, acc = 0.94
[Train] Batch ID = 27790, loss = 0.212572, acc = 0.82
[Validation] Batch ID = 27790, loss = 0.0424083, acc = 0.96
[Train] Batch ID = 27800, loss = 0.00346044, acc = 1.0
[Validation] Batch ID = 27800, loss = 0.0487666, acc = 0.98
[Train] Batch ID = 27810, loss = 0.00328715, acc = 1.0
[Validation] Batch ID = 27810, loss = 0.0415209, acc = 0.96
[Train] Batch ID = 27820, loss = 0.00699302, acc = 1.0
[Validation] Batch ID = 27820, loss = 0.0218442, acc = 0.98
[Train] Batch ID = 27830, loss = 0.00400849, acc = 1.0
[Validation] Batch ID = 27830, loss = 0.0383321, acc = 0.98
[Train] Batch ID = 27840, loss = 0.00345799, acc = 1.0
[Validation] Batch ID = 27840, loss = 0.00681413, acc = 1.0
[Train] Batch ID = 27850, loss = 0.00364605, acc = 1.0
[Validation] Batch ID = 27850, loss = 0.00989431, acc = 1.0
[Train] Batch ID = 27860, loss = 0.177231, acc = 0.82
[Validation] Batch ID = 27860, loss = 0.034446, acc = 0.98
[Train] Batch ID = 27870, loss = 0.00482243, acc = 1.0
[Validation] Batch ID = 27870, loss = 0.0370102, acc = 0.98
[Train] Batch ID = 27880, loss = 0.00301864, acc = 1.0
[Validation] Batch ID = 27880, loss = 0.0245813, acc = 1.0
[Train] Batch ID = 27890, loss = 0.00238273, acc = 1.0
[Validation] Batch ID = 27890, loss = 0.0108975, acc = 1.0
[Train] Batch ID = 27900, loss = 0.0037313, acc = 1.0
[Validation] Batch ID = 27900, loss = 0.0318729, acc = 0.98
[Train] Batch ID = 27910, loss = 0.00220983, acc = 1.0
[Validation] Batch ID = 27910, loss = 0.0317025, acc = 1.0
[Train] Batch ID = 27920, loss = 0.00454798, acc = 1.0
[Validation] Batch ID = 27920, loss = 0.034279, acc = 0.94
[Train] Batch ID = 27930, loss = 0.00456027, acc = 1.0
[Validation] Batch ID = 27930, loss = 0.0375703, acc = 0.96
[Train] Batch ID = 27940, loss = 0.00207326, acc = 1.0
[Validation] Batch ID = 27940, loss = 0.0245635, acc = 0.98
[Train] Batch ID = 27950, loss = 0.00254769, acc = 1.0
[Validation] Batch ID = 27950, loss = 0.0272671, acc = 0.98
[Train] Batch ID = 27960, loss = 0.00293592, acc = 1.0
[Validation] Batch ID = 27960, loss = 0.0281415, acc = 0.96
[Train] Batch ID = 27970, loss = 0.00211629, acc = 1.0
[Validation] Batch ID = 27970, loss = 0.0138597, acc = 1.0
[Train] Batch ID = 27980, loss = 0.00623275, acc = 1.0
[Validation] Batch ID = 27980, loss = 0.0294323, acc = 0.96
[Train] Batch ID = 27990, loss = 0.00163982, acc = 1.0
[Validation] Batch ID = 27990, loss = 0.0236676, acc = 0.98
[Train] Batch ID = 28000, loss = 0.00254689, acc = 1.0
[Validation] Batch ID = 28000, loss = 0.0199397, acc = 1.0
Evaluate full validation dataset ...
Current loss: 0.030012 Best loss: 0.0288538
[TOTAL Validation] Batch ID = 28000, loss = 0.030012, acc = 0.975736961451
Augmented Factor = 0.04663027410273785
[Train] Batch ID = 28010, loss = 0.00187517, acc = 1.0
[Validation] Batch ID = 28010, loss = 0.0148295, acc = 0.98
[Train] Batch ID = 28020, loss = 0.00282962, acc = 1.0
[Validation] Batch ID = 28020, loss = 0.0294613, acc = 0.96
[Train] Batch ID = 28030, loss = 0.00181198, acc = 1.0
[Validation] Batch ID = 28030, loss = 0.0198276, acc = 0.98
[Train] Batch ID = 28040, loss = 0.0029496, acc = 1.0
[Validation] Batch ID = 28040, loss = 0.0201372, acc = 1.0
[Train] Batch ID = 28050, loss = 0.00334896, acc = 1.0
[Validation] Batch ID = 28050, loss = 0.0251114, acc = 0.98
[Train] Batch ID = 28060, loss = 0.00249863, acc = 1.0
[Validation] Batch ID = 28060, loss = 0.0112194, acc = 1.0
[Train] Batch ID = 28070, loss = 0.00246355, acc = 1.0
[Validation] Batch ID = 28070, loss = 0.0610709, acc = 0.94
[Train] Batch ID = 28080, loss = 0.00649246, acc = 1.0
[Validation] Batch ID = 28080, loss = 0.026216, acc = 0.98
[Train] Batch ID = 28090, loss = 0.00303462, acc = 1.0
[Validation] Batch ID = 28090, loss = 0.0378549, acc = 0.98
[Train] Batch ID = 28100, loss = 0.00347731, acc = 1.0
[Validation] Batch ID = 28100, loss = 0.0222453, acc = 0.98
[Train] Batch ID = 28110, loss = 0.00421006, acc = 1.0
[Validation] Batch ID = 28110, loss = 0.0195487, acc = 1.0
[Train] Batch ID = 28120, loss = 0.00320211, acc = 1.0
[Validation] Batch ID = 28120, loss = 0.0396301, acc = 0.96
[Train] Batch ID = 28130, loss = 0.000717742, acc = 1.0
[Validation] Batch ID = 28130, loss = 0.0516516, acc = 0.94
[Train] Batch ID = 28140, loss = 0.00242869, acc = 1.0
[Validation] Batch ID = 28140, loss = 0.0381379, acc = 0.96
[Train] Batch ID = 28150, loss = 0.00196508, acc = 1.0
[Validation] Batch ID = 28150, loss = 0.0192463, acc = 0.98
[Train] Batch ID = 28160, loss = 0.00260866, acc = 1.0
[Validation] Batch ID = 28160, loss = 0.0447866, acc = 0.96
[Train] Batch ID = 28170, loss = 0.00851993, acc = 1.0
[Validation] Batch ID = 28170, loss = 0.0234473, acc = 1.0
[Train] Batch ID = 28180, loss = 0.00495754, acc = 1.0
[Validation] Batch ID = 28180, loss = 0.0296174, acc = 0.98
[Train] Batch ID = 28190, loss = 0.00353983, acc = 1.0
[Validation] Batch ID = 28190, loss = 0.0131416, acc = 1.0
[Train] Batch ID = 28200, loss = 0.00157515, acc = 1.0
[Validation] Batch ID = 28200, loss = 0.0171649, acc = 1.0
[Train] Batch ID = 28210, loss = 0.00253486, acc = 1.0
[Validation] Batch ID = 28210, loss = 0.0307121, acc = 0.98
[Train] Batch ID = 28220, loss = 0.00335755, acc = 1.0
[Validation] Batch ID = 28220, loss = 0.0493128, acc = 0.96
[Train] Batch ID = 28230, loss = 0.00275743, acc = 1.0
[Validation] Batch ID = 28230, loss = 0.0510425, acc = 0.94
[Train] Batch ID = 28240, loss = 0.00629263, acc = 1.0
[Validation] Batch ID = 28240, loss = 0.0141851, acc = 1.0
[Train] Batch ID = 28250, loss = 0.00417819, acc = 1.0
[Validation] Batch ID = 28250, loss = 0.0299346, acc = 0.98
[Train] Batch ID = 28260, loss = 0.00310623, acc = 1.0
[Validation] Batch ID = 28260, loss = 0.0284007, acc = 1.0
[Train] Batch ID = 28270, loss = 0.00471785, acc = 1.0
[Validation] Batch ID = 28270, loss = 0.0341935, acc = 0.98
[Train] Batch ID = 28280, loss = 0.00593985, acc = 1.0
[Validation] Batch ID = 28280, loss = 0.014572, acc = 1.0
[Train] Batch ID = 28290, loss = 0.00565017, acc = 1.0
[Validation] Batch ID = 28290, loss = 0.0380004, acc = 1.0
[Train] Batch ID = 28300, loss = 0.00331818, acc = 1.0
[Validation] Batch ID = 28300, loss = 0.029631, acc = 0.98
[Train] Batch ID = 28310, loss = 0.00217559, acc = 1.0
[Validation] Batch ID = 28310, loss = 0.0203245, acc = 0.98
[Train] Batch ID = 28320, loss = 0.00309005, acc = 1.0
[Validation] Batch ID = 28320, loss = 0.0155592, acc = 1.0
[Train] Batch ID = 28330, loss = 0.0029702, acc = 1.0
[Validation] Batch ID = 28330, loss = 0.0617228, acc = 0.92
[Train] Batch ID = 28340, loss = 0.000899298, acc = 1.0
[Validation] Batch ID = 28340, loss = 0.0127443, acc = 1.0
[Train] Batch ID = 28350, loss = 0.00355056, acc = 1.0
[Validation] Batch ID = 28350, loss = 0.0372019, acc = 0.96
[Train] Batch ID = 28360, loss = 0.00291447, acc = 1.0
[Validation] Batch ID = 28360, loss = 0.0447046, acc = 0.94
[Train] Batch ID = 28370, loss = 0.00308209, acc = 1.0
[Validation] Batch ID = 28370, loss = 0.022357, acc = 0.98
[Train] Batch ID = 28380, loss = 0.00271913, acc = 1.0
[Validation] Batch ID = 28380, loss = 0.024885, acc = 0.98
[Train] Batch ID = 28390, loss = 0.208916, acc = 0.78
[Validation] Batch ID = 28390, loss = 0.0711173, acc = 0.9
[Train] Batch ID = 28400, loss = 0.00296322, acc = 1.0
[Validation] Batch ID = 28400, loss = 0.0191428, acc = 1.0
[Train] Batch ID = 28410, loss = 0.00235889, acc = 1.0
[Validation] Batch ID = 28410, loss = 0.0272752, acc = 0.98
[Train] Batch ID = 28420, loss = 0.00465191, acc = 1.0
[Validation] Batch ID = 28420, loss = 0.0346188, acc = 0.98
[Train] Batch ID = 28430, loss = 0.00310973, acc = 1.0
[Validation] Batch ID = 28430, loss = 0.0433816, acc = 0.94
[Train] Batch ID = 28440, loss = 0.217337, acc = 0.8
[Validation] Batch ID = 28440, loss = 0.020323, acc = 1.0
[Train] Batch ID = 28450, loss = 0.0018264, acc = 1.0
[Validation] Batch ID = 28450, loss = 0.0367968, acc = 0.96
[Train] Batch ID = 28460, loss = 0.00391045, acc = 1.0
[Validation] Batch ID = 28460, loss = 0.0493477, acc = 0.96
[Train] Batch ID = 28470, loss = 0.00269479, acc = 1.0
[Validation] Batch ID = 28470, loss = 0.0227373, acc = 0.98
[Train] Batch ID = 28480, loss = 0.00397583, acc = 1.0
[Validation] Batch ID = 28480, loss = 0.0238048, acc = 1.0
[Train] Batch ID = 28490, loss = 0.00300744, acc = 1.0
[Validation] Batch ID = 28490, loss = 0.0544896, acc = 0.96
[Train] Batch ID = 28500, loss = 0.00680725, acc = 1.0
[Validation] Batch ID = 28500, loss = 0.0505459, acc = 0.94
[Train] Batch ID = 28510, loss = 0.00250771, acc = 1.0
[Validation] Batch ID = 28510, loss = 0.0273664, acc = 0.98
[Train] Batch ID = 28520, loss = 0.00225257, acc = 1.0
[Validation] Batch ID = 28520, loss = 0.014909, acc = 1.0
[Train] Batch ID = 28530, loss = 0.00351722, acc = 1.0
[Validation] Batch ID = 28530, loss = 0.0119792, acc = 1.0
[Train] Batch ID = 28540, loss = 0.00299136, acc = 1.0
[Validation] Batch ID = 28540, loss = 0.025234, acc = 1.0
[Train] Batch ID = 28550, loss = 0.00511427, acc = 1.0
[Validation] Batch ID = 28550, loss = 0.0379574, acc = 0.96
[Train] Batch ID = 28560, loss = 0.00287795, acc = 1.0
[Validation] Batch ID = 28560, loss = 0.0251482, acc = 1.0
[Train] Batch ID = 28570, loss = 0.00487774, acc = 1.0
[Validation] Batch ID = 28570, loss = 0.0444929, acc = 0.96
[Train] Batch ID = 28580, loss = 0.00217892, acc = 1.0
[Validation] Batch ID = 28580, loss = 0.0191939, acc = 0.98
[Train] Batch ID = 28590, loss = 0.0060878, acc = 1.0
[Validation] Batch ID = 28590, loss = 0.0197076, acc = 1.0
[Train] Batch ID = 28600, loss = 0.00638748, acc = 1.0
[Validation] Batch ID = 28600, loss = 0.0273514, acc = 0.98
[Train] Batch ID = 28610, loss = 0.00305316, acc = 1.0
[Validation] Batch ID = 28610, loss = 0.037881, acc = 0.96
[Train] Batch ID = 28620, loss = 0.00238016, acc = 1.0
[Validation] Batch ID = 28620, loss = 0.0586842, acc = 0.92
[Train] Batch ID = 28630, loss = 0.00160888, acc = 1.0
[Validation] Batch ID = 28630, loss = 0.0184048, acc = 1.0
[Train] Batch ID = 28640, loss = 0.00374865, acc = 1.0
[Validation] Batch ID = 28640, loss = 0.0218343, acc = 1.0
[Train] Batch ID = 28650, loss = 0.00298201, acc = 1.0
[Validation] Batch ID = 28650, loss = 0.0714884, acc = 0.9
[Train] Batch ID = 28660, loss = 0.00555242, acc = 1.0
[Validation] Batch ID = 28660, loss = 0.0381605, acc = 0.98
[Train] Batch ID = 28670, loss = 0.00354916, acc = 1.0
[Validation] Batch ID = 28670, loss = 0.0427044, acc = 0.96
[Train] Batch ID = 28680, loss = 0.00249881, acc = 1.0
[Validation] Batch ID = 28680, loss = 0.0395053, acc = 0.96
[Train] Batch ID = 28690, loss = 0.00208115, acc = 1.0
[Validation] Batch ID = 28690, loss = 0.0358692, acc = 0.98
[Train] Batch ID = 28700, loss = 0.0015764, acc = 1.0
[Validation] Batch ID = 28700, loss = 0.060289, acc = 0.92
[Train] Batch ID = 28710, loss = 0.00121999, acc = 1.0
[Validation] Batch ID = 28710, loss = 0.0121361, acc = 1.0
[Train] Batch ID = 28720, loss = 0.00561682, acc = 1.0
[Validation] Batch ID = 28720, loss = 0.0401307, acc = 0.98
[Train] Batch ID = 28730, loss = 0.00820093, acc = 1.0
[Validation] Batch ID = 28730, loss = 0.0293135, acc = 0.98
[Train] Batch ID = 28740, loss = 0.00329881, acc = 1.0
[Validation] Batch ID = 28740, loss = 0.0198598, acc = 0.98
[Train] Batch ID = 28750, loss = 0.00204191, acc = 1.0
[Validation] Batch ID = 28750, loss = 0.0497055, acc = 0.96
[Train] Batch ID = 28760, loss = 0.00207496, acc = 1.0
[Validation] Batch ID = 28760, loss = 0.0242623, acc = 0.98
[Train] Batch ID = 28770, loss = 0.00220595, acc = 1.0
[Validation] Batch ID = 28770, loss = 0.0106344, acc = 1.0
[Train] Batch ID = 28780, loss = 0.00307546, acc = 1.0
[Validation] Batch ID = 28780, loss = 0.0420062, acc = 0.96
[Train] Batch ID = 28790, loss = 0.00332108, acc = 1.0
[Validation] Batch ID = 28790, loss = 0.0400945, acc = 0.94
[Train] Batch ID = 28800, loss = 0.00481934, acc = 1.0
[Validation] Batch ID = 28800, loss = 0.0378716, acc = 0.98
[Train] Batch ID = 28810, loss = 0.00714701, acc = 1.0
[Validation] Batch ID = 28810, loss = 0.0172037, acc = 0.98
[Train] Batch ID = 28820, loss = 0.00726843, acc = 1.0
[Validation] Batch ID = 28820, loss = 0.0420491, acc = 0.98
[Train] Batch ID = 28830, loss = 0.174289, acc = 0.86
[Validation] Batch ID = 28830, loss = 0.0172853, acc = 0.98
[Train] Batch ID = 28840, loss = 0.00381695, acc = 1.0
[Validation] Batch ID = 28840, loss = 0.0463148, acc = 0.94
[Train] Batch ID = 28850, loss = 0.00689381, acc = 1.0
[Validation] Batch ID = 28850, loss = 0.0582483, acc = 0.94
[Train] Batch ID = 28860, loss = 0.00313813, acc = 1.0
[Validation] Batch ID = 28860, loss = 0.0322532, acc = 0.98
[Train] Batch ID = 28870, loss = 0.00181361, acc = 1.0
[Validation] Batch ID = 28870, loss = 0.0611829, acc = 0.92
[Train] Batch ID = 28880, loss = 0.00223306, acc = 1.0
[Validation] Batch ID = 28880, loss = 0.0278901, acc = 0.98
[Train] Batch ID = 28890, loss = 0.00206606, acc = 1.0
[Validation] Batch ID = 28890, loss = 0.0358936, acc = 0.98
[Train] Batch ID = 28900, loss = 0.00286588, acc = 1.0
[Validation] Batch ID = 28900, loss = 0.0331103, acc = 0.98
[Train] Batch ID = 28910, loss = 0.00308549, acc = 1.0
[Validation] Batch ID = 28910, loss = 0.0230195, acc = 1.0
[Train] Batch ID = 28920, loss = 0.00227246, acc = 1.0
[Validation] Batch ID = 28920, loss = 0.0594105, acc = 0.94
[Train] Batch ID = 28930, loss = 0.00381859, acc = 1.0
[Validation] Batch ID = 28930, loss = 0.0461507, acc = 0.94
[Train] Batch ID = 28940, loss = 0.0056247, acc = 1.0
[Validation] Batch ID = 28940, loss = 0.0358883, acc = 0.98
[Train] Batch ID = 28950, loss = 0.00230527, acc = 1.0
[Validation] Batch ID = 28950, loss = 0.0357706, acc = 0.98
[Train] Batch ID = 28960, loss = 0.0050136, acc = 1.0
[Validation] Batch ID = 28960, loss = 0.0150801, acc = 0.98
[Train] Batch ID = 28970, loss = 0.165283, acc = 0.86
[Validation] Batch ID = 28970, loss = 0.0466333, acc = 0.98
[Train] Batch ID = 28980, loss = 0.00816504, acc = 1.0
[Validation] Batch ID = 28980, loss = 0.0410329, acc = 0.96
[Train] Batch ID = 28990, loss = 0.00268747, acc = 1.0
[Validation] Batch ID = 28990, loss = 0.0654232, acc = 0.92
[Train] Batch ID = 29000, loss = 0.00296797, acc = 1.0
[Validation] Batch ID = 29000, loss = 0.0252606, acc = 0.96
Evaluate full validation dataset ...
Current loss: 0.0305534 Best loss: 0.0288538
[TOTAL Validation] Batch ID = 29000, loss = 0.0305534, acc = 0.974376417234
Augmented Factor = 0.041967246692464065
[Train] Batch ID = 29010, loss = 0.0038844, acc = 1.0
[Validation] Batch ID = 29010, loss = 0.031116, acc = 0.96
[Train] Batch ID = 29020, loss = 0.00256857, acc = 1.0
[Validation] Batch ID = 29020, loss = 0.0513856, acc = 0.96
[Train] Batch ID = 29030, loss = 0.00246887, acc = 1.0
[Validation] Batch ID = 29030, loss = 0.0114498, acc = 1.0
[Train] Batch ID = 29040, loss = 0.00251095, acc = 1.0
[Validation] Batch ID = 29040, loss = 0.0544572, acc = 0.94
[Train] Batch ID = 29050, loss = 0.00212128, acc = 1.0
[Validation] Batch ID = 29050, loss = 0.0284784, acc = 0.96
[Train] Batch ID = 29060, loss = 0.00353372, acc = 1.0
[Validation] Batch ID = 29060, loss = 0.0485321, acc = 0.96
[Train] Batch ID = 29070, loss = 0.00553347, acc = 1.0
[Validation] Batch ID = 29070, loss = 0.0411138, acc = 0.96
[Train] Batch ID = 29080, loss = 0.00240105, acc = 1.0
[Validation] Batch ID = 29080, loss = 0.0532665, acc = 0.94
[Train] Batch ID = 29090, loss = 0.00532016, acc = 1.0
[Validation] Batch ID = 29090, loss = 0.0231304, acc = 0.96
[Train] Batch ID = 29100, loss = 0.00451271, acc = 1.0
[Validation] Batch ID = 29100, loss = 0.0361954, acc = 0.98
[Train] Batch ID = 29110, loss = 0.00430247, acc = 1.0
[Validation] Batch ID = 29110, loss = 0.0303963, acc = 0.98
[Train] Batch ID = 29120, loss = 0.00430035, acc = 1.0
[Validation] Batch ID = 29120, loss = 0.0549169, acc = 0.94
[Train] Batch ID = 29130, loss = 0.00229102, acc = 1.0
[Validation] Batch ID = 29130, loss = 0.0567443, acc = 0.94
[Train] Batch ID = 29140, loss = 0.00287827, acc = 1.0
[Validation] Batch ID = 29140, loss = 0.0258817, acc = 1.0
[Train] Batch ID = 29150, loss = 0.00324381, acc = 1.0
[Validation] Batch ID = 29150, loss = 0.0108777, acc = 1.0
[Train] Batch ID = 29160, loss = 0.00439642, acc = 1.0
[Validation] Batch ID = 29160, loss = 0.0146374, acc = 1.0
[Train] Batch ID = 29170, loss = 0.00489323, acc = 1.0
[Validation] Batch ID = 29170, loss = 0.0232258, acc = 1.0
[Train] Batch ID = 29180, loss = 0.215129, acc = 0.82
[Validation] Batch ID = 29180, loss = 0.016429, acc = 1.0
[Train] Batch ID = 29190, loss = 0.00769889, acc = 1.0
[Validation] Batch ID = 29190, loss = 0.0509269, acc = 0.96
[Train] Batch ID = 29200, loss = 0.00232387, acc = 1.0
[Validation] Batch ID = 29200, loss = 0.0245043, acc = 0.98
[Train] Batch ID = 29210, loss = 0.00237136, acc = 1.0
[Validation] Batch ID = 29210, loss = 0.029129, acc = 1.0
[Train] Batch ID = 29220, loss = 0.0021763, acc = 1.0
[Validation] Batch ID = 29220, loss = 0.0208607, acc = 1.0
[Train] Batch ID = 29230, loss = 0.00385343, acc = 1.0
[Validation] Batch ID = 29230, loss = 0.0227971, acc = 1.0
[Train] Batch ID = 29240, loss = 0.00287054, acc = 1.0
[Validation] Batch ID = 29240, loss = 0.0193502, acc = 1.0
[Train] Batch ID = 29250, loss = 0.00488642, acc = 1.0
[Validation] Batch ID = 29250, loss = 0.0148413, acc = 1.0
[Train] Batch ID = 29260, loss = 0.00536227, acc = 1.0
[Validation] Batch ID = 29260, loss = 0.0235412, acc = 0.98
[Train] Batch ID = 29270, loss = 0.0036957, acc = 1.0
[Validation] Batch ID = 29270, loss = 0.0155122, acc = 1.0
[Train] Batch ID = 29280, loss = 0.00438094, acc = 1.0
[Validation] Batch ID = 29280, loss = 0.0599261, acc = 0.9
[Train] Batch ID = 29290, loss = 0.00301456, acc = 1.0
[Validation] Batch ID = 29290, loss = 0.0354964, acc = 0.98
[Train] Batch ID = 29300, loss = 0.00131375, acc = 1.0
[Validation] Batch ID = 29300, loss = 0.0121265, acc = 1.0
[Train] Batch ID = 29310, loss = 0.00527284, acc = 1.0
[Validation] Batch ID = 29310, loss = 0.0292488, acc = 0.98
[Train] Batch ID = 29320, loss = 0.00360234, acc = 1.0
[Validation] Batch ID = 29320, loss = 0.019855, acc = 0.98
[Train] Batch ID = 29330, loss = 0.00250239, acc = 1.0
[Validation] Batch ID = 29330, loss = 0.0465166, acc = 0.96
[Train] Batch ID = 29340, loss = 0.00284056, acc = 1.0
[Validation] Batch ID = 29340, loss = 0.0185543, acc = 1.0
[Train] Batch ID = 29350, loss = 0.00349764, acc = 1.0
[Validation] Batch ID = 29350, loss = 0.0279455, acc = 0.98
[Train] Batch ID = 29360, loss = 0.00242556, acc = 1.0
[Validation] Batch ID = 29360, loss = 0.0143339, acc = 1.0
[Train] Batch ID = 29370, loss = 0.00297518, acc = 1.0
[Validation] Batch ID = 29370, loss = 0.0659745, acc = 0.94
[Train] Batch ID = 29380, loss = 0.00174884, acc = 1.0
[Validation] Batch ID = 29380, loss = 0.0156295, acc = 1.0
[Train] Batch ID = 29390, loss = 0.00255615, acc = 1.0
[Validation] Batch ID = 29390, loss = 0.0181886, acc = 1.0
[Train] Batch ID = 29400, loss = 0.00268685, acc = 1.0
[Validation] Batch ID = 29400, loss = 0.0130103, acc = 1.0
[Train] Batch ID = 29410, loss = 0.00239325, acc = 1.0
[Validation] Batch ID = 29410, loss = 0.0322887, acc = 0.96
[Train] Batch ID = 29420, loss = 0.00331816, acc = 1.0
[Validation] Batch ID = 29420, loss = 0.01989, acc = 0.96
[Train] Batch ID = 29430, loss = 0.00281455, acc = 1.0
[Validation] Batch ID = 29430, loss = 0.0173552, acc = 1.0
[Train] Batch ID = 29440, loss = 0.00452452, acc = 1.0
[Validation] Batch ID = 29440, loss = 0.0226489, acc = 1.0
[Train] Batch ID = 29450, loss = 0.00195001, acc = 1.0
[Validation] Batch ID = 29450, loss = 0.0310046, acc = 0.96
[Train] Batch ID = 29460, loss = 0.00265407, acc = 1.0
[Validation] Batch ID = 29460, loss = 0.0135432, acc = 0.98
[Train] Batch ID = 29470, loss = 0.00453543, acc = 1.0
[Validation] Batch ID = 29470, loss = 0.0217565, acc = 0.98
[Train] Batch ID = 29480, loss = 0.00257016, acc = 1.0
[Validation] Batch ID = 29480, loss = 0.0105343, acc = 1.0
[Train] Batch ID = 29490, loss = 0.0034656, acc = 1.0
[Validation] Batch ID = 29490, loss = 0.0339107, acc = 0.98
[Train] Batch ID = 29500, loss = 0.00361954, acc = 1.0
[Validation] Batch ID = 29500, loss = 0.0208016, acc = 0.98
[Train] Batch ID = 29510, loss = 0.00244643, acc = 1.0
[Validation] Batch ID = 29510, loss = 0.0168126, acc = 1.0
[Train] Batch ID = 29520, loss = 0.00116432, acc = 1.0
[Validation] Batch ID = 29520, loss = 0.0486197, acc = 0.94
[Train] Batch ID = 29530, loss = 0.00154674, acc = 1.0
[Validation] Batch ID = 29530, loss = 0.0342671, acc = 0.96
[Train] Batch ID = 29540, loss = 0.00186046, acc = 1.0
[Validation] Batch ID = 29540, loss = 0.0214592, acc = 0.98
[Train] Batch ID = 29550, loss = 0.00201071, acc = 1.0
[Validation] Batch ID = 29550, loss = 0.0346468, acc = 0.96
[Train] Batch ID = 29560, loss = 0.00322824, acc = 1.0
[Validation] Batch ID = 29560, loss = 0.0108135, acc = 1.0
[Train] Batch ID = 29570, loss = 0.00231557, acc = 1.0
[Validation] Batch ID = 29570, loss = 0.0312824, acc = 0.96
[Train] Batch ID = 29580, loss = 0.00291333, acc = 1.0
[Validation] Batch ID = 29580, loss = 0.0270655, acc = 0.98
[Train] Batch ID = 29590, loss = 0.00497232, acc = 1.0
[Validation] Batch ID = 29590, loss = 0.0238215, acc = 1.0
[Train] Batch ID = 29600, loss = 0.0024114, acc = 1.0
[Validation] Batch ID = 29600, loss = 0.0274955, acc = 0.98
[Train] Batch ID = 29610, loss = 0.00174403, acc = 1.0
[Validation] Batch ID = 29610, loss = 0.0238297, acc = 0.98
[Train] Batch ID = 29620, loss = 0.00225151, acc = 1.0
[Validation] Batch ID = 29620, loss = 0.019734, acc = 0.98
[Train] Batch ID = 29630, loss = 0.00610198, acc = 1.0
[Validation] Batch ID = 29630, loss = 0.0324072, acc = 0.96
[Train] Batch ID = 29640, loss = 0.00527555, acc = 1.0
[Validation] Batch ID = 29640, loss = 0.0249677, acc = 1.0
[Train] Batch ID = 29650, loss = 0.00298039, acc = 1.0
[Validation] Batch ID = 29650, loss = 0.0238455, acc = 1.0
[Train] Batch ID = 29660, loss = 0.00232286, acc = 1.0
[Validation] Batch ID = 29660, loss = 0.0201177, acc = 0.98
[Train] Batch ID = 29670, loss = 0.00131186, acc = 1.0
[Validation] Batch ID = 29670, loss = 0.052216, acc = 0.96
[Train] Batch ID = 29680, loss = 0.000613342, acc = 1.0
[Validation] Batch ID = 29680, loss = 0.0300524, acc = 0.96
[Train] Batch ID = 29690, loss = 0.00156731, acc = 1.0
[Validation] Batch ID = 29690, loss = 0.0436714, acc = 0.94
[Train] Batch ID = 29700, loss = 0.00267004, acc = 1.0
[Validation] Batch ID = 29700, loss = 0.0427525, acc = 0.96
[Train] Batch ID = 29710, loss = 0.0020074, acc = 1.0
[Validation] Batch ID = 29710, loss = 0.0242303, acc = 1.0
[Train] Batch ID = 29720, loss = 0.00600549, acc = 1.0
[Validation] Batch ID = 29720, loss = 0.0214799, acc = 1.0
[Train] Batch ID = 29730, loss = 0.00751813, acc = 1.0
[Validation] Batch ID = 29730, loss = 0.0221981, acc = 1.0
[Train] Batch ID = 29740, loss = 0.0040346, acc = 1.0
[Validation] Batch ID = 29740, loss = 0.0228101, acc = 0.98
[Train] Batch ID = 29750, loss = 0.00277805, acc = 1.0
[Validation] Batch ID = 29750, loss = 0.0279392, acc = 0.98
[Train] Batch ID = 29760, loss = 0.00340124, acc = 1.0
[Validation] Batch ID = 29760, loss = 0.0120123, acc = 1.0
[Train] Batch ID = 29770, loss = 0.00270091, acc = 1.0
[Validation] Batch ID = 29770, loss = 0.044132, acc = 0.94
[Train] Batch ID = 29780, loss = 0.00452921, acc = 1.0
[Validation] Batch ID = 29780, loss = 0.0128293, acc = 1.0
[Train] Batch ID = 29790, loss = 0.00301279, acc = 1.0
[Validation] Batch ID = 29790, loss = 0.0306247, acc = 0.98
[Train] Batch ID = 29800, loss = 0.00219593, acc = 1.0
[Validation] Batch ID = 29800, loss = 0.0394418, acc = 0.96
[Train] Batch ID = 29810, loss = 0.00256027, acc = 1.0
[Validation] Batch ID = 29810, loss = 0.0166895, acc = 1.0
[Train] Batch ID = 29820, loss = 0.00309072, acc = 1.0
[Validation] Batch ID = 29820, loss = 0.0408857, acc = 0.96
[Train] Batch ID = 29830, loss = 0.000998118, acc = 1.0
[Validation] Batch ID = 29830, loss = 0.039212, acc = 0.98
[Train] Batch ID = 29840, loss = 0.00367502, acc = 1.0
[Validation] Batch ID = 29840, loss = 0.0188063, acc = 1.0
[Train] Batch ID = 29850, loss = 0.000793363, acc = 1.0
[Validation] Batch ID = 29850, loss = 0.0151321, acc = 1.0
[Train] Batch ID = 29860, loss = 0.00624411, acc = 1.0
[Validation] Batch ID = 29860, loss = 0.0587721, acc = 0.96
[Train] Batch ID = 29870, loss = 0.00866576, acc = 1.0
[Validation] Batch ID = 29870, loss = 0.0466332, acc = 0.96
[Train] Batch ID = 29880, loss = 0.00274511, acc = 1.0
[Validation] Batch ID = 29880, loss = 0.0189194, acc = 1.0
[Train] Batch ID = 29890, loss = 0.0014106, acc = 1.0
[Validation] Batch ID = 29890, loss = 0.0257046, acc = 0.98
[Train] Batch ID = 29900, loss = 0.00186409, acc = 1.0
[Validation] Batch ID = 29900, loss = 0.0350293, acc = 0.98
[Train] Batch ID = 29910, loss = 0.00321869, acc = 1.0
[Validation] Batch ID = 29910, loss = 0.0376301, acc = 0.96
[Train] Batch ID = 29920, loss = 0.00143117, acc = 1.0
[Validation] Batch ID = 29920, loss = 0.0411825, acc = 0.96
[Train] Batch ID = 29930, loss = 0.000999447, acc = 1.0
[Validation] Batch ID = 29930, loss = 0.0343564, acc = 0.98
[Train] Batch ID = 29940, loss = 0.00127585, acc = 1.0
[Validation] Batch ID = 29940, loss = 0.0254181, acc = 1.0
[Train] Batch ID = 29950, loss = 0.00336109, acc = 1.0
[Validation] Batch ID = 29950, loss = 0.0471523, acc = 0.94
[Train] Batch ID = 29960, loss = 0.0029882, acc = 1.0
[Validation] Batch ID = 29960, loss = 0.0176365, acc = 1.0
[Train] Batch ID = 29970, loss = 0.00244312, acc = 1.0
[Validation] Batch ID = 29970, loss = 0.0292141, acc = 0.98
[Train] Batch ID = 29980, loss = 0.00348194, acc = 1.0
[Validation] Batch ID = 29980, loss = 0.0214035, acc = 0.98
[Train] Batch ID = 29990, loss = 0.00290159, acc = 1.0
[Validation] Batch ID = 29990, loss = 0.0328107, acc = 0.96
[Train] Batch ID = 30000, loss = 0.0033496, acc = 1.0
[Validation] Batch ID = 30000, loss = 0.013939, acc = 1.0
Evaluate full validation dataset ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Saving model ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Current loss: 0.0281227 Best loss: 0.0288538
[TOTAL Validation] Batch ID = 30000, loss = 0.0281227, acc = 0.978458049887
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Model successfully saved here: outputs/checkpoints/c1s_9_c1n_256_c2s_6_c2n_64_c2d_0.7_c1vl_16_c1s_5_c1nf_16_c2vl_32_lr_0.0001_rs_1--TrafficSign--1510487290.423481
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Augmented Factor = 0.03777052202321766
[Train] Batch ID = 30010, loss = 0.00308558, acc = 1.0
[Validation] Batch ID = 30010, loss = 0.0298162, acc = 0.98
[Train] Batch ID = 30020, loss = 0.00409182, acc = 1.0
[Validation] Batch ID = 30020, loss = 0.0267626, acc = 0.98
[Train] Batch ID = 30030, loss = 0.00184304, acc = 1.0
[Validation] Batch ID = 30030, loss = 0.0167693, acc = 1.0
[Train] Batch ID = 30040, loss = 0.00163594, acc = 1.0
[Validation] Batch ID = 30040, loss = 0.0353338, acc = 0.96
[Train] Batch ID = 30050, loss = 0.00188912, acc = 1.0
[Validation] Batch ID = 30050, loss = 0.0216687, acc = 0.98
[Train] Batch ID = 30060, loss = 0.00255838, acc = 1.0
[Validation] Batch ID = 30060, loss = 0.013865, acc = 1.0
[Train] Batch ID = 30070, loss = 0.00305114, acc = 1.0
[Validation] Batch ID = 30070, loss = 0.0242632, acc = 0.98
[Train] Batch ID = 30080, loss = 0.00290655, acc = 1.0
[Validation] Batch ID = 30080, loss = 0.0201221, acc = 1.0
[Train] Batch ID = 30090, loss = 0.0027923, acc = 1.0
[Validation] Batch ID = 30090, loss = 0.0542704, acc = 0.96
[Train] Batch ID = 30100, loss = 0.00346498, acc = 1.0
[Validation] Batch ID = 30100, loss = 0.0388422, acc = 0.96
[Train] Batch ID = 30110, loss = 0.00511713, acc = 1.0
[Validation] Batch ID = 30110, loss = 0.0403253, acc = 0.96
[Train] Batch ID = 30120, loss = 0.165509, acc = 0.92
[Validation] Batch ID = 30120, loss = 0.0451424, acc = 0.96
[Train] Batch ID = 30130, loss = 0.00740871, acc = 1.0
[Validation] Batch ID = 30130, loss = 0.0469599, acc = 0.96
[Train] Batch ID = 30140, loss = 0.224502, acc = 0.68
[Validation] Batch ID = 30140, loss = 0.032461, acc = 0.98
[Train] Batch ID = 30150, loss = 0.00703456, acc = 1.0
[Validation] Batch ID = 30150, loss = 0.019953, acc = 1.0
[Train] Batch ID = 30160, loss = 0.00355368, acc = 1.0
[Validation] Batch ID = 30160, loss = 0.0219064, acc = 0.98
[Train] Batch ID = 30170, loss = 0.00204645, acc = 1.0
[Validation] Batch ID = 30170, loss = 0.0498067, acc = 1.0
[Train] Batch ID = 30180, loss = 0.00232646, acc = 1.0
[Validation] Batch ID = 30180, loss = 0.0371475, acc = 0.98
[Train] Batch ID = 30190, loss = 0.00243541, acc = 1.0
[Validation] Batch ID = 30190, loss = 0.017446, acc = 1.0
[Train] Batch ID = 30200, loss = 0.00330877, acc = 1.0
[Validation] Batch ID = 30200, loss = 0.0270755, acc = 0.98
[Train] Batch ID = 30210, loss = 0.00171942, acc = 1.0
[Validation] Batch ID = 30210, loss = 0.0156927, acc = 1.0
[Train] Batch ID = 30220, loss = 0.00193393, acc = 1.0
[Validation] Batch ID = 30220, loss = 0.0156462, acc = 1.0
[Train] Batch ID = 30230, loss = 0.00162406, acc = 1.0
[Validation] Batch ID = 30230, loss = 0.0349887, acc = 0.96
[Train] Batch ID = 30240, loss = 0.00275971, acc = 1.0
[Validation] Batch ID = 30240, loss = 0.0388496, acc = 0.96
[Train] Batch ID = 30250, loss = 0.166583, acc = 0.82
[Validation] Batch ID = 30250, loss = 0.0408573, acc = 0.96
[Train] Batch ID = 30260, loss = 0.0037323, acc = 1.0
[Validation] Batch ID = 30260, loss = 0.0351399, acc = 0.98
[Train] Batch ID = 30270, loss = 0.00198307, acc = 1.0
[Validation] Batch ID = 30270, loss = 0.0308444, acc = 0.98
[Train] Batch ID = 30280, loss = 0.00345518, acc = 1.0
[Validation] Batch ID = 30280, loss = 0.0333832, acc = 0.98
[Train] Batch ID = 30290, loss = 0.0025137, acc = 1.0
[Validation] Batch ID = 30290, loss = 0.0358848, acc = 0.96
[Train] Batch ID = 30300, loss = 0.00252573, acc = 1.0
[Validation] Batch ID = 30300, loss = 0.0434974, acc = 0.94
[Train] Batch ID = 30310, loss = 0.00225887, acc = 1.0
[Validation] Batch ID = 30310, loss = 0.0285508, acc = 0.96
[Train] Batch ID = 30320, loss = 0.00161825, acc = 1.0
[Validation] Batch ID = 30320, loss = 0.015969, acc = 1.0
[Train] Batch ID = 30330, loss = 0.00651159, acc = 1.0
[Validation] Batch ID = 30330, loss = 0.0381881, acc = 1.0
[Train] Batch ID = 30340, loss = 0.00194908, acc = 1.0
[Validation] Batch ID = 30340, loss = 0.0560107, acc = 0.96
[Train] Batch ID = 30350, loss = 0.00274221, acc = 1.0
[Validation] Batch ID = 30350, loss = 0.0619698, acc = 0.92
[Train] Batch ID = 30360, loss = 0.0034279, acc = 1.0
[Validation] Batch ID = 30360, loss = 0.0471996, acc = 0.94
[Train] Batch ID = 30370, loss = 0.00311877, acc = 1.0
[Validation] Batch ID = 30370, loss = 0.0139151, acc = 1.0
[Train] Batch ID = 30380, loss = 0.00342589, acc = 1.0
[Validation] Batch ID = 30380, loss = 0.0206453, acc = 1.0
[Train] Batch ID = 30390, loss = 0.00329326, acc = 1.0
[Validation] Batch ID = 30390, loss = 0.0141933, acc = 1.0
[Train] Batch ID = 30400, loss = 0.00235963, acc = 1.0
[Validation] Batch ID = 30400, loss = 0.0224919, acc = 1.0
[Train] Batch ID = 30410, loss = 0.00281501, acc = 1.0
[Validation] Batch ID = 30410, loss = 0.0637048, acc = 0.92
[Train] Batch ID = 30420, loss = 0.00441067, acc = 1.0
[Validation] Batch ID = 30420, loss = 0.0368943, acc = 0.96
[Train] Batch ID = 30430, loss = 0.00256141, acc = 1.0
[Validation] Batch ID = 30430, loss = 0.052466, acc = 0.94
[Train] Batch ID = 30440, loss = 0.00231464, acc = 1.0
[Validation] Batch ID = 30440, loss = 0.0153817, acc = 0.98
[Train] Batch ID = 30450, loss = 0.00214256, acc = 1.0
[Validation] Batch ID = 30450, loss = 0.0245095, acc = 0.98
[Train] Batch ID = 30460, loss = 0.00153847, acc = 1.0
[Validation] Batch ID = 30460, loss = 0.0587088, acc = 0.94
[Train] Batch ID = 30470, loss = 0.00235586, acc = 1.0
[Validation] Batch ID = 30470, loss = 0.0311099, acc = 0.98
[Train] Batch ID = 30480, loss = 0.00496623, acc = 1.0
[Validation] Batch ID = 30480, loss = 0.0403023, acc = 0.98
[Train] Batch ID = 30490, loss = 0.0036113, acc = 1.0
[Validation] Batch ID = 30490, loss = 0.0298248, acc = 1.0
[Train] Batch ID = 30500, loss = 0.00260245, acc = 1.0
[Validation] Batch ID = 30500, loss = 0.0398998, acc = 0.96
[Train] Batch ID = 30510, loss = 0.00217038, acc = 1.0
[Validation] Batch ID = 30510, loss = 0.020265, acc = 0.98
[Train] Batch ID = 30520, loss = 0.00180789, acc = 1.0
[Validation] Batch ID = 30520, loss = 0.0270737, acc = 0.98
[Train] Batch ID = 30530, loss = 0.00241464, acc = 1.0
[Validation] Batch ID = 30530, loss = 0.018195, acc = 0.98
[Train] Batch ID = 30540, loss = 0.00357134, acc = 1.0
[Validation] Batch ID = 30540, loss = 0.040771, acc = 0.96
[Train] Batch ID = 30550, loss = 0.00117278, acc = 1.0
[Validation] Batch ID = 30550, loss = 0.0270232, acc = 0.98
[Train] Batch ID = 30560, loss = 0.00238039, acc = 1.0
[Validation] Batch ID = 30560, loss = 0.0324522, acc = 0.98
[Train] Batch ID = 30570, loss = 0.00174935, acc = 1.0
[Validation] Batch ID = 30570, loss = 0.0621308, acc = 0.94
[Train] Batch ID = 30580, loss = 0.00292681, acc = 1.0
[Validation] Batch ID = 30580, loss = 0.0495532, acc = 0.96
[Train] Batch ID = 30590, loss = 0.00150827, acc = 1.0
[Validation] Batch ID = 30590, loss = 0.0223394, acc = 0.98
[Train] Batch ID = 30600, loss = 0.00192335, acc = 1.0
[Validation] Batch ID = 30600, loss = 0.0168607, acc = 1.0
[Train] Batch ID = 30610, loss = 0.00323653, acc = 1.0
[Validation] Batch ID = 30610, loss = 0.0295714, acc = 0.98
[Train] Batch ID = 30620, loss = 0.00207161, acc = 1.0
[Validation] Batch ID = 30620, loss = 0.0290416, acc = 0.98
[Train] Batch ID = 30630, loss = 0.00397435, acc = 1.0
[Validation] Batch ID = 30630, loss = 0.0556789, acc = 0.96
[Train] Batch ID = 30640, loss = 0.00351983, acc = 1.0
[Validation] Batch ID = 30640, loss = 0.00791785, acc = 1.0
[Train] Batch ID = 30650, loss = 0.00174651, acc = 1.0
[Validation] Batch ID = 30650, loss = 0.0422654, acc = 0.96
[Train] Batch ID = 30660, loss = 0.00273615, acc = 1.0
[Validation] Batch ID = 30660, loss = 0.0535341, acc = 0.9
[Train] Batch ID = 30670, loss = 0.00278145, acc = 1.0
[Validation] Batch ID = 30670, loss = 0.00938919, acc = 1.0
[Train] Batch ID = 30680, loss = 0.00272183, acc = 1.0
[Validation] Batch ID = 30680, loss = 0.0198699, acc = 0.98
[Train] Batch ID = 30690, loss = 0.174083, acc = 0.82
[Validation] Batch ID = 30690, loss = 0.0409344, acc = 0.96
[Train] Batch ID = 30700, loss = 0.00441883, acc = 1.0
[Validation] Batch ID = 30700, loss = 0.0370503, acc = 1.0
[Train] Batch ID = 30710, loss = 0.0120226, acc = 1.0
[Validation] Batch ID = 30710, loss = 0.0770121, acc = 0.94
[Train] Batch ID = 30720, loss = 0.00324649, acc = 1.0
[Validation] Batch ID = 30720, loss = 0.019695, acc = 0.98
[Train] Batch ID = 30730, loss = 0.00726951, acc = 1.0
[Validation] Batch ID = 30730, loss = 0.0457008, acc = 0.94
[Train] Batch ID = 30740, loss = 0.00262897, acc = 1.0
[Validation] Batch ID = 30740, loss = 0.0351115, acc = 0.98
[Train] Batch ID = 30750, loss = 0.00153887, acc = 1.0
[Validation] Batch ID = 30750, loss = 0.0211766, acc = 1.0
[Train] Batch ID = 30760, loss = 0.00299434, acc = 1.0
[Validation] Batch ID = 30760, loss = 0.00991762, acc = 1.0
[Train] Batch ID = 30770, loss = 0.00735433, acc = 1.0
[Validation] Batch ID = 30770, loss = 0.0222274, acc = 0.98
[Train] Batch ID = 30780, loss = 0.00576768, acc = 1.0
[Validation] Batch ID = 30780, loss = 0.030316, acc = 0.96
[Train] Batch ID = 30790, loss = 0.00307421, acc = 1.0
[Validation] Batch ID = 30790, loss = 0.0150448, acc = 1.0
[Train] Batch ID = 30800, loss = 0.00522711, acc = 1.0
[Validation] Batch ID = 30800, loss = 0.0102159, acc = 1.0
[Train] Batch ID = 30810, loss = 0.00159104, acc = 1.0
[Validation] Batch ID = 30810, loss = 0.018668, acc = 1.0
[Train] Batch ID = 30820, loss = 0.00209257, acc = 1.0
[Validation] Batch ID = 30820, loss = 0.0143923, acc = 0.98
[Train] Batch ID = 30830, loss = 0.00293544, acc = 1.0
[Validation] Batch ID = 30830, loss = 0.0195162, acc = 0.98
[Train] Batch ID = 30840, loss = 0.00101926, acc = 1.0
[Validation] Batch ID = 30840, loss = 0.0301813, acc = 0.96
[Train] Batch ID = 30850, loss = 0.00348647, acc = 1.0
[Validation] Batch ID = 30850, loss = 0.0279274, acc = 0.98
[Train] Batch ID = 30860, loss = 0.00116152, acc = 1.0
[Validation] Batch ID = 30860, loss = 0.0505418, acc = 0.94
[Train] Batch ID = 30870, loss = 0.00126153, acc = 1.0
[Validation] Batch ID = 30870, loss = 0.0473751, acc = 0.96
[Train] Batch ID = 30880, loss = 0.00305089, acc = 1.0
[Validation] Batch ID = 30880, loss = 0.0415256, acc = 0.96
[Train] Batch ID = 30890, loss = 0.0011835, acc = 1.0
[Validation] Batch ID = 30890, loss = 0.0265887, acc = 1.0
[Train] Batch ID = 30900, loss = 0.00317623, acc = 1.0
[Validation] Batch ID = 30900, loss = 0.0416649, acc = 0.98
[Train] Batch ID = 30910, loss = 0.00629843, acc = 1.0
[Validation] Batch ID = 30910, loss = 0.0445942, acc = 0.96
[Train] Batch ID = 30920, loss = 0.00561427, acc = 1.0
[Validation] Batch ID = 30920, loss = 0.0307548, acc = 0.98
[Train] Batch ID = 30930, loss = 0.00464124, acc = 1.0
[Validation] Batch ID = 30930, loss = 0.0290602, acc = 0.96
[Train] Batch ID = 30940, loss = 0.00261114, acc = 1.0
[Validation] Batch ID = 30940, loss = 0.0383824, acc = 0.94
[Train] Batch ID = 30950, loss = 0.00281591, acc = 1.0
[Validation] Batch ID = 30950, loss = 0.0231211, acc = 0.98
[Train] Batch ID = 30960, loss = 0.00134218, acc = 1.0
[Validation] Batch ID = 30960, loss = 0.00769898, acc = 1.0
[Train] Batch ID = 30970, loss = 0.00263869, acc = 1.0
[Validation] Batch ID = 30970, loss = 0.0480683, acc = 0.92
[Train] Batch ID = 30980, loss = 0.00142341, acc = 1.0
[Validation] Batch ID = 30980, loss = 0.0273591, acc = 0.98
[Train] Batch ID = 30990, loss = 0.00142448, acc = 1.0
[Validation] Batch ID = 30990, loss = 0.00866922, acc = 1.0
[Train] Batch ID = 31000, loss = 0.00183827, acc = 1.0
[Validation] Batch ID = 31000, loss = 0.0293035, acc = 0.98
Evaluate full validation dataset ...
Current loss: 0.0293512 Best loss: 0.0281227
[TOTAL Validation] Batch ID = 31000, loss = 0.0293512, acc = 0.973696145125
Augmented Factor = 0.03399346982089589
[Train] Batch ID = 31010, loss = 0.00109526, acc = 1.0
[Validation] Batch ID = 31010, loss = 0.0209888, acc = 0.98
[Train] Batch ID = 31020, loss = 0.00149772, acc = 1.0
[Validation] Batch ID = 31020, loss = 0.0367371, acc = 0.96
[Train] Batch ID = 31030, loss = 0.00287742, acc = 1.0
[Validation] Batch ID = 31030, loss = 0.0357544, acc = 0.96
[Train] Batch ID = 31040, loss = 0.00622898, acc = 1.0
[Validation] Batch ID = 31040, loss = 0.0516094, acc = 0.96
[Train] Batch ID = 31050, loss = 0.00314686, acc = 1.0
[Validation] Batch ID = 31050, loss = 0.0395477, acc = 0.96
[Train] Batch ID = 31060, loss = 0.00232349, acc = 1.0
[Validation] Batch ID = 31060, loss = 0.0491235, acc = 0.9
[Train] Batch ID = 31070, loss = 0.00257453, acc = 1.0
[Validation] Batch ID = 31070, loss = 0.0205726, acc = 1.0
[Train] Batch ID = 31080, loss = 0.00108937, acc = 1.0
[Validation] Batch ID = 31080, loss = 0.0183345, acc = 1.0
[Train] Batch ID = 31090, loss = 0.00246596, acc = 1.0
[Validation] Batch ID = 31090, loss = 0.0336431, acc = 0.96
[Train] Batch ID = 31100, loss = 0.00278701, acc = 1.0
[Validation] Batch ID = 31100, loss = 0.0453568, acc = 0.98
[Train] Batch ID = 31110, loss = 0.192478, acc = 0.82
[Validation] Batch ID = 31110, loss = 0.0239345, acc = 1.0
[Train] Batch ID = 31120, loss = 0.00425275, acc = 1.0
[Validation] Batch ID = 31120, loss = 0.00838458, acc = 1.0
[Train] Batch ID = 31130, loss = 0.00224531, acc = 1.0
[Validation] Batch ID = 31130, loss = 0.0419688, acc = 0.96
[Train] Batch ID = 31140, loss = 0.0031795, acc = 1.0
[Validation] Batch ID = 31140, loss = 0.0432402, acc = 0.94
[Train] Batch ID = 31150, loss = 0.00178239, acc = 1.0
[Validation] Batch ID = 31150, loss = 0.0144345, acc = 0.98
[Train] Batch ID = 31160, loss = 0.00231957, acc = 1.0
[Validation] Batch ID = 31160, loss = 0.0134037, acc = 1.0
[Train] Batch ID = 31170, loss = 0.0015889, acc = 1.0
[Validation] Batch ID = 31170, loss = 0.0142935, acc = 1.0
[Train] Batch ID = 31180, loss = 0.00309462, acc = 1.0
[Validation] Batch ID = 31180, loss = 0.0192129, acc = 1.0
[Train] Batch ID = 31190, loss = 0.00134566, acc = 1.0
[Validation] Batch ID = 31190, loss = 0.0216003, acc = 0.98
[Train] Batch ID = 31200, loss = 0.00211744, acc = 1.0
[Validation] Batch ID = 31200, loss = 0.0327926, acc = 0.96
[Train] Batch ID = 31210, loss = 0.00301934, acc = 1.0
[Validation] Batch ID = 31210, loss = 0.0611122, acc = 0.94
[Train] Batch ID = 31220, loss = 0.00380254, acc = 1.0
[Validation] Batch ID = 31220, loss = 0.0120143, acc = 1.0
[Train] Batch ID = 31230, loss = 0.00120407, acc = 1.0
[Validation] Batch ID = 31230, loss = 0.00670944, acc = 1.0
[Train] Batch ID = 31240, loss = 0.00330565, acc = 1.0
[Validation] Batch ID = 31240, loss = 0.0193155, acc = 1.0
[Train] Batch ID = 31250, loss = 0.0017795, acc = 1.0
[Validation] Batch ID = 31250, loss = 0.02187, acc = 0.98
[Train] Batch ID = 31260, loss = 0.000966598, acc = 1.0
[Validation] Batch ID = 31260, loss = 0.00780236, acc = 1.0
[Train] Batch ID = 31270, loss = 0.00169157, acc = 1.0
[Validation] Batch ID = 31270, loss = 0.0066283, acc = 1.0
[Train] Batch ID = 31280, loss = 0.00149083, acc = 1.0
[Validation] Batch ID = 31280, loss = 0.0183884, acc = 0.98
[Train] Batch ID = 31290, loss = 0.00145079, acc = 1.0
[Validation] Batch ID = 31290, loss = 0.00428045, acc = 1.0
[Train] Batch ID = 31300, loss = 0.000778875, acc = 1.0
[Validation] Batch ID = 31300, loss = 0.0280677, acc = 0.98
[Train] Batch ID = 31310, loss = 0.00268299, acc = 1.0
[Validation] Batch ID = 31310, loss = 0.0393795, acc = 0.96
[Train] Batch ID = 31320, loss = 0.0016673, acc = 1.0
[Validation] Batch ID = 31320, loss = 0.00898811, acc = 1.0
[Train] Batch ID = 31330, loss = 0.00104528, acc = 1.0
[Validation] Batch ID = 31330, loss = 0.00902743, acc = 1.0
[Train] Batch ID = 31340, loss = 0.00241876, acc = 1.0
[Validation] Batch ID = 31340, loss = 0.0196604, acc = 0.98
[Train] Batch ID = 31350, loss = 0.00149815, acc = 1.0
[Validation] Batch ID = 31350, loss = 0.0299185, acc = 0.98
[Train] Batch ID = 31360, loss = 0.00215979, acc = 1.0
[Validation] Batch ID = 31360, loss = 0.0428622, acc = 0.96
[Train] Batch ID = 31370, loss = 0.00334863, acc = 1.0
[Validation] Batch ID = 31370, loss = 0.0282145, acc = 1.0
[Train] Batch ID = 31380, loss = 0.00408889, acc = 1.0
[Validation] Batch ID = 31380, loss = 0.0378733, acc = 0.94
[Train] Batch ID = 31390, loss = 0.00345361, acc = 1.0
[Validation] Batch ID = 31390, loss = 0.0219698, acc = 1.0
[Train] Batch ID = 31400, loss = 0.00200021, acc = 1.0
[Validation] Batch ID = 31400, loss = 0.0274301, acc = 0.98
[Train] Batch ID = 31410, loss = 0.00186481, acc = 1.0
[Validation] Batch ID = 31410, loss = 0.030923, acc = 0.96
[Train] Batch ID = 31420, loss = 0.0025669, acc = 1.0
[Validation] Batch ID = 31420, loss = 0.0149037, acc = 0.98
[Train] Batch ID = 31430, loss = 0.00234606, acc = 1.0
[Validation] Batch ID = 31430, loss = 0.0197291, acc = 1.0
[Train] Batch ID = 31440, loss = 0.00203573, acc = 1.0
[Validation] Batch ID = 31440, loss = 0.0255656, acc = 0.98
[Train] Batch ID = 31450, loss = 0.00294161, acc = 1.0
[Validation] Batch ID = 31450, loss = 0.01591, acc = 1.0
[Train] Batch ID = 31460, loss = 0.00601573, acc = 1.0
[Validation] Batch ID = 31460, loss = 0.0287948, acc = 0.98
[Train] Batch ID = 31470, loss = 0.00508016, acc = 1.0
[Validation] Batch ID = 31470, loss = 0.026645, acc = 0.98
[Train] Batch ID = 31480, loss = 0.00196063, acc = 1.0
[Validation] Batch ID = 31480, loss = 0.0304203, acc = 0.96
[Train] Batch ID = 31490, loss = 0.00179898, acc = 1.0
[Validation] Batch ID = 31490, loss = 0.0220754, acc = 0.98
[Train] Batch ID = 31500, loss = 0.00227282, acc = 1.0
[Validation] Batch ID = 31500, loss = 0.0185636, acc = 1.0
[Train] Batch ID = 31510, loss = 0.000770672, acc = 1.0
[Validation] Batch ID = 31510, loss = 0.0710147, acc = 0.92
[Train] Batch ID = 31520, loss = 0.00240887, acc = 1.0
[Validation] Batch ID = 31520, loss = 0.0183172, acc = 1.0
[Train] Batch ID = 31530, loss = 0.00145106, acc = 1.0
[Validation] Batch ID = 31530, loss = 0.028365, acc = 0.98
[Train] Batch ID = 31540, loss = 0.00106641, acc = 1.0
[Validation] Batch ID = 31540, loss = 0.0219807, acc = 0.96
[Train] Batch ID = 31550, loss = 0.199072, acc = 0.86
[Validation] Batch ID = 31550, loss = 0.0395239, acc = 0.98
[Train] Batch ID = 31560, loss = 0.00292863, acc = 1.0
[Validation] Batch ID = 31560, loss = 0.03267, acc = 0.98
[Train] Batch ID = 31570, loss = 0.250853, acc = 0.7
[Validation] Batch ID = 31570, loss = 0.0377817, acc = 0.98
[Train] Batch ID = 31580, loss = 0.00391347, acc = 1.0
[Validation] Batch ID = 31580, loss = 0.030578, acc = 0.98
[Train] Batch ID = 31590, loss = 0.00424812, acc = 1.0
[Validation] Batch ID = 31590, loss = 0.0219569, acc = 1.0
[Train] Batch ID = 31600, loss = 0.00288475, acc = 1.0
[Validation] Batch ID = 31600, loss = 0.052804, acc = 0.96
[Train] Batch ID = 31610, loss = 0.00174762, acc = 1.0
[Validation] Batch ID = 31610, loss = 0.021121, acc = 0.98
[Train] Batch ID = 31620, loss = 0.00347886, acc = 1.0
[Validation] Batch ID = 31620, loss = 0.0134904, acc = 1.0
[Train] Batch ID = 31630, loss = 0.00147968, acc = 1.0
[Validation] Batch ID = 31630, loss = 0.0270738, acc = 0.98
[Train] Batch ID = 31640, loss = 0.00209516, acc = 1.0
[Validation] Batch ID = 31640, loss = 0.0214039, acc = 1.0
[Train] Batch ID = 31650, loss = 0.224207, acc = 0.84
[Validation] Batch ID = 31650, loss = 0.0110585, acc = 1.0
[Train] Batch ID = 31660, loss = 0.00139218, acc = 1.0
[Validation] Batch ID = 31660, loss = 0.0202217, acc = 1.0
[Train] Batch ID = 31670, loss = 0.0010174, acc = 1.0
[Validation] Batch ID = 31670, loss = 0.0339531, acc = 0.98
[Train] Batch ID = 31680, loss = 0.00492307, acc = 1.0
[Validation] Batch ID = 31680, loss = 0.0264508, acc = 0.98
[Train] Batch ID = 31690, loss = 0.00246523, acc = 1.0
[Validation] Batch ID = 31690, loss = 0.0255473, acc = 0.98
[Train] Batch ID = 31700, loss = 0.00400027, acc = 1.0
[Validation] Batch ID = 31700, loss = 0.0270714, acc = 0.98
[Train] Batch ID = 31710, loss = 0.00133492, acc = 1.0
[Validation] Batch ID = 31710, loss = 0.0315654, acc = 0.96
[Train] Batch ID = 31720, loss = 0.00497223, acc = 1.0
[Validation] Batch ID = 31720, loss = 0.0239318, acc = 1.0
[Train] Batch ID = 31730, loss = 0.00252467, acc = 1.0
[Validation] Batch ID = 31730, loss = 0.0173167, acc = 1.0
[Train] Batch ID = 31740, loss = 0.00391987, acc = 1.0
[Validation] Batch ID = 31740, loss = 0.0176395, acc = 1.0
[Train] Batch ID = 31750, loss = 0.00195219, acc = 1.0
[Validation] Batch ID = 31750, loss = 0.0252507, acc = 1.0
[Train] Batch ID = 31760, loss = 0.00203188, acc = 1.0
[Validation] Batch ID = 31760, loss = 0.0429484, acc = 0.94
[Train] Batch ID = 31770, loss = 0.00149816, acc = 1.0
[Validation] Batch ID = 31770, loss = 0.0743951, acc = 0.88
[Train] Batch ID = 31780, loss = 0.00113559, acc = 1.0
[Validation] Batch ID = 31780, loss = 0.035306, acc = 0.98
[Train] Batch ID = 31790, loss = 0.00168533, acc = 1.0
[Validation] Batch ID = 31790, loss = 0.0157123, acc = 0.98
[Train] Batch ID = 31800, loss = 0.00204551, acc = 1.0
[Validation] Batch ID = 31800, loss = 0.0197226, acc = 1.0
[Train] Batch ID = 31810, loss = 0.00149921, acc = 1.0
[Validation] Batch ID = 31810, loss = 0.0238835, acc = 0.98
[Train] Batch ID = 31820, loss = 0.00323012, acc = 1.0
[Validation] Batch ID = 31820, loss = 0.0104428, acc = 1.0
[Train] Batch ID = 31830, loss = 0.00295867, acc = 1.0
[Validation] Batch ID = 31830, loss = 0.0397866, acc = 0.94
[Train] Batch ID = 31840, loss = 0.0016805, acc = 1.0
[Validation] Batch ID = 31840, loss = 0.0245933, acc = 0.96
[Train] Batch ID = 31850, loss = 0.0013261, acc = 1.0
[Validation] Batch ID = 31850, loss = 0.016168, acc = 0.98
[Train] Batch ID = 31860, loss = 0.00212478, acc = 1.0
[Validation] Batch ID = 31860, loss = 0.039522, acc = 0.96
[Train] Batch ID = 31870, loss = 0.00299583, acc = 1.0
[Validation] Batch ID = 31870, loss = 0.0145088, acc = 1.0
[Train] Batch ID = 31880, loss = 0.00376722, acc = 1.0
[Validation] Batch ID = 31880, loss = 0.0287992, acc = 0.98
[Train] Batch ID = 31890, loss = 0.00180234, acc = 1.0
[Validation] Batch ID = 31890, loss = 0.0359838, acc = 0.96
[Train] Batch ID = 31900, loss = 0.00139798, acc = 1.0
[Validation] Batch ID = 31900, loss = 0.0201998, acc = 1.0
[Train] Batch ID = 31910, loss = 0.00191381, acc = 1.0
[Validation] Batch ID = 31910, loss = 0.0290803, acc = 0.98
[Train] Batch ID = 31920, loss = 0.0063396, acc = 1.0
[Validation] Batch ID = 31920, loss = 0.0322938, acc = 0.98
[Train] Batch ID = 31930, loss = 0.00657362, acc = 1.0
[Validation] Batch ID = 31930, loss = 0.0325126, acc = 0.98
[Train] Batch ID = 31940, loss = 0.00666376, acc = 1.0
[Validation] Batch ID = 31940, loss = 0.0350213, acc = 0.98
[Train] Batch ID = 31950, loss = 0.00555858, acc = 1.0
[Validation] Batch ID = 31950, loss = 0.0405503, acc = 1.0
[Train] Batch ID = 31960, loss = 0.00853985, acc = 1.0
[Validation] Batch ID = 31960, loss = 0.0285326, acc = 1.0
[Train] Batch ID = 31970, loss = 0.00273717, acc = 1.0
[Validation] Batch ID = 31970, loss = 0.037582, acc = 0.94
[Train] Batch ID = 31980, loss = 0.00391666, acc = 1.0
[Validation] Batch ID = 31980, loss = 0.024414, acc = 0.98
[Train] Batch ID = 31990, loss = 0.00195356, acc = 1.0
[Validation] Batch ID = 31990, loss = 0.0190577, acc = 1.0
[Train] Batch ID = 32000, loss = 0.00328198, acc = 1.0
[Validation] Batch ID = 32000, loss = 0.0251426, acc = 1.0
Evaluate full validation dataset ...
Current loss: 0.0283315 Best loss: 0.0281227
[TOTAL Validation] Batch ID = 32000, loss = 0.0283315, acc = 0.980498866213
Augmented Factor = 0.030594122838806304
[Train] Batch ID = 32010, loss = 0.00244792, acc = 1.0
[Validation] Batch ID = 32010, loss = 0.0152536, acc = 1.0
[Train] Batch ID = 32020, loss = 0.00539285, acc = 1.0
[Validation] Batch ID = 32020, loss = 0.0192728, acc = 1.0
[Train] Batch ID = 32030, loss = 0.00254554, acc = 1.0
[Validation] Batch ID = 32030, loss = 0.0483486, acc = 0.94
[Train] Batch ID = 32040, loss = 0.226445, acc = 0.78
[Validation] Batch ID = 32040, loss = 0.0241564, acc = 0.98
[Train] Batch ID = 32050, loss = 0.00198244, acc = 1.0
[Validation] Batch ID = 32050, loss = 0.0288919, acc = 0.98
[Train] Batch ID = 32060, loss = 0.00143583, acc = 1.0
[Validation] Batch ID = 32060, loss = 0.0305794, acc = 0.96
[Train] Batch ID = 32070, loss = 0.00369631, acc = 1.0
[Validation] Batch ID = 32070, loss = 0.0632883, acc = 0.96
[Train] Batch ID = 32080, loss = 0.00326873, acc = 1.0
[Validation] Batch ID = 32080, loss = 0.0547151, acc = 0.96
[Train] Batch ID = 32090, loss = 0.00352583, acc = 1.0
[Validation] Batch ID = 32090, loss = 0.0115315, acc = 1.0
[Train] Batch ID = 32100, loss = 0.00337912, acc = 1.0
[Validation] Batch ID = 32100, loss = 0.0278435, acc = 0.98
[Train] Batch ID = 32110, loss = 0.00183454, acc = 1.0
[Validation] Batch ID = 32110, loss = 0.0478019, acc = 0.94
[Train] Batch ID = 32120, loss = 0.00186462, acc = 1.0
[Validation] Batch ID = 32120, loss = 0.0230001, acc = 1.0
[Train] Batch ID = 32130, loss = 0.00245284, acc = 1.0
[Validation] Batch ID = 32130, loss = 0.021992, acc = 0.98
[Train] Batch ID = 32140, loss = 0.0015283, acc = 1.0
[Validation] Batch ID = 32140, loss = 0.0171926, acc = 0.98
[Train] Batch ID = 32150, loss = 0.00198823, acc = 1.0
[Validation] Batch ID = 32150, loss = 0.0378377, acc = 0.94
[Train] Batch ID = 32160, loss = 0.00194967, acc = 1.0
[Validation] Batch ID = 32160, loss = 0.0196612, acc = 1.0
[Train] Batch ID = 32170, loss = 0.000975529, acc = 1.0
[Validation] Batch ID = 32170, loss = 0.0182886, acc = 0.96
[Train] Batch ID = 32180, loss = 0.00184632, acc = 1.0
[Validation] Batch ID = 32180, loss = 0.0181237, acc = 1.0
[Train] Batch ID = 32190, loss = 0.00116337, acc = 1.0
[Validation] Batch ID = 32190, loss = 0.0218746, acc = 0.98
[Train] Batch ID = 32200, loss = 0.00163323, acc = 1.0
[Validation] Batch ID = 32200, loss = 0.0175637, acc = 1.0
[Train] Batch ID = 32210, loss = 0.000977775, acc = 1.0
[Validation] Batch ID = 32210, loss = 0.0297615, acc = 1.0
[Train] Batch ID = 32220, loss = 0.00463468, acc = 1.0
[Validation] Batch ID = 32220, loss = 0.0406702, acc = 0.94
[Train] Batch ID = 32230, loss = 0.00296435, acc = 1.0
[Validation] Batch ID = 32230, loss = 0.0184173, acc = 0.98
[Train] Batch ID = 32240, loss = 0.0023784, acc = 1.0
[Validation] Batch ID = 32240, loss = 0.0287957, acc = 0.98
[Train] Batch ID = 32250, loss = 0.00222009, acc = 1.0
[Validation] Batch ID = 32250, loss = 0.0515997, acc = 0.94
[Train] Batch ID = 32260, loss = 0.00246799, acc = 1.0
[Validation] Batch ID = 32260, loss = 0.0400675, acc = 0.98
[Train] Batch ID = 32270, loss = 0.00137399, acc = 1.0
[Validation] Batch ID = 32270, loss = 0.0458705, acc = 0.94
[Train] Batch ID = 32280, loss = 0.00309487, acc = 1.0
[Validation] Batch ID = 32280, loss = 0.0551574, acc = 0.94
[Train] Batch ID = 32290, loss = 0.00121884, acc = 1.0
[Validation] Batch ID = 32290, loss = 0.0290543, acc = 0.96
[Train] Batch ID = 32300, loss = 0.00221107, acc = 1.0
[Validation] Batch ID = 32300, loss = 0.0138598, acc = 1.0
[Train] Batch ID = 32310, loss = 0.000732373, acc = 1.0
[Validation] Batch ID = 32310, loss = 0.017209, acc = 0.98
[Train] Batch ID = 32320, loss = 0.00127065, acc = 1.0
[Validation] Batch ID = 32320, loss = 0.0153215, acc = 1.0
[Train] Batch ID = 32330, loss = 0.00126636, acc = 1.0
[Validation] Batch ID = 32330, loss = 0.0272918, acc = 0.98
[Train] Batch ID = 32340, loss = 0.00271425, acc = 1.0
[Validation] Batch ID = 32340, loss = 0.054351, acc = 0.94
[Train] Batch ID = 32350, loss = 0.00198749, acc = 1.0
[Validation] Batch ID = 32350, loss = 0.0367771, acc = 1.0
[Train] Batch ID = 32360, loss = 0.00293163, acc = 1.0
[Validation] Batch ID = 32360, loss = 0.0244586, acc = 1.0
[Train] Batch ID = 32370, loss = 0.00397864, acc = 1.0
[Validation] Batch ID = 32370, loss = 0.0140845, acc = 1.0
[Train] Batch ID = 32380, loss = 0.00140013, acc = 1.0
[Validation] Batch ID = 32380, loss = 0.0518198, acc = 0.96
[Train] Batch ID = 32390, loss = 0.000612135, acc = 1.0
[Validation] Batch ID = 32390, loss = 0.0161579, acc = 0.98
[Train] Batch ID = 32400, loss = 0.00193689, acc = 1.0
[Validation] Batch ID = 32400, loss = 0.0275207, acc = 0.98
[Train] Batch ID = 32410, loss = 0.0032033, acc = 1.0
[Validation] Batch ID = 32410, loss = 0.017851, acc = 1.0
[Train] Batch ID = 32420, loss = 0.00243046, acc = 1.0
[Validation] Batch ID = 32420, loss = 0.034153, acc = 0.96
[Train] Batch ID = 32430, loss = 0.00272799, acc = 1.0
[Validation] Batch ID = 32430, loss = 0.0262465, acc = 0.98
[Train] Batch ID = 32440, loss = 0.00196897, acc = 1.0
[Validation] Batch ID = 32440, loss = 0.0278712, acc = 0.98
[Train] Batch ID = 32450, loss = 0.000943169, acc = 1.0
[Validation] Batch ID = 32450, loss = 0.0297475, acc = 0.96
[Train] Batch ID = 32460, loss = 0.00126869, acc = 1.0
[Validation] Batch ID = 32460, loss = 0.0186871, acc = 1.0
[Train] Batch ID = 32470, loss = 0.00138185, acc = 1.0
[Validation] Batch ID = 32470, loss = 0.0250948, acc = 0.98
[Train] Batch ID = 32480, loss = 0.00326513, acc = 1.0
[Validation] Batch ID = 32480, loss = 0.030942, acc = 0.96
[Train] Batch ID = 32490, loss = 0.00252428, acc = 1.0
[Validation] Batch ID = 32490, loss = 0.0343268, acc = 0.98
[Train] Batch ID = 32500, loss = 0.00202878, acc = 1.0
[Validation] Batch ID = 32500, loss = 0.0125569, acc = 1.0
[Train] Batch ID = 32510, loss = 0.00248645, acc = 1.0
[Validation] Batch ID = 32510, loss = 0.0134091, acc = 1.0
[Train] Batch ID = 32520, loss = 0.00168562, acc = 1.0
[Validation] Batch ID = 32520, loss = 0.0231548, acc = 0.96
[Train] Batch ID = 32530, loss = 0.00160326, acc = 1.0
[Validation] Batch ID = 32530, loss = 0.00875802, acc = 1.0
[Train] Batch ID = 32540, loss = 0.000880266, acc = 1.0
[Validation] Batch ID = 32540, loss = 0.0305853, acc = 0.96
[Train] Batch ID = 32550, loss = 0.00255616, acc = 1.0
[Validation] Batch ID = 32550, loss = 0.0271652, acc = 0.98
[Train] Batch ID = 32560, loss = 0.00297306, acc = 1.0
[Validation] Batch ID = 32560, loss = 0.0193047, acc = 1.0
[Train] Batch ID = 32570, loss = 0.00274726, acc = 1.0
[Validation] Batch ID = 32570, loss = 0.0185353, acc = 0.98
[Train] Batch ID = 32580, loss = 0.00194632, acc = 1.0
[Validation] Batch ID = 32580, loss = 0.0304191, acc = 0.96
[Train] Batch ID = 32590, loss = 0.00162661, acc = 1.0
[Validation] Batch ID = 32590, loss = 0.0319835, acc = 0.98
[Train] Batch ID = 32600, loss = 0.00161296, acc = 1.0
[Validation] Batch ID = 32600, loss = 0.01074, acc = 1.0
[Train] Batch ID = 32610, loss = 0.00329993, acc = 1.0
[Validation] Batch ID = 32610, loss = 0.0157735, acc = 1.0
[Train] Batch ID = 32620, loss = 0.00941771, acc = 1.0
[Validation] Batch ID = 32620, loss = 0.01756, acc = 1.0
[Train] Batch ID = 32630, loss = 0.0092046, acc = 1.0
[Validation] Batch ID = 32630, loss = 0.0369092, acc = 1.0
[Train] Batch ID = 32640, loss = 0.00188782, acc = 1.0
[Validation] Batch ID = 32640, loss = 0.00659924, acc = 1.0
[Train] Batch ID = 32650, loss = 0.00166541, acc = 1.0
[Validation] Batch ID = 32650, loss = 0.0212478, acc = 0.98
[Train] Batch ID = 32660, loss = 0.000854403, acc = 1.0
[Validation] Batch ID = 32660, loss = 0.0254204, acc = 0.98
[Train] Batch ID = 32670, loss = 0.00489171, acc = 1.0
[Validation] Batch ID = 32670, loss = 0.0227241, acc = 1.0
[Train] Batch ID = 32680, loss = 0.00388071, acc = 1.0
[Validation] Batch ID = 32680, loss = 0.0139344, acc = 1.0
[Train] Batch ID = 32690, loss = 0.00205495, acc = 1.0
[Validation] Batch ID = 32690, loss = 0.0117917, acc = 1.0
[Train] Batch ID = 32700, loss = 0.00199648, acc = 1.0
[Validation] Batch ID = 32700, loss = 0.0321297, acc = 0.96
[Train] Batch ID = 32710, loss = 0.00142083, acc = 1.0
[Validation] Batch ID = 32710, loss = 0.0291808, acc = 0.96
[Train] Batch ID = 32720, loss = 0.000962315, acc = 1.0
[Validation] Batch ID = 32720, loss = 0.0243412, acc = 1.0
[Train] Batch ID = 32730, loss = 0.000814988, acc = 1.0
[Validation] Batch ID = 32730, loss = 0.0157139, acc = 1.0
[Train] Batch ID = 32740, loss = 0.00254767, acc = 1.0
[Validation] Batch ID = 32740, loss = 0.0278855, acc = 1.0
[Train] Batch ID = 32750, loss = 0.0018026, acc = 1.0
[Validation] Batch ID = 32750, loss = 0.0376208, acc = 0.96
[Train] Batch ID = 32760, loss = 0.00122523, acc = 1.0
[Validation] Batch ID = 32760, loss = 0.0438346, acc = 0.92
[Train] Batch ID = 32770, loss = 0.00376461, acc = 1.0
[Validation] Batch ID = 32770, loss = 0.0393185, acc = 0.98
[Train] Batch ID = 32780, loss = 0.00216467, acc = 1.0
[Validation] Batch ID = 32780, loss = 0.031257, acc = 0.98
[Train] Batch ID = 32790, loss = 0.00138312, acc = 1.0
[Validation] Batch ID = 32790, loss = 0.0150523, acc = 1.0
[Train] Batch ID = 32800, loss = 0.00215408, acc = 1.0
[Validation] Batch ID = 32800, loss = 0.0366487, acc = 0.98
[Train] Batch ID = 32810, loss = 0.00129638, acc = 1.0
[Validation] Batch ID = 32810, loss = 0.0092653, acc = 1.0
[Train] Batch ID = 32820, loss = 0.00185204, acc = 1.0
[Validation] Batch ID = 32820, loss = 0.0215562, acc = 0.98
[Train] Batch ID = 32830, loss = 0.0013449, acc = 1.0
[Validation] Batch ID = 32830, loss = 0.0446077, acc = 0.96
[Train] Batch ID = 32840, loss = 0.00127398, acc = 1.0
[Validation] Batch ID = 32840, loss = 0.00356353, acc = 1.0
[Train] Batch ID = 32850, loss = 0.00389033, acc = 1.0
[Validation] Batch ID = 32850, loss = 0.0164521, acc = 0.98
[Train] Batch ID = 32860, loss = 0.00461923, acc = 1.0
[Validation] Batch ID = 32860, loss = 0.0254456, acc = 1.0
[Train] Batch ID = 32870, loss = 0.00203537, acc = 1.0
[Validation] Batch ID = 32870, loss = 0.04042, acc = 0.96
[Train] Batch ID = 32880, loss = 0.00203483, acc = 1.0
[Validation] Batch ID = 32880, loss = 0.0234942, acc = 0.98
[Train] Batch ID = 32890, loss = 0.00187033, acc = 1.0
[Validation] Batch ID = 32890, loss = 0.0369457, acc = 0.96
[Train] Batch ID = 32900, loss = 0.0010437, acc = 1.0
[Validation] Batch ID = 32900, loss = 0.0447355, acc = 0.96
[Train] Batch ID = 32910, loss = 0.00304987, acc = 1.0
[Validation] Batch ID = 32910, loss = 0.0208077, acc = 0.98
[Train] Batch ID = 32920, loss = 0.002313, acc = 1.0
[Validation] Batch ID = 32920, loss = 0.0433858, acc = 0.96
[Train] Batch ID = 32930, loss = 0.00103577, acc = 1.0
[Validation] Batch ID = 32930, loss = 0.0121091, acc = 1.0
[Train] Batch ID = 32940, loss = 0.00477809, acc = 1.0
[Validation] Batch ID = 32940, loss = 0.0383068, acc = 0.96
[Train] Batch ID = 32950, loss = 0.000994055, acc = 1.0
[Validation] Batch ID = 32950, loss = 0.0133046, acc = 1.0
[Train] Batch ID = 32960, loss = 0.00215455, acc = 1.0
[Validation] Batch ID = 32960, loss = 0.0466382, acc = 0.94
[Train] Batch ID = 32970, loss = 0.00113158, acc = 1.0
[Validation] Batch ID = 32970, loss = 0.0266435, acc = 0.98
[Train] Batch ID = 32980, loss = 0.000771765, acc = 1.0
[Validation] Batch ID = 32980, loss = 0.0358519, acc = 0.98
[Train] Batch ID = 32990, loss = 0.000754133, acc = 1.0
[Validation] Batch ID = 32990, loss = 0.00959618, acc = 1.0
[Train] Batch ID = 33000, loss = 0.00288395, acc = 1.0
[Validation] Batch ID = 33000, loss = 0.0116783, acc = 1.0
Evaluate full validation dataset ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Saving model ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Current loss: 0.0279286 Best loss: 0.0281227
[TOTAL Validation] Batch ID = 33000, loss = 0.0279286, acc = 0.977777777778
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Model successfully saved here: outputs/checkpoints/c1s_9_c1n_256_c2s_6_c2n_64_c2d_0.7_c1vl_16_c1s_5_c1nf_16_c2vl_32_lr_0.0001_rs_1--TrafficSign--1510487290.423481
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Augmented Factor = 0.027534710554925675
[Train] Batch ID = 33010, loss = 0.00181849, acc = 1.0
[Validation] Batch ID = 33010, loss = 0.0340514, acc = 0.98
[Train] Batch ID = 33020, loss = 0.00325495, acc = 1.0
[Validation] Batch ID = 33020, loss = 0.0228029, acc = 0.98
[Train] Batch ID = 33030, loss = 0.00318333, acc = 1.0
[Validation] Batch ID = 33030, loss = 0.0273975, acc = 1.0
[Train] Batch ID = 33040, loss = 0.00121912, acc = 1.0
[Validation] Batch ID = 33040, loss = 0.018543, acc = 1.0
[Train] Batch ID = 33050, loss = 0.00053879, acc = 1.0
[Validation] Batch ID = 33050, loss = 0.0185162, acc = 1.0
[Train] Batch ID = 33060, loss = 0.00249961, acc = 1.0
[Validation] Batch ID = 33060, loss = 0.0175863, acc = 0.98
[Train] Batch ID = 33070, loss = 0.00226629, acc = 1.0
[Validation] Batch ID = 33070, loss = 0.00575258, acc = 1.0
[Train] Batch ID = 33080, loss = 0.00122987, acc = 1.0
[Validation] Batch ID = 33080, loss = 0.0185106, acc = 0.98
[Train] Batch ID = 33090, loss = 0.00130267, acc = 1.0
[Validation] Batch ID = 33090, loss = 0.0171537, acc = 1.0
[Train] Batch ID = 33100, loss = 0.000840497, acc = 1.0
[Validation] Batch ID = 33100, loss = 0.0248239, acc = 1.0
[Train] Batch ID = 33110, loss = 0.00497245, acc = 1.0
[Validation] Batch ID = 33110, loss = 0.0266441, acc = 1.0
[Train] Batch ID = 33120, loss = 0.00246843, acc = 1.0
[Validation] Batch ID = 33120, loss = 0.0120394, acc = 0.98
[Train] Batch ID = 33130, loss = 0.0030819, acc = 1.0
[Validation] Batch ID = 33130, loss = 0.013348, acc = 1.0
[Train] Batch ID = 33140, loss = 0.00110325, acc = 1.0
[Validation] Batch ID = 33140, loss = 0.0175235, acc = 1.0
[Train] Batch ID = 33150, loss = 0.00124824, acc = 1.0
[Validation] Batch ID = 33150, loss = 0.0273643, acc = 0.98
[Train] Batch ID = 33160, loss = 0.000870531, acc = 1.0
[Validation] Batch ID = 33160, loss = 0.0325356, acc = 0.96
[Train] Batch ID = 33170, loss = 0.000935222, acc = 1.0
[Validation] Batch ID = 33170, loss = 0.0186631, acc = 1.0
[Train] Batch ID = 33180, loss = 0.00160773, acc = 1.0
[Validation] Batch ID = 33180, loss = 0.0371717, acc = 0.96
[Train] Batch ID = 33190, loss = 0.000552651, acc = 1.0
[Validation] Batch ID = 33190, loss = 0.0195016, acc = 0.98
[Train] Batch ID = 33200, loss = 0.00226886, acc = 1.0
[Validation] Batch ID = 33200, loss = 0.0231467, acc = 0.98
[Train] Batch ID = 33210, loss = 0.00445881, acc = 1.0
[Validation] Batch ID = 33210, loss = 0.0258166, acc = 0.98
[Train] Batch ID = 33220, loss = 0.00281248, acc = 1.0
[Validation] Batch ID = 33220, loss = 0.0155061, acc = 1.0
[Train] Batch ID = 33230, loss = 0.00334207, acc = 1.0
[Validation] Batch ID = 33230, loss = 0.00982972, acc = 1.0
[Train] Batch ID = 33240, loss = 0.00369319, acc = 1.0
[Validation] Batch ID = 33240, loss = 0.0407696, acc = 0.98
[Train] Batch ID = 33250, loss = 0.00178102, acc = 1.0
[Validation] Batch ID = 33250, loss = 0.0148712, acc = 1.0
[Train] Batch ID = 33260, loss = 0.0019711, acc = 1.0
[Validation] Batch ID = 33260, loss = 0.0283755, acc = 0.98
[Train] Batch ID = 33270, loss = 0.00140165, acc = 1.0
[Validation] Batch ID = 33270, loss = 0.0285463, acc = 0.98
[Train] Batch ID = 33280, loss = 0.00123305, acc = 1.0
[Validation] Batch ID = 33280, loss = 0.00876212, acc = 1.0
[Train] Batch ID = 33290, loss = 0.00159225, acc = 1.0
[Validation] Batch ID = 33290, loss = 0.0250008, acc = 0.98
[Train] Batch ID = 33300, loss = 0.00171913, acc = 1.0
[Validation] Batch ID = 33300, loss = 0.0219332, acc = 0.98
[Train] Batch ID = 33310, loss = 0.00226492, acc = 1.0
[Validation] Batch ID = 33310, loss = 0.0258679, acc = 0.98
[Train] Batch ID = 33320, loss = 0.00115471, acc = 1.0
[Validation] Batch ID = 33320, loss = 0.0182495, acc = 1.0
[Train] Batch ID = 33330, loss = 0.0011099, acc = 1.0
[Validation] Batch ID = 33330, loss = 0.0129627, acc = 1.0
[Train] Batch ID = 33340, loss = 0.00114239, acc = 1.0
[Validation] Batch ID = 33340, loss = 0.0224047, acc = 0.98
[Train] Batch ID = 33350, loss = 0.00143153, acc = 1.0
[Validation] Batch ID = 33350, loss = 0.0392582, acc = 0.96
[Train] Batch ID = 33360, loss = 0.000775912, acc = 1.0
[Validation] Batch ID = 33360, loss = 0.0567734, acc = 0.96
[Train] Batch ID = 33370, loss = 0.00127811, acc = 1.0
[Validation] Batch ID = 33370, loss = 0.0158642, acc = 0.98
[Train] Batch ID = 33380, loss = 0.0021451, acc = 1.0
[Validation] Batch ID = 33380, loss = 0.00478845, acc = 1.0
[Train] Batch ID = 33390, loss = 0.00133939, acc = 1.0
[Validation] Batch ID = 33390, loss = 0.0467568, acc = 0.96
[Train] Batch ID = 33400, loss = 0.00114221, acc = 1.0
[Validation] Batch ID = 33400, loss = 0.018701, acc = 0.98
[Train] Batch ID = 33410, loss = 0.000656294, acc = 1.0
[Validation] Batch ID = 33410, loss = 0.029396, acc = 0.98
[Train] Batch ID = 33420, loss = 0.00128939, acc = 1.0
[Validation] Batch ID = 33420, loss = 0.0134015, acc = 1.0
[Train] Batch ID = 33430, loss = 0.00117163, acc = 1.0
[Validation] Batch ID = 33430, loss = 0.0122138, acc = 1.0
[Train] Batch ID = 33440, loss = 0.00219798, acc = 1.0
[Validation] Batch ID = 33440, loss = 0.0177056, acc = 1.0
[Train] Batch ID = 33450, loss = 0.00086066, acc = 1.0
[Validation] Batch ID = 33450, loss = 0.0244949, acc = 1.0
[Train] Batch ID = 33460, loss = 0.00161027, acc = 1.0
[Validation] Batch ID = 33460, loss = 0.0135184, acc = 0.98
[Train] Batch ID = 33470, loss = 0.00181402, acc = 1.0
[Validation] Batch ID = 33470, loss = 0.0469599, acc = 0.94
[Train] Batch ID = 33480, loss = 0.00222441, acc = 1.0
[Validation] Batch ID = 33480, loss = 0.0401, acc = 0.96
[Train] Batch ID = 33490, loss = 0.00267539, acc = 1.0
[Validation] Batch ID = 33490, loss = 0.0254628, acc = 0.98
[Train] Batch ID = 33500, loss = 0.00203254, acc = 1.0
[Validation] Batch ID = 33500, loss = 0.0134601, acc = 1.0
[Train] Batch ID = 33510, loss = 0.00101351, acc = 1.0
[Validation] Batch ID = 33510, loss = 0.0173526, acc = 1.0
[Train] Batch ID = 33520, loss = 0.000351228, acc = 1.0
[Validation] Batch ID = 33520, loss = 0.028063, acc = 0.98
[Train] Batch ID = 33530, loss = 0.00309073, acc = 1.0
[Validation] Batch ID = 33530, loss = 0.0241765, acc = 1.0
[Train] Batch ID = 33540, loss = 0.00135097, acc = 1.0
[Validation] Batch ID = 33540, loss = 0.0356681, acc = 0.98
[Train] Batch ID = 33550, loss = 0.000931253, acc = 1.0
[Validation] Batch ID = 33550, loss = 0.0337044, acc = 0.98
[Train] Batch ID = 33560, loss = 0.00121306, acc = 1.0
[Validation] Batch ID = 33560, loss = 0.0198492, acc = 0.98
[Train] Batch ID = 33570, loss = 0.00183575, acc = 1.0
[Validation] Batch ID = 33570, loss = 0.0261529, acc = 0.98
[Train] Batch ID = 33580, loss = 0.00537902, acc = 1.0
[Validation] Batch ID = 33580, loss = 0.0219252, acc = 1.0
[Train] Batch ID = 33590, loss = 0.00305744, acc = 1.0
[Validation] Batch ID = 33590, loss = 0.0587448, acc = 0.96
[Train] Batch ID = 33600, loss = 0.00222588, acc = 1.0
[Validation] Batch ID = 33600, loss = 0.0113798, acc = 1.0
[Train] Batch ID = 33610, loss = 0.216053, acc = 0.84
[Validation] Batch ID = 33610, loss = 0.0456582, acc = 0.96
[Train] Batch ID = 33620, loss = 0.00403571, acc = 1.0
[Validation] Batch ID = 33620, loss = 0.0358384, acc = 0.98
[Train] Batch ID = 33630, loss = 0.00245096, acc = 1.0
[Validation] Batch ID = 33630, loss = 0.0400173, acc = 0.96
[Train] Batch ID = 33640, loss = 0.00419924, acc = 1.0
[Validation] Batch ID = 33640, loss = 0.0129962, acc = 1.0
[Train] Batch ID = 33650, loss = 0.00203869, acc = 1.0
[Validation] Batch ID = 33650, loss = 0.0323964, acc = 0.98
[Train] Batch ID = 33660, loss = 0.00269876, acc = 1.0
[Validation] Batch ID = 33660, loss = 0.0328521, acc = 0.98
[Train] Batch ID = 33670, loss = 0.00179589, acc = 1.0
[Validation] Batch ID = 33670, loss = 0.068287, acc = 0.9
[Train] Batch ID = 33680, loss = 0.0016557, acc = 1.0
[Validation] Batch ID = 33680, loss = 0.036526, acc = 0.96
[Train] Batch ID = 33690, loss = 0.00080653, acc = 1.0
[Validation] Batch ID = 33690, loss = 0.0252813, acc = 0.96
[Train] Batch ID = 33700, loss = 0.000873974, acc = 1.0
[Validation] Batch ID = 33700, loss = 0.0223677, acc = 1.0
[Train] Batch ID = 33710, loss = 0.00123022, acc = 1.0
[Validation] Batch ID = 33710, loss = 0.0334933, acc = 0.96
[Train] Batch ID = 33720, loss = 0.0026075, acc = 1.0
[Validation] Batch ID = 33720, loss = 0.0388142, acc = 0.98
[Train] Batch ID = 33730, loss = 0.0014227, acc = 1.0
[Validation] Batch ID = 33730, loss = 0.0465692, acc = 1.0
[Train] Batch ID = 33740, loss = 0.00154358, acc = 1.0
[Validation] Batch ID = 33740, loss = 0.0217439, acc = 0.98
[Train] Batch ID = 33750, loss = 0.00108881, acc = 1.0
[Validation] Batch ID = 33750, loss = 0.0153538, acc = 1.0
[Train] Batch ID = 33760, loss = 0.00208851, acc = 1.0
[Validation] Batch ID = 33760, loss = 0.0187131, acc = 0.98
[Train] Batch ID = 33770, loss = 0.00230359, acc = 1.0
[Validation] Batch ID = 33770, loss = 0.0193091, acc = 0.98
[Train] Batch ID = 33780, loss = 0.00255943, acc = 1.0
[Validation] Batch ID = 33780, loss = 0.0253616, acc = 1.0
[Train] Batch ID = 33790, loss = 0.00141364, acc = 1.0
[Validation] Batch ID = 33790, loss = 0.0381494, acc = 0.94
[Train] Batch ID = 33800, loss = 0.000759173, acc = 1.0
[Validation] Batch ID = 33800, loss = 0.0206996, acc = 0.98
[Train] Batch ID = 33810, loss = 0.00153981, acc = 1.0
[Validation] Batch ID = 33810, loss = 0.0403791, acc = 0.96
[Train] Batch ID = 33820, loss = 0.00112776, acc = 1.0
[Validation] Batch ID = 33820, loss = 0.0104464, acc = 1.0
[Train] Batch ID = 33830, loss = 0.000706016, acc = 1.0
[Validation] Batch ID = 33830, loss = 0.0349083, acc = 1.0
[Train] Batch ID = 33840, loss = 0.00193746, acc = 1.0
[Validation] Batch ID = 33840, loss = 0.0152287, acc = 1.0
[Train] Batch ID = 33850, loss = 0.00201659, acc = 1.0
[Validation] Batch ID = 33850, loss = 0.0305157, acc = 0.98
[Train] Batch ID = 33860, loss = 0.000779262, acc = 1.0
[Validation] Batch ID = 33860, loss = 0.0289241, acc = 0.98
[Train] Batch ID = 33870, loss = 0.000919842, acc = 1.0
[Validation] Batch ID = 33870, loss = 0.01571, acc = 0.98
[Train] Batch ID = 33880, loss = 0.0056259, acc = 1.0
[Validation] Batch ID = 33880, loss = 0.0336432, acc = 0.96
[Train] Batch ID = 33890, loss = 0.00305266, acc = 1.0
[Validation] Batch ID = 33890, loss = 0.0531919, acc = 0.96
[Train] Batch ID = 33900, loss = 0.00429765, acc = 1.0
[Validation] Batch ID = 33900, loss = 0.0155319, acc = 1.0
[Train] Batch ID = 33910, loss = 0.00375414, acc = 1.0
[Validation] Batch ID = 33910, loss = 0.0496658, acc = 0.96
[Train] Batch ID = 33920, loss = 0.00597919, acc = 1.0
[Validation] Batch ID = 33920, loss = 0.0353993, acc = 0.98
[Train] Batch ID = 33930, loss = 0.00523041, acc = 1.0
[Validation] Batch ID = 33930, loss = 0.018453, acc = 1.0
[Train] Batch ID = 33940, loss = 0.00379052, acc = 1.0
[Validation] Batch ID = 33940, loss = 0.0335519, acc = 0.96
[Train] Batch ID = 33950, loss = 0.00246781, acc = 1.0
[Validation] Batch ID = 33950, loss = 0.0246614, acc = 0.98
[Train] Batch ID = 33960, loss = 0.00737513, acc = 1.0
[Validation] Batch ID = 33960, loss = 0.0202566, acc = 0.98
[Train] Batch ID = 33970, loss = 0.258969, acc = 0.78
[Validation] Batch ID = 33970, loss = 0.0498904, acc = 0.96
[Train] Batch ID = 33980, loss = 0.00358301, acc = 1.0
[Validation] Batch ID = 33980, loss = 0.0265126, acc = 0.98
[Train] Batch ID = 33990, loss = 0.00441193, acc = 1.0
[Validation] Batch ID = 33990, loss = 0.0612483, acc = 0.94
[Train] Batch ID = 34000, loss = 0.00127521, acc = 1.0
[Validation] Batch ID = 34000, loss = 0.035544, acc = 0.98
Evaluate full validation dataset ...
Current loss: 0.0281532 Best loss: 0.0279286
[TOTAL Validation] Batch ID = 34000, loss = 0.0281532, acc = 0.974376417234
Augmented Factor = 0.02478123949943311
[Train] Batch ID = 34010, loss = 0.00292716, acc = 1.0
[Validation] Batch ID = 34010, loss = 0.0388733, acc = 0.94
[Train] Batch ID = 34020, loss = 0.00390851, acc = 1.0
[Validation] Batch ID = 34020, loss = 0.0079285, acc = 1.0
[Train] Batch ID = 34030, loss = 0.214262, acc = 0.78
[Validation] Batch ID = 34030, loss = 0.054598, acc = 0.94
[Train] Batch ID = 34040, loss = 0.00420655, acc = 1.0
[Validation] Batch ID = 34040, loss = 0.0246616, acc = 0.98
[Train] Batch ID = 34050, loss = 0.00320833, acc = 1.0
[Validation] Batch ID = 34050, loss = 0.0262696, acc = 1.0
[Train] Batch ID = 34060, loss = 0.00179443, acc = 1.0
[Validation] Batch ID = 34060, loss = 0.00724466, acc = 1.0
[Train] Batch ID = 34070, loss = 0.00134016, acc = 1.0
[Validation] Batch ID = 34070, loss = 0.0265773, acc = 0.98
[Train] Batch ID = 34080, loss = 0.0022292, acc = 1.0
[Validation] Batch ID = 34080, loss = 0.00986422, acc = 1.0
[Train] Batch ID = 34090, loss = 0.00253996, acc = 1.0
[Validation] Batch ID = 34090, loss = 0.0284195, acc = 0.98
[Train] Batch ID = 34100, loss = 0.00144634, acc = 1.0
[Validation] Batch ID = 34100, loss = 0.0455917, acc = 0.96
[Train] Batch ID = 34110, loss = 0.00408443, acc = 1.0
[Validation] Batch ID = 34110, loss = 0.0470518, acc = 0.94
[Train] Batch ID = 34120, loss = 0.00180702, acc = 1.0
[Validation] Batch ID = 34120, loss = 0.0287269, acc = 0.98
[Train] Batch ID = 34130, loss = 0.00221286, acc = 1.0
[Validation] Batch ID = 34130, loss = 0.0182229, acc = 1.0
[Train] Batch ID = 34140, loss = 0.00104676, acc = 1.0
[Validation] Batch ID = 34140, loss = 0.0589918, acc = 0.96
[Train] Batch ID = 34150, loss = 0.00153778, acc = 1.0
[Validation] Batch ID = 34150, loss = 0.025807, acc = 0.96
[Train] Batch ID = 34160, loss = 0.00139048, acc = 1.0
[Validation] Batch ID = 34160, loss = 0.0254652, acc = 0.98
[Train] Batch ID = 34170, loss = 0.00108228, acc = 1.0
[Validation] Batch ID = 34170, loss = 0.024228, acc = 0.98
[Train] Batch ID = 34180, loss = 0.00138399, acc = 1.0
[Validation] Batch ID = 34180, loss = 0.0115673, acc = 1.0
[Train] Batch ID = 34190, loss = 0.000957156, acc = 1.0
[Validation] Batch ID = 34190, loss = 0.0292247, acc = 1.0
[Train] Batch ID = 34200, loss = 0.00126168, acc = 1.0
[Validation] Batch ID = 34200, loss = 0.0266125, acc = 0.98
[Train] Batch ID = 34210, loss = 0.00107253, acc = 1.0
[Validation] Batch ID = 34210, loss = 0.0177075, acc = 1.0
[Train] Batch ID = 34220, loss = 0.00158458, acc = 1.0
[Validation] Batch ID = 34220, loss = 0.0250548, acc = 1.0
[Train] Batch ID = 34230, loss = 0.0028385, acc = 1.0
[Validation] Batch ID = 34230, loss = 0.0099975, acc = 1.0
[Train] Batch ID = 34240, loss = 0.00333945, acc = 1.0
[Validation] Batch ID = 34240, loss = 0.015042, acc = 1.0
[Train] Batch ID = 34250, loss = 0.00107485, acc = 1.0
[Validation] Batch ID = 34250, loss = 0.054031, acc = 0.9
[Train] Batch ID = 34260, loss = 0.00162134, acc = 1.0
[Validation] Batch ID = 34260, loss = 0.0463529, acc = 0.96
[Train] Batch ID = 34270, loss = 0.00232209, acc = 1.0
[Validation] Batch ID = 34270, loss = 0.0213975, acc = 0.98
[Train] Batch ID = 34280, loss = 0.00206215, acc = 1.0
[Validation] Batch ID = 34280, loss = 0.0232347, acc = 1.0
[Train] Batch ID = 34290, loss = 0.00403854, acc = 1.0
[Validation] Batch ID = 34290, loss = 0.0474341, acc = 0.94
[Train] Batch ID = 34300, loss = 0.00318019, acc = 1.0
[Validation] Batch ID = 34300, loss = 0.0267329, acc = 1.0
[Train] Batch ID = 34310, loss = 0.000890194, acc = 1.0
[Validation] Batch ID = 34310, loss = 0.0168448, acc = 1.0
[Train] Batch ID = 34320, loss = 0.0016286, acc = 1.0
[Validation] Batch ID = 34320, loss = 0.0243907, acc = 0.98
[Train] Batch ID = 34330, loss = 0.00374931, acc = 1.0
[Validation] Batch ID = 34330, loss = 0.044567, acc = 0.92
[Train] Batch ID = 34340, loss = 0.00427511, acc = 1.0
[Validation] Batch ID = 34340, loss = 0.0267493, acc = 0.98
[Train] Batch ID = 34350, loss = 0.00228432, acc = 1.0
[Validation] Batch ID = 34350, loss = 0.0195777, acc = 0.98
[Train] Batch ID = 34360, loss = 0.00170838, acc = 1.0
[Validation] Batch ID = 34360, loss = 0.0147028, acc = 1.0
[Train] Batch ID = 34370, loss = 0.00405182, acc = 1.0
[Validation] Batch ID = 34370, loss = 0.0135615, acc = 1.0
[Train] Batch ID = 34380, loss = 0.00274036, acc = 1.0
[Validation] Batch ID = 34380, loss = 0.0360181, acc = 0.96
[Train] Batch ID = 34390, loss = 0.00214647, acc = 1.0
[Validation] Batch ID = 34390, loss = 0.0267034, acc = 1.0
[Train] Batch ID = 34400, loss = 0.00217682, acc = 1.0
[Validation] Batch ID = 34400, loss = 0.0277916, acc = 0.98
[Train] Batch ID = 34410, loss = 0.00205903, acc = 1.0
[Validation] Batch ID = 34410, loss = 0.0168659, acc = 0.98
[Train] Batch ID = 34420, loss = 0.00129326, acc = 1.0
[Validation] Batch ID = 34420, loss = 0.0388039, acc = 0.96
[Train] Batch ID = 34430, loss = 0.000940373, acc = 1.0
[Validation] Batch ID = 34430, loss = 0.00654498, acc = 1.0
[Train] Batch ID = 34440, loss = 0.00165389, acc = 1.0
[Validation] Batch ID = 34440, loss = 0.0258308, acc = 0.96
[Train] Batch ID = 34450, loss = 0.000799451, acc = 1.0
[Validation] Batch ID = 34450, loss = 0.0224393, acc = 0.98
[Train] Batch ID = 34460, loss = 0.0012742, acc = 1.0
[Validation] Batch ID = 34460, loss = 0.0368613, acc = 0.96
[Train] Batch ID = 34470, loss = 0.00241067, acc = 1.0
[Validation] Batch ID = 34470, loss = 0.0621379, acc = 0.92
[Train] Batch ID = 34480, loss = 0.00240353, acc = 1.0
[Validation] Batch ID = 34480, loss = 0.0251606, acc = 0.98
[Train] Batch ID = 34490, loss = 0.00104062, acc = 1.0
[Validation] Batch ID = 34490, loss = 0.0313245, acc = 0.98
[Train] Batch ID = 34500, loss = 0.00123432, acc = 1.0
[Validation] Batch ID = 34500, loss = 0.0399166, acc = 0.94
[Train] Batch ID = 34510, loss = 0.00264213, acc = 1.0
[Validation] Batch ID = 34510, loss = 0.0418553, acc = 0.96
[Train] Batch ID = 34520, loss = 0.00286723, acc = 1.0
[Validation] Batch ID = 34520, loss = 0.020106, acc = 1.0
[Train] Batch ID = 34530, loss = 0.000727647, acc = 1.0
[Validation] Batch ID = 34530, loss = 0.0168686, acc = 0.98
[Train] Batch ID = 34540, loss = 0.00105633, acc = 1.0
[Validation] Batch ID = 34540, loss = 0.01112, acc = 1.0
[Train] Batch ID = 34550, loss = 0.0011426, acc = 1.0
[Validation] Batch ID = 34550, loss = 0.0230898, acc = 0.98
[Train] Batch ID = 34560, loss = 0.00202895, acc = 1.0
[Validation] Batch ID = 34560, loss = 0.0362619, acc = 0.96
[Train] Batch ID = 34570, loss = 0.205977, acc = 0.88
[Validation] Batch ID = 34570, loss = 0.0313396, acc = 0.98
[Train] Batch ID = 34580, loss = 0.00168833, acc = 1.0
[Validation] Batch ID = 34580, loss = 0.0361696, acc = 0.98
[Train] Batch ID = 34590, loss = 0.00191977, acc = 1.0
[Validation] Batch ID = 34590, loss = 0.0214165, acc = 1.0
[Train] Batch ID = 34600, loss = 0.000828731, acc = 1.0
[Validation] Batch ID = 34600, loss = 0.0237738, acc = 0.98
[Train] Batch ID = 34610, loss = 0.00225998, acc = 1.0
[Validation] Batch ID = 34610, loss = 0.0436404, acc = 0.96
[Train] Batch ID = 34620, loss = 0.00321665, acc = 1.0
[Validation] Batch ID = 34620, loss = 0.0136035, acc = 1.0
[Train] Batch ID = 34630, loss = 0.00378405, acc = 1.0
[Validation] Batch ID = 34630, loss = 0.0248081, acc = 1.0
[Train] Batch ID = 34640, loss = 0.00346752, acc = 1.0
[Validation] Batch ID = 34640, loss = 0.0154217, acc = 0.98
[Train] Batch ID = 34650, loss = 0.00265397, acc = 1.0
[Validation] Batch ID = 34650, loss = 0.0140412, acc = 1.0
[Train] Batch ID = 34660, loss = 0.176497, acc = 0.88
[Validation] Batch ID = 34660, loss = 0.00914493, acc = 1.0
[Train] Batch ID = 34670, loss = 0.00544764, acc = 1.0
[Validation] Batch ID = 34670, loss = 0.0423473, acc = 0.96
[Train] Batch ID = 34680, loss = 0.0112335, acc = 1.0
[Validation] Batch ID = 34680, loss = 0.0327307, acc = 0.98
[Train] Batch ID = 34690, loss = 0.280758, acc = 0.68
[Validation] Batch ID = 34690, loss = 0.0364617, acc = 0.98
[Train] Batch ID = 34700, loss = 0.00217996, acc = 1.0
[Validation] Batch ID = 34700, loss = 0.0302443, acc = 0.98
[Train] Batch ID = 34710, loss = 0.00427503, acc = 1.0
[Validation] Batch ID = 34710, loss = 0.0164207, acc = 1.0
[Train] Batch ID = 34720, loss = 0.00319668, acc = 1.0
[Validation] Batch ID = 34720, loss = 0.0257829, acc = 0.98
[Train] Batch ID = 34730, loss = 0.00244617, acc = 1.0
[Validation] Batch ID = 34730, loss = 0.0491925, acc = 0.96
[Train] Batch ID = 34740, loss = 0.00130755, acc = 1.0
[Validation] Batch ID = 34740, loss = 0.0159836, acc = 1.0
[Train] Batch ID = 34750, loss = 0.000922704, acc = 1.0
[Validation] Batch ID = 34750, loss = 0.0202928, acc = 0.98
[Train] Batch ID = 34760, loss = 0.00113312, acc = 1.0
[Validation] Batch ID = 34760, loss = 0.0267652, acc = 0.98
[Train] Batch ID = 34770, loss = 0.00113025, acc = 1.0
[Validation] Batch ID = 34770, loss = 0.0303798, acc = 0.98
[Train] Batch ID = 34780, loss = 0.00107034, acc = 1.0
[Validation] Batch ID = 34780, loss = 0.0085439, acc = 1.0
[Train] Batch ID = 34790, loss = 0.000568644, acc = 1.0
[Validation] Batch ID = 34790, loss = 0.0381623, acc = 0.98
[Train] Batch ID = 34800, loss = 0.000406391, acc = 1.0
[Validation] Batch ID = 34800, loss = 0.041879, acc = 0.96
[Train] Batch ID = 34810, loss = 0.000527877, acc = 1.0
[Validation] Batch ID = 34810, loss = 0.0153544, acc = 1.0
[Train] Batch ID = 34820, loss = 0.00124814, acc = 1.0
[Validation] Batch ID = 34820, loss = 0.022132, acc = 0.98
[Train] Batch ID = 34830, loss = 0.00131949, acc = 1.0
[Validation] Batch ID = 34830, loss = 0.0181519, acc = 0.98
[Train] Batch ID = 34840, loss = 0.00059383, acc = 1.0
[Validation] Batch ID = 34840, loss = 0.0282374, acc = 0.98
[Train] Batch ID = 34850, loss = 0.00164318, acc = 1.0
[Validation] Batch ID = 34850, loss = 0.0201427, acc = 1.0
[Train] Batch ID = 34860, loss = 0.00267948, acc = 1.0
[Validation] Batch ID = 34860, loss = 0.01531, acc = 1.0
[Train] Batch ID = 34870, loss = 0.00182316, acc = 1.0
[Validation] Batch ID = 34870, loss = 0.0642087, acc = 0.94
[Train] Batch ID = 34880, loss = 0.0020084, acc = 1.0
[Validation] Batch ID = 34880, loss = 0.0181483, acc = 1.0
[Train] Batch ID = 34890, loss = 0.00117665, acc = 1.0
[Validation] Batch ID = 34890, loss = 0.0181139, acc = 0.98
[Train] Batch ID = 34900, loss = 0.000585932, acc = 1.0
[Validation] Batch ID = 34900, loss = 0.0299241, acc = 0.98
[Train] Batch ID = 34910, loss = 0.00195954, acc = 1.0
[Validation] Batch ID = 34910, loss = 0.0415075, acc = 0.96
[Train] Batch ID = 34920, loss = 0.000746637, acc = 1.0
[Validation] Batch ID = 34920, loss = 0.0228915, acc = 0.98
[Train] Batch ID = 34930, loss = 0.00301906, acc = 1.0
[Validation] Batch ID = 34930, loss = 0.0226889, acc = 1.0
[Train] Batch ID = 34940, loss = 0.00361435, acc = 1.0
[Validation] Batch ID = 34940, loss = 0.0203312, acc = 1.0
[Train] Batch ID = 34950, loss = 0.0013223, acc = 1.0
[Validation] Batch ID = 34950, loss = 0.0347867, acc = 0.96
[Train] Batch ID = 34960, loss = 0.00272004, acc = 1.0
[Validation] Batch ID = 34960, loss = 0.016318, acc = 1.0
[Train] Batch ID = 34970, loss = 0.00154643, acc = 1.0
[Validation] Batch ID = 34970, loss = 0.0209945, acc = 0.98
[Train] Batch ID = 34980, loss = 0.00342527, acc = 1.0
[Validation] Batch ID = 34980, loss = 0.0467939, acc = 0.94
[Train] Batch ID = 34990, loss = 0.00251763, acc = 1.0
[Validation] Batch ID = 34990, loss = 0.0196573, acc = 1.0
[Train] Batch ID = 35000, loss = 0.00489313, acc = 1.0
[Validation] Batch ID = 35000, loss = 0.0346506, acc = 0.98
Evaluate full validation dataset ...
Current loss: 0.0338471 Best loss: 0.0279286
[TOTAL Validation] Batch ID = 35000, loss = 0.0338471, acc = 0.974376417234
Augmented Factor = 0.0223031155494898
[Train] Batch ID = 35010, loss = 0.00123101, acc = 1.0
[Validation] Batch ID = 35010, loss = 0.0211353, acc = 0.98
[Train] Batch ID = 35020, loss = 0.00483166, acc = 1.0
[Validation] Batch ID = 35020, loss = 0.030276, acc = 0.98
[Train] Batch ID = 35030, loss = 0.00303367, acc = 1.0
[Validation] Batch ID = 35030, loss = 0.0321597, acc = 0.96
[Train] Batch ID = 35040, loss = 0.00195591, acc = 1.0
[Validation] Batch ID = 35040, loss = 0.0105399, acc = 1.0
[Train] Batch ID = 35050, loss = 0.00064356, acc = 1.0
[Validation] Batch ID = 35050, loss = 0.0212917, acc = 0.98
[Train] Batch ID = 35060, loss = 0.00151086, acc = 1.0
[Validation] Batch ID = 35060, loss = 0.0185054, acc = 1.0
[Train] Batch ID = 35070, loss = 0.0019008, acc = 1.0
[Validation] Batch ID = 35070, loss = 0.0245975, acc = 0.98
[Train] Batch ID = 35080, loss = 0.00178826, acc = 1.0
[Validation] Batch ID = 35080, loss = 0.0149673, acc = 1.0
[Train] Batch ID = 35090, loss = 0.00141485, acc = 1.0
[Validation] Batch ID = 35090, loss = 0.0288711, acc = 0.98
[Train] Batch ID = 35100, loss = 0.00148675, acc = 1.0
[Validation] Batch ID = 35100, loss = 0.0315895, acc = 0.98
[Train] Batch ID = 35110, loss = 0.00496753, acc = 1.0
[Validation] Batch ID = 35110, loss = 0.0291774, acc = 1.0
[Train] Batch ID = 35120, loss = 0.00148082, acc = 1.0
[Validation] Batch ID = 35120, loss = 0.0237277, acc = 0.98
[Train] Batch ID = 35130, loss = 0.00146676, acc = 1.0
[Validation] Batch ID = 35130, loss = 0.0198125, acc = 1.0
[Train] Batch ID = 35140, loss = 0.00168412, acc = 1.0
[Validation] Batch ID = 35140, loss = 0.0157836, acc = 1.0
[Train] Batch ID = 35150, loss = 0.00223866, acc = 1.0
[Validation] Batch ID = 35150, loss = 0.0122051, acc = 1.0
[Train] Batch ID = 35160, loss = 0.00195233, acc = 1.0
[Validation] Batch ID = 35160, loss = 0.0115557, acc = 1.0
[Train] Batch ID = 35170, loss = 0.00185339, acc = 1.0
[Validation] Batch ID = 35170, loss = 0.032402, acc = 0.96
[Train] Batch ID = 35180, loss = 0.00139078, acc = 1.0
[Validation] Batch ID = 35180, loss = 0.0296124, acc = 0.98
[Train] Batch ID = 35190, loss = 0.00199218, acc = 1.0
[Validation] Batch ID = 35190, loss = 0.0219612, acc = 0.98
[Train] Batch ID = 35200, loss = 0.000734279, acc = 1.0
[Validation] Batch ID = 35200, loss = 0.0523639, acc = 0.96
[Train] Batch ID = 35210, loss = 0.000791422, acc = 1.0
[Validation] Batch ID = 35210, loss = 0.0186676, acc = 0.98
[Train] Batch ID = 35220, loss = 0.000668661, acc = 1.0
[Validation] Batch ID = 35220, loss = 0.0182843, acc = 1.0
[Train] Batch ID = 35230, loss = 0.00239851, acc = 1.0
[Validation] Batch ID = 35230, loss = 0.0164689, acc = 1.0
[Train] Batch ID = 35240, loss = 0.00144483, acc = 1.0
[Validation] Batch ID = 35240, loss = 0.0359894, acc = 0.96
[Train] Batch ID = 35250, loss = 0.000911718, acc = 1.0
[Validation] Batch ID = 35250, loss = 0.0228408, acc = 0.98
[Train] Batch ID = 35260, loss = 0.00181636, acc = 1.0
[Validation] Batch ID = 35260, loss = 0.0277013, acc = 0.98
[Train] Batch ID = 35270, loss = 0.00129693, acc = 1.0
[Validation] Batch ID = 35270, loss = 0.0122954, acc = 1.0
[Train] Batch ID = 35280, loss = 0.00106596, acc = 1.0
[Validation] Batch ID = 35280, loss = 0.0290187, acc = 0.96
[Train] Batch ID = 35290, loss = 0.00186773, acc = 1.0
[Validation] Batch ID = 35290, loss = 0.0259945, acc = 0.96
[Train] Batch ID = 35300, loss = 0.00165797, acc = 1.0
[Validation] Batch ID = 35300, loss = 0.0342112, acc = 0.96
[Train] Batch ID = 35310, loss = 0.00238422, acc = 1.0
[Validation] Batch ID = 35310, loss = 0.019165, acc = 1.0
[Train] Batch ID = 35320, loss = 0.00265946, acc = 1.0
[Validation] Batch ID = 35320, loss = 0.018348, acc = 1.0
[Train] Batch ID = 35330, loss = 0.00112968, acc = 1.0
[Validation] Batch ID = 35330, loss = 0.0108394, acc = 1.0
[Train] Batch ID = 35340, loss = 0.00133968, acc = 1.0
[Validation] Batch ID = 35340, loss = 0.0343262, acc = 0.98
[Train] Batch ID = 35350, loss = 0.000579713, acc = 1.0
[Validation] Batch ID = 35350, loss = 0.0472246, acc = 0.94
[Train] Batch ID = 35360, loss = 0.000474305, acc = 1.0
[Validation] Batch ID = 35360, loss = 0.0320105, acc = 0.96
[Train] Batch ID = 35370, loss = 0.00151863, acc = 1.0
[Validation] Batch ID = 35370, loss = 0.00748708, acc = 1.0
[Train] Batch ID = 35380, loss = 0.00241837, acc = 1.0
[Validation] Batch ID = 35380, loss = 0.0298927, acc = 0.98
[Train] Batch ID = 35390, loss = 0.188076, acc = 0.86
[Validation] Batch ID = 35390, loss = 0.0526109, acc = 0.92
[Train] Batch ID = 35400, loss = 0.00330111, acc = 1.0
[Validation] Batch ID = 35400, loss = 0.0161357, acc = 1.0
[Train] Batch ID = 35410, loss = 0.0028664, acc = 1.0
[Validation] Batch ID = 35410, loss = 0.0191126, acc = 1.0
[Train] Batch ID = 35420, loss = 0.00106006, acc = 1.0
[Validation] Batch ID = 35420, loss = 0.0172395, acc = 0.98
[Train] Batch ID = 35430, loss = 0.000549528, acc = 1.0
[Validation] Batch ID = 35430, loss = 0.013277, acc = 0.98
[Train] Batch ID = 35440, loss = 0.00108247, acc = 1.0
[Validation] Batch ID = 35440, loss = 0.0432458, acc = 0.94
[Train] Batch ID = 35450, loss = 0.00114345, acc = 1.0
[Validation] Batch ID = 35450, loss = 0.0327118, acc = 0.94
[Train] Batch ID = 35460, loss = 0.0014665, acc = 1.0
[Validation] Batch ID = 35460, loss = 0.0619566, acc = 0.92
[Train] Batch ID = 35470, loss = 0.000570245, acc = 1.0
[Validation] Batch ID = 35470, loss = 0.0112915, acc = 1.0
[Train] Batch ID = 35480, loss = 0.00288832, acc = 1.0
[Validation] Batch ID = 35480, loss = 0.0247959, acc = 0.98
[Train] Batch ID = 35490, loss = 0.00278684, acc = 1.0
[Validation] Batch ID = 35490, loss = 0.0375957, acc = 0.96
[Train] Batch ID = 35500, loss = 0.00255916, acc = 1.0
[Validation] Batch ID = 35500, loss = 0.0348293, acc = 0.96
[Train] Batch ID = 35510, loss = 0.219207, acc = 0.82
[Validation] Batch ID = 35510, loss = 0.00482722, acc = 1.0
[Train] Batch ID = 35520, loss = 0.00254461, acc = 1.0
[Validation] Batch ID = 35520, loss = 0.0154841, acc = 1.0
[Train] Batch ID = 35530, loss = 0.0015859, acc = 1.0
[Validation] Batch ID = 35530, loss = 0.0313105, acc = 0.96
[Train] Batch ID = 35540, loss = 0.0028022, acc = 1.0
[Validation] Batch ID = 35540, loss = 0.0300512, acc = 0.98
[Train] Batch ID = 35550, loss = 0.0009475, acc = 1.0
[Validation] Batch ID = 35550, loss = 0.0221287, acc = 1.0
[Train] Batch ID = 35560, loss = 0.0010983, acc = 1.0
[Validation] Batch ID = 35560, loss = 0.0213457, acc = 0.96
[Train] Batch ID = 35570, loss = 0.00231058, acc = 1.0
[Validation] Batch ID = 35570, loss = 0.0316365, acc = 0.98
[Train] Batch ID = 35580, loss = 0.00255997, acc = 1.0
[Validation] Batch ID = 35580, loss = 0.068434, acc = 0.92
[Train] Batch ID = 35590, loss = 0.00150198, acc = 1.0
[Validation] Batch ID = 35590, loss = 0.0297742, acc = 0.98
[Train] Batch ID = 35600, loss = 0.00116091, acc = 1.0
[Validation] Batch ID = 35600, loss = 0.00840573, acc = 1.0
[Train] Batch ID = 35610, loss = 0.0015711, acc = 1.0
[Validation] Batch ID = 35610, loss = 0.0110809, acc = 1.0
[Train] Batch ID = 35620, loss = 0.00549141, acc = 1.0
[Validation] Batch ID = 35620, loss = 0.0167908, acc = 1.0
[Train] Batch ID = 35630, loss = 0.00389095, acc = 1.0
[Validation] Batch ID = 35630, loss = 0.0517466, acc = 0.94
[Train] Batch ID = 35640, loss = 0.00257538, acc = 1.0
[Validation] Batch ID = 35640, loss = 0.0368672, acc = 0.96
[Train] Batch ID = 35650, loss = 0.00188736, acc = 1.0
[Validation] Batch ID = 35650, loss = 0.0139378, acc = 1.0
[Train] Batch ID = 35660, loss = 0.00122664, acc = 1.0
[Validation] Batch ID = 35660, loss = 0.0149245, acc = 1.0
[Train] Batch ID = 35670, loss = 0.00115179, acc = 1.0
[Validation] Batch ID = 35670, loss = 0.0401415, acc = 0.94
[Train] Batch ID = 35680, loss = 0.00113401, acc = 1.0
[Validation] Batch ID = 35680, loss = 0.0245407, acc = 1.0
[Train] Batch ID = 35690, loss = 0.001514, acc = 1.0
[Validation] Batch ID = 35690, loss = 0.0452087, acc = 0.92
[Train] Batch ID = 35700, loss = 0.000824824, acc = 1.0
[Validation] Batch ID = 35700, loss = 0.025087, acc = 0.98
[Train] Batch ID = 35710, loss = 0.00133319, acc = 1.0
[Validation] Batch ID = 35710, loss = 0.0234307, acc = 0.98
[Train] Batch ID = 35720, loss = 0.00197493, acc = 1.0
[Validation] Batch ID = 35720, loss = 0.0229535, acc = 0.98
[Train] Batch ID = 35730, loss = 0.00374448, acc = 1.0
[Validation] Batch ID = 35730, loss = 0.0337954, acc = 0.98
[Train] Batch ID = 35740, loss = 0.00343965, acc = 1.0
[Validation] Batch ID = 35740, loss = 0.0219215, acc = 0.98
[Train] Batch ID = 35750, loss = 0.00201432, acc = 1.0
[Validation] Batch ID = 35750, loss = 0.011466, acc = 1.0
[Train] Batch ID = 35760, loss = 0.00141768, acc = 1.0
[Validation] Batch ID = 35760, loss = 0.00873763, acc = 1.0
[Train] Batch ID = 35770, loss = 0.000926716, acc = 1.0
[Validation] Batch ID = 35770, loss = 0.00837433, acc = 1.0
[Train] Batch ID = 35780, loss = 0.00168031, acc = 1.0
[Validation] Batch ID = 35780, loss = 0.0322792, acc = 0.96
[Train] Batch ID = 35790, loss = 0.0014129, acc = 1.0
[Validation] Batch ID = 35790, loss = 0.0144773, acc = 0.98
[Train] Batch ID = 35800, loss = 0.00128679, acc = 1.0
[Validation] Batch ID = 35800, loss = 0.0263892, acc = 0.98
[Train] Batch ID = 35810, loss = 0.00140809, acc = 1.0
[Validation] Batch ID = 35810, loss = 0.0217168, acc = 1.0
[Train] Batch ID = 35820, loss = 0.00457105, acc = 1.0
[Validation] Batch ID = 35820, loss = 0.0217399, acc = 1.0
[Train] Batch ID = 35830, loss = 0.00135411, acc = 1.0
[Validation] Batch ID = 35830, loss = 0.0276325, acc = 0.98
[Train] Batch ID = 35840, loss = 0.0020144, acc = 1.0
[Validation] Batch ID = 35840, loss = 0.0280892, acc = 0.98
[Train] Batch ID = 35850, loss = 0.00229682, acc = 1.0
[Validation] Batch ID = 35850, loss = 0.0187131, acc = 0.98
[Train] Batch ID = 35860, loss = 0.0031632, acc = 1.0
[Validation] Batch ID = 35860, loss = 0.0141907, acc = 1.0
[Train] Batch ID = 35870, loss = 0.0016642, acc = 1.0
[Validation] Batch ID = 35870, loss = 0.039399, acc = 0.96
[Train] Batch ID = 35880, loss = 0.00201166, acc = 1.0
[Validation] Batch ID = 35880, loss = 0.0098812, acc = 1.0
[Train] Batch ID = 35890, loss = 0.00132046, acc = 1.0
[Validation] Batch ID = 35890, loss = 0.0193322, acc = 0.98
[Train] Batch ID = 35900, loss = 0.00105584, acc = 1.0
[Validation] Batch ID = 35900, loss = 0.00898944, acc = 1.0
[Train] Batch ID = 35910, loss = 0.000852348, acc = 1.0
[Validation] Batch ID = 35910, loss = 0.0090617, acc = 1.0
[Train] Batch ID = 35920, loss = 0.000753168, acc = 1.0
[Validation] Batch ID = 35920, loss = 0.0315808, acc = 0.98
[Train] Batch ID = 35930, loss = 0.00113977, acc = 1.0
[Validation] Batch ID = 35930, loss = 0.0249847, acc = 0.98
[Train] Batch ID = 35940, loss = 0.000651954, acc = 1.0
[Validation] Batch ID = 35940, loss = 0.0387029, acc = 0.94
[Train] Batch ID = 35950, loss = 0.000960406, acc = 1.0
[Validation] Batch ID = 35950, loss = 0.00776293, acc = 1.0
[Train] Batch ID = 35960, loss = 0.00253778, acc = 1.0
[Validation] Batch ID = 35960, loss = 0.0403442, acc = 0.94
[Train] Batch ID = 35970, loss = 0.00231554, acc = 1.0
[Validation] Batch ID = 35970, loss = 0.022458, acc = 0.98
[Train] Batch ID = 35980, loss = 0.00144338, acc = 1.0
[Validation] Batch ID = 35980, loss = 0.0207997, acc = 1.0
[Train] Batch ID = 35990, loss = 0.000867255, acc = 1.0
[Validation] Batch ID = 35990, loss = 0.0347783, acc = 0.96
[Train] Batch ID = 36000, loss = 0.00100862, acc = 1.0
[Validation] Batch ID = 36000, loss = 0.0304484, acc = 0.96
Evaluate full validation dataset ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Saving model ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Current loss: 0.0264652 Best loss: 0.0279286
[TOTAL Validation] Batch ID = 36000, loss = 0.0264652, acc = 0.978004535147
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Model successfully saved here: outputs/checkpoints/c1s_9_c1n_256_c2s_6_c2n_64_c2d_0.7_c1vl_16_c1s_5_c1nf_16_c2vl_32_lr_0.0001_rs_1--TrafficSign--1510487290.423481
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Augmented Factor = 0.02007280399454082
[Train] Batch ID = 36010, loss = 0.200188, acc = 0.78
[Validation] Batch ID = 36010, loss = 0.050085, acc = 0.94
[Train] Batch ID = 36020, loss = 0.00255817, acc = 1.0
[Validation] Batch ID = 36020, loss = 0.0587653, acc = 0.92
[Train] Batch ID = 36030, loss = 0.00352771, acc = 1.0
[Validation] Batch ID = 36030, loss = 0.0208967, acc = 0.98
[Train] Batch ID = 36040, loss = 0.00204748, acc = 1.0
[Validation] Batch ID = 36040, loss = 0.0359496, acc = 0.98
[Train] Batch ID = 36050, loss = 0.00096165, acc = 1.0
[Validation] Batch ID = 36050, loss = 0.023482, acc = 0.96
[Train] Batch ID = 36060, loss = 0.00224286, acc = 1.0
[Validation] Batch ID = 36060, loss = 0.0203404, acc = 1.0
[Train] Batch ID = 36070, loss = 0.000565031, acc = 1.0
[Validation] Batch ID = 36070, loss = 0.0364635, acc = 0.96
[Train] Batch ID = 36080, loss = 0.00221873, acc = 1.0
[Validation] Batch ID = 36080, loss = 0.0371938, acc = 0.94
[Train] Batch ID = 36090, loss = 0.000865876, acc = 1.0
[Validation] Batch ID = 36090, loss = 0.0301647, acc = 0.98
[Train] Batch ID = 36100, loss = 0.00114873, acc = 1.0
[Validation] Batch ID = 36100, loss = 0.0209461, acc = 1.0
[Train] Batch ID = 36110, loss = 0.0017317, acc = 1.0
[Validation] Batch ID = 36110, loss = 0.0221933, acc = 1.0
[Train] Batch ID = 36120, loss = 0.0045195, acc = 1.0
[Validation] Batch ID = 36120, loss = 0.0384292, acc = 0.98
[Train] Batch ID = 36130, loss = 0.00467786, acc = 1.0
[Validation] Batch ID = 36130, loss = 0.0307506, acc = 0.94
[Train] Batch ID = 36140, loss = 0.00114053, acc = 1.0
[Validation] Batch ID = 36140, loss = 0.0701763, acc = 0.92
[Train] Batch ID = 36150, loss = 0.000975655, acc = 1.0
[Validation] Batch ID = 36150, loss = 0.0180731, acc = 1.0
[Train] Batch ID = 36160, loss = 0.00112731, acc = 1.0
[Validation] Batch ID = 36160, loss = 0.025659, acc = 0.98
[Train] Batch ID = 36170, loss = 0.00302265, acc = 1.0
[Validation] Batch ID = 36170, loss = 0.0115467, acc = 1.0
[Train] Batch ID = 36180, loss = 0.00326234, acc = 1.0
[Validation] Batch ID = 36180, loss = 0.0200813, acc = 1.0
[Train] Batch ID = 36190, loss = 0.00400732, acc = 1.0
[Validation] Batch ID = 36190, loss = 0.0434149, acc = 0.98
[Train] Batch ID = 36200, loss = 0.00298995, acc = 1.0
[Validation] Batch ID = 36200, loss = 0.0447065, acc = 0.96
[Train] Batch ID = 36210, loss = 0.00112196, acc = 1.0
[Validation] Batch ID = 36210, loss = 0.0238598, acc = 0.98
[Train] Batch ID = 36220, loss = 0.0011598, acc = 1.0
[Validation] Batch ID = 36220, loss = 0.0158512, acc = 1.0
[Train] Batch ID = 36230, loss = 0.00127889, acc = 1.0
[Validation] Batch ID = 36230, loss = 0.0159166, acc = 0.98
[Train] Batch ID = 36240, loss = 0.000847863, acc = 1.0
[Validation] Batch ID = 36240, loss = 0.0112617, acc = 1.0
[Train] Batch ID = 36250, loss = 0.000660449, acc = 1.0
[Validation] Batch ID = 36250, loss = 0.027839, acc = 1.0
[Train] Batch ID = 36260, loss = 0.000654596, acc = 1.0
[Validation] Batch ID = 36260, loss = 0.0140631, acc = 1.0
[Train] Batch ID = 36270, loss = 0.00349554, acc = 1.0
[Validation] Batch ID = 36270, loss = 0.0327893, acc = 0.98
[Train] Batch ID = 36280, loss = 0.00145731, acc = 1.0
[Validation] Batch ID = 36280, loss = 0.0398115, acc = 0.94
[Train] Batch ID = 36290, loss = 0.00253798, acc = 1.0
[Validation] Batch ID = 36290, loss = 0.0203192, acc = 0.98
[Train] Batch ID = 36300, loss = 0.00170909, acc = 1.0
[Validation] Batch ID = 36300, loss = 0.0342698, acc = 0.96
[Train] Batch ID = 36310, loss = 0.000979109, acc = 1.0
[Validation] Batch ID = 36310, loss = 0.0152062, acc = 0.98
[Train] Batch ID = 36320, loss = 0.00123555, acc = 1.0
[Validation] Batch ID = 36320, loss = 0.0101658, acc = 1.0
[Train] Batch ID = 36330, loss = 0.00119133, acc = 1.0
[Validation] Batch ID = 36330, loss = 0.028515, acc = 0.98
[Train] Batch ID = 36340, loss = 0.000626183, acc = 1.0
[Validation] Batch ID = 36340, loss = 0.0206513, acc = 0.98
[Train] Batch ID = 36350, loss = 0.00305864, acc = 1.0
[Validation] Batch ID = 36350, loss = 0.0229075, acc = 0.98
[Train] Batch ID = 36360, loss = 0.00357254, acc = 1.0
[Validation] Batch ID = 36360, loss = 0.0134957, acc = 1.0
[Train] Batch ID = 36370, loss = 0.00248249, acc = 1.0
[Validation] Batch ID = 36370, loss = 0.0320324, acc = 1.0
[Train] Batch ID = 36380, loss = 0.00182497, acc = 1.0
[Validation] Batch ID = 36380, loss = 0.0485939, acc = 0.94
[Train] Batch ID = 36390, loss = 0.00237705, acc = 1.0
[Validation] Batch ID = 36390, loss = 0.0396345, acc = 0.98
[Train] Batch ID = 36400, loss = 0.000892917, acc = 1.0
[Validation] Batch ID = 36400, loss = 0.0135154, acc = 1.0
[Train] Batch ID = 36410, loss = 0.00112621, acc = 1.0
[Validation] Batch ID = 36410, loss = 0.0141791, acc = 1.0
[Train] Batch ID = 36420, loss = 0.0051444, acc = 1.0
[Validation] Batch ID = 36420, loss = 0.0550196, acc = 0.96
[Train] Batch ID = 36430, loss = 0.00208048, acc = 1.0
[Validation] Batch ID = 36430, loss = 0.0601402, acc = 0.96
[Train] Batch ID = 36440, loss = 0.00213177, acc = 1.0
[Validation] Batch ID = 36440, loss = 0.0205095, acc = 0.98
[Train] Batch ID = 36450, loss = 0.00440013, acc = 1.0
[Validation] Batch ID = 36450, loss = 0.0603165, acc = 0.96
[Train] Batch ID = 36460, loss = 0.00540139, acc = 1.0
[Validation] Batch ID = 36460, loss = 0.0281102, acc = 0.98
[Train] Batch ID = 36470, loss = 0.00272452, acc = 1.0
[Validation] Batch ID = 36470, loss = 0.0239488, acc = 1.0
[Train] Batch ID = 36480, loss = 0.00265926, acc = 1.0
[Validation] Batch ID = 36480, loss = 0.00841701, acc = 1.0
[Train] Batch ID = 36490, loss = 0.00151518, acc = 1.0
[Validation] Batch ID = 36490, loss = 0.0160414, acc = 0.98
[Train] Batch ID = 36500, loss = 0.00165567, acc = 1.0
[Validation] Batch ID = 36500, loss = 0.0115224, acc = 1.0
[Train] Batch ID = 36510, loss = 0.00123466, acc = 1.0
[Validation] Batch ID = 36510, loss = 0.0290231, acc = 0.98
[Train] Batch ID = 36520, loss = 0.00128063, acc = 1.0
[Validation] Batch ID = 36520, loss = 0.00632217, acc = 1.0
[Train] Batch ID = 36530, loss = 0.00397213, acc = 1.0
[Validation] Batch ID = 36530, loss = 0.0248125, acc = 0.98
[Train] Batch ID = 36540, loss = 0.00216018, acc = 1.0
[Validation] Batch ID = 36540, loss = 0.0290568, acc = 0.98
[Train] Batch ID = 36550, loss = 0.00106494, acc = 1.0
[Validation] Batch ID = 36550, loss = 0.0319098, acc = 1.0
[Train] Batch ID = 36560, loss = 0.00145958, acc = 1.0
[Validation] Batch ID = 36560, loss = 0.0399346, acc = 0.96
[Train] Batch ID = 36570, loss = 0.000718598, acc = 1.0
[Validation] Batch ID = 36570, loss = 0.0169471, acc = 1.0
[Train] Batch ID = 36580, loss = 0.00101994, acc = 1.0
[Validation] Batch ID = 36580, loss = 0.0191743, acc = 0.98
[Train] Batch ID = 36590, loss = 0.00127438, acc = 1.0
[Validation] Batch ID = 36590, loss = 0.0322477, acc = 0.96
[Train] Batch ID = 36600, loss = 0.0021684, acc = 1.0
[Validation] Batch ID = 36600, loss = 0.0439625, acc = 0.98
[Train] Batch ID = 36610, loss = 0.00154091, acc = 1.0
[Validation] Batch ID = 36610, loss = 0.0172619, acc = 1.0
[Train] Batch ID = 36620, loss = 0.00172869, acc = 1.0
[Validation] Batch ID = 36620, loss = 0.059736, acc = 0.94
[Train] Batch ID = 36630, loss = 0.00103565, acc = 1.0
[Validation] Batch ID = 36630, loss = 0.0186352, acc = 1.0
[Train] Batch ID = 36640, loss = 0.00131421, acc = 1.0
[Validation] Batch ID = 36640, loss = 0.0195324, acc = 1.0
[Train] Batch ID = 36650, loss = 0.00133124, acc = 1.0
[Validation] Batch ID = 36650, loss = 0.044695, acc = 0.94
[Train] Batch ID = 36660, loss = 0.191446, acc = 0.82
[Validation] Batch ID = 36660, loss = 0.0327608, acc = 0.96
[Train] Batch ID = 36670, loss = 0.00234586, acc = 1.0
[Validation] Batch ID = 36670, loss = 0.0416938, acc = 0.96
[Train] Batch ID = 36680, loss = 0.00355926, acc = 1.0
[Validation] Batch ID = 36680, loss = 0.0188118, acc = 1.0
[Train] Batch ID = 36690, loss = 0.00141413, acc = 1.0
[Validation] Batch ID = 36690, loss = 0.0100994, acc = 1.0
[Train] Batch ID = 36700, loss = 0.00198118, acc = 1.0
[Validation] Batch ID = 36700, loss = 0.027812, acc = 0.98
[Train] Batch ID = 36710, loss = 0.000971419, acc = 1.0
[Validation] Batch ID = 36710, loss = 0.027191, acc = 0.98
[Train] Batch ID = 36720, loss = 0.000378196, acc = 1.0
[Validation] Batch ID = 36720, loss = 0.0105049, acc = 1.0
[Train] Batch ID = 36730, loss = 0.0025604, acc = 1.0
[Validation] Batch ID = 36730, loss = 0.0169361, acc = 1.0
[Train] Batch ID = 36740, loss = 0.00218077, acc = 1.0
[Validation] Batch ID = 36740, loss = 0.0387151, acc = 0.98
[Train] Batch ID = 36750, loss = 0.00176128, acc = 1.0
[Validation] Batch ID = 36750, loss = 0.0318839, acc = 0.98
[Train] Batch ID = 36760, loss = 0.00410441, acc = 1.0
[Validation] Batch ID = 36760, loss = 0.0445748, acc = 0.96
[Train] Batch ID = 36770, loss = 0.000961732, acc = 1.0
[Validation] Batch ID = 36770, loss = 0.0351225, acc = 0.98
[Train] Batch ID = 36780, loss = 0.00447581, acc = 1.0
[Validation] Batch ID = 36780, loss = 0.0121757, acc = 1.0
[Train] Batch ID = 36790, loss = 0.0052812, acc = 1.0
[Validation] Batch ID = 36790, loss = 0.039876, acc = 0.96
[Train] Batch ID = 36800, loss = 0.00405995, acc = 1.0
[Validation] Batch ID = 36800, loss = 0.0196059, acc = 1.0
[Train] Batch ID = 36810, loss = 0.00152738, acc = 1.0
[Validation] Batch ID = 36810, loss = 0.0163322, acc = 0.98
[Train] Batch ID = 36820, loss = 0.00179688, acc = 1.0
[Validation] Batch ID = 36820, loss = 0.0159203, acc = 0.98
[Train] Batch ID = 36830, loss = 0.00164828, acc = 1.0
[Validation] Batch ID = 36830, loss = 0.0190434, acc = 0.98
[Train] Batch ID = 36840, loss = 0.0036785, acc = 1.0
[Validation] Batch ID = 36840, loss = 0.0218362, acc = 0.98
[Train] Batch ID = 36850, loss = 0.00237001, acc = 1.0
[Validation] Batch ID = 36850, loss = 0.0450192, acc = 0.94
[Train] Batch ID = 36860, loss = 0.00205953, acc = 1.0
[Validation] Batch ID = 36860, loss = 0.0202107, acc = 1.0
[Train] Batch ID = 36870, loss = 0.0019133, acc = 1.0
[Validation] Batch ID = 36870, loss = 0.0312143, acc = 0.98
[Train] Batch ID = 36880, loss = 0.00126145, acc = 1.0
[Validation] Batch ID = 36880, loss = 0.0352698, acc = 0.96
[Train] Batch ID = 36890, loss = 0.000639507, acc = 1.0
[Validation] Batch ID = 36890, loss = 0.0362391, acc = 0.92
[Train] Batch ID = 36900, loss = 0.000972909, acc = 1.0
[Validation] Batch ID = 36900, loss = 0.0265807, acc = 0.98
[Train] Batch ID = 36910, loss = 0.00166517, acc = 1.0
[Validation] Batch ID = 36910, loss = 0.0145177, acc = 0.98
[Train] Batch ID = 36920, loss = 0.000424803, acc = 1.0
[Validation] Batch ID = 36920, loss = 0.024946, acc = 0.98
[Train] Batch ID = 36930, loss = 0.00122428, acc = 1.0
[Validation] Batch ID = 36930, loss = 0.0103561, acc = 1.0
[Train] Batch ID = 36940, loss = 0.000987635, acc = 1.0
[Validation] Batch ID = 36940, loss = 0.0216528, acc = 0.96
[Train] Batch ID = 36950, loss = 0.00243964, acc = 1.0
[Validation] Batch ID = 36950, loss = 0.0215313, acc = 0.98
[Train] Batch ID = 36960, loss = 0.00213407, acc = 1.0
[Validation] Batch ID = 36960, loss = 0.0195071, acc = 1.0
[Train] Batch ID = 36970, loss = 0.00147166, acc = 1.0
[Validation] Batch ID = 36970, loss = 0.0198261, acc = 1.0
[Train] Batch ID = 36980, loss = 0.00117199, acc = 1.0
[Validation] Batch ID = 36980, loss = 0.0270078, acc = 0.98
[Train] Batch ID = 36990, loss = 0.000867529, acc = 1.0
[Validation] Batch ID = 36990, loss = 0.0206978, acc = 1.0
[Train] Batch ID = 37000, loss = 0.000824032, acc = 1.0
[Validation] Batch ID = 37000, loss = 0.0259292, acc = 0.98
Evaluate full validation dataset ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Saving model ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Current loss: 0.0254414 Best loss: 0.0264652
[TOTAL Validation] Batch ID = 37000, loss = 0.0254414, acc = 0.975510204082
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Model successfully saved here: outputs/checkpoints/c1s_9_c1n_256_c2s_6_c2n_64_c2d_0.7_c1vl_16_c1s_5_c1nf_16_c2vl_32_lr_0.0001_rs_1--TrafficSign--1510487290.423481
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Augmented Factor = 0.01806552359508674
[Train] Batch ID = 37010, loss = 0.00219439, acc = 1.0
[Validation] Batch ID = 37010, loss = 0.0213016, acc = 0.96
[Train] Batch ID = 37020, loss = 0.000328499, acc = 1.0
[Validation] Batch ID = 37020, loss = 0.0340482, acc = 0.98
[Train] Batch ID = 37030, loss = 0.000604523, acc = 1.0
[Validation] Batch ID = 37030, loss = 0.0299739, acc = 0.98
[Train] Batch ID = 37040, loss = 0.00110161, acc = 1.0
[Validation] Batch ID = 37040, loss = 0.0181824, acc = 0.98
[Train] Batch ID = 37050, loss = 0.00123481, acc = 1.0
[Validation] Batch ID = 37050, loss = 0.048744, acc = 0.96
[Train] Batch ID = 37060, loss = 0.000347122, acc = 1.0
[Validation] Batch ID = 37060, loss = 0.0270024, acc = 0.98
[Train] Batch ID = 37070, loss = 0.000961318, acc = 1.0
[Validation] Batch ID = 37070, loss = 0.0254172, acc = 0.96
[Train] Batch ID = 37080, loss = 0.000748675, acc = 1.0
[Validation] Batch ID = 37080, loss = 0.0200109, acc = 0.98
[Train] Batch ID = 37090, loss = 0.000891692, acc = 1.0
[Validation] Batch ID = 37090, loss = 0.0192072, acc = 0.98
[Train] Batch ID = 37100, loss = 0.000955008, acc = 1.0
[Validation] Batch ID = 37100, loss = 0.0302344, acc = 0.98
[Train] Batch ID = 37110, loss = 0.00153561, acc = 1.0
[Validation] Batch ID = 37110, loss = 0.0325721, acc = 1.0
[Train] Batch ID = 37120, loss = 0.000750753, acc = 1.0
[Validation] Batch ID = 37120, loss = 0.0366266, acc = 0.96
[Train] Batch ID = 37130, loss = 0.000712051, acc = 1.0
[Validation] Batch ID = 37130, loss = 0.0262635, acc = 0.98
[Train] Batch ID = 37140, loss = 0.00163962, acc = 1.0
[Validation] Batch ID = 37140, loss = 0.0275794, acc = 0.96
[Train] Batch ID = 37150, loss = 0.00433396, acc = 1.0
[Validation] Batch ID = 37150, loss = 0.035029, acc = 0.98
[Train] Batch ID = 37160, loss = 0.00381715, acc = 1.0
[Validation] Batch ID = 37160, loss = 0.0216777, acc = 0.96
[Train] Batch ID = 37170, loss = 0.00123481, acc = 1.0
[Validation] Batch ID = 37170, loss = 0.0242624, acc = 1.0
[Train] Batch ID = 37180, loss = 0.00148104, acc = 1.0
[Validation] Batch ID = 37180, loss = 0.0424997, acc = 0.94
[Train] Batch ID = 37190, loss = 0.00155893, acc = 1.0
[Validation] Batch ID = 37190, loss = 0.0222218, acc = 0.96
[Train] Batch ID = 37200, loss = 0.00170277, acc = 1.0
[Validation] Batch ID = 37200, loss = 0.0285615, acc = 0.98
[Train] Batch ID = 37210, loss = 0.00311964, acc = 1.0
[Validation] Batch ID = 37210, loss = 0.0228171, acc = 0.98
[Train] Batch ID = 37220, loss = 0.00084114, acc = 1.0
[Validation] Batch ID = 37220, loss = 0.0318931, acc = 0.96
[Train] Batch ID = 37230, loss = 0.00175938, acc = 1.0
[Validation] Batch ID = 37230, loss = 0.0100522, acc = 1.0
[Train] Batch ID = 37240, loss = 0.00308574, acc = 1.0
[Validation] Batch ID = 37240, loss = 0.016312, acc = 0.98
[Train] Batch ID = 37250, loss = 0.000713381, acc = 1.0
[Validation] Batch ID = 37250, loss = 0.0522177, acc = 0.96
[Train] Batch ID = 37260, loss = 0.000759051, acc = 1.0
[Validation] Batch ID = 37260, loss = 0.0436251, acc = 0.96
[Train] Batch ID = 37270, loss = 0.000975786, acc = 1.0
[Validation] Batch ID = 37270, loss = 0.0101251, acc = 1.0
[Train] Batch ID = 37280, loss = 0.0011086, acc = 1.0
[Validation] Batch ID = 37280, loss = 0.00910077, acc = 1.0
[Train] Batch ID = 37290, loss = 0.00200636, acc = 1.0
[Validation] Batch ID = 37290, loss = 0.0358176, acc = 0.9
[Train] Batch ID = 37300, loss = 0.00777636, acc = 1.0
[Validation] Batch ID = 37300, loss = 0.0117058, acc = 1.0
[Train] Batch ID = 37310, loss = 0.0024414, acc = 1.0
[Validation] Batch ID = 37310, loss = 0.0204751, acc = 0.98
[Train] Batch ID = 37320, loss = 0.000981288, acc = 1.0
[Validation] Batch ID = 37320, loss = 0.0188924, acc = 1.0
[Train] Batch ID = 37330, loss = 0.000897745, acc = 1.0
[Validation] Batch ID = 37330, loss = 0.0130475, acc = 1.0
[Train] Batch ID = 37340, loss = 0.00177241, acc = 1.0
[Validation] Batch ID = 37340, loss = 0.036657, acc = 0.96
[Train] Batch ID = 37350, loss = 0.000939688, acc = 1.0
[Validation] Batch ID = 37350, loss = 0.023476, acc = 0.96
[Train] Batch ID = 37360, loss = 0.00125714, acc = 1.0
[Validation] Batch ID = 37360, loss = 0.0240832, acc = 0.98
[Train] Batch ID = 37370, loss = 0.000906425, acc = 1.0
[Validation] Batch ID = 37370, loss = 0.0151605, acc = 1.0
[Train] Batch ID = 37380, loss = 0.000967521, acc = 1.0
[Validation] Batch ID = 37380, loss = 0.0304334, acc = 0.96
[Train] Batch ID = 37390, loss = 0.00121941, acc = 1.0
[Validation] Batch ID = 37390, loss = 0.0181249, acc = 0.98
[Train] Batch ID = 37400, loss = 0.00106544, acc = 1.0
[Validation] Batch ID = 37400, loss = 0.0570694, acc = 0.92
[Train] Batch ID = 37410, loss = 0.00176347, acc = 1.0
[Validation] Batch ID = 37410, loss = 0.0360286, acc = 0.96
[Train] Batch ID = 37420, loss = 0.0029126, acc = 1.0
[Validation] Batch ID = 37420, loss = 0.0353016, acc = 0.96
[Train] Batch ID = 37430, loss = 0.00301982, acc = 1.0
[Validation] Batch ID = 37430, loss = 0.0216013, acc = 1.0
[Train] Batch ID = 37440, loss = 0.00494126, acc = 1.0
[Validation] Batch ID = 37440, loss = 0.0298347, acc = 0.98
[Train] Batch ID = 37450, loss = 0.00326622, acc = 1.0
[Validation] Batch ID = 37450, loss = 0.0568239, acc = 0.98
[Train] Batch ID = 37460, loss = 0.00260797, acc = 1.0
[Validation] Batch ID = 37460, loss = 0.0284146, acc = 0.96
[Train] Batch ID = 37470, loss = 0.00109283, acc = 1.0
[Validation] Batch ID = 37470, loss = 0.0390337, acc = 0.98
[Train] Batch ID = 37480, loss = 0.0012269, acc = 1.0
[Validation] Batch ID = 37480, loss = 0.0202388, acc = 1.0
[Train] Batch ID = 37490, loss = 0.00185064, acc = 1.0
[Validation] Batch ID = 37490, loss = 0.027772, acc = 0.98
[Train] Batch ID = 37500, loss = 0.00286272, acc = 1.0
[Validation] Batch ID = 37500, loss = 0.0371534, acc = 0.98
[Train] Batch ID = 37510, loss = 0.00122545, acc = 1.0
[Validation] Batch ID = 37510, loss = 0.0218342, acc = 1.0
[Train] Batch ID = 37520, loss = 0.00177784, acc = 1.0
[Validation] Batch ID = 37520, loss = 0.0196635, acc = 0.98
[Train] Batch ID = 37530, loss = 0.00127242, acc = 1.0
[Validation] Batch ID = 37530, loss = 0.0380079, acc = 0.94
[Train] Batch ID = 37540, loss = 0.00044425, acc = 1.0
[Validation] Batch ID = 37540, loss = 0.0343205, acc = 0.96
[Train] Batch ID = 37550, loss = 0.000908291, acc = 1.0
[Validation] Batch ID = 37550, loss = 0.0288307, acc = 0.96
[Train] Batch ID = 37560, loss = 0.00121291, acc = 1.0
[Validation] Batch ID = 37560, loss = 0.0269828, acc = 1.0
[Train] Batch ID = 37570, loss = 0.000699753, acc = 1.0
[Validation] Batch ID = 37570, loss = 0.033114, acc = 0.96
[Train] Batch ID = 37580, loss = 0.000472514, acc = 1.0
[Validation] Batch ID = 37580, loss = 0.0216205, acc = 1.0
[Train] Batch ID = 37590, loss = 0.000877045, acc = 1.0
[Validation] Batch ID = 37590, loss = 0.0184613, acc = 1.0
[Train] Batch ID = 37600, loss = 0.000992497, acc = 1.0
[Validation] Batch ID = 37600, loss = 0.0194417, acc = 0.96
[Train] Batch ID = 37610, loss = 0.00095358, acc = 1.0
[Validation] Batch ID = 37610, loss = 0.0199265, acc = 0.98
[Train] Batch ID = 37620, loss = 0.000848513, acc = 1.0
[Validation] Batch ID = 37620, loss = 0.0476511, acc = 0.94
[Train] Batch ID = 37630, loss = 0.00115382, acc = 1.0
[Validation] Batch ID = 37630, loss = 0.0388899, acc = 0.94
[Train] Batch ID = 37640, loss = 0.000717152, acc = 1.0
[Validation] Batch ID = 37640, loss = 0.0392804, acc = 0.96
[Train] Batch ID = 37650, loss = 0.000750362, acc = 1.0
[Validation] Batch ID = 37650, loss = 0.0205194, acc = 0.98
[Train] Batch ID = 37660, loss = 0.00191947, acc = 1.0
[Validation] Batch ID = 37660, loss = 0.0251928, acc = 0.98
[Train] Batch ID = 37670, loss = 0.00217696, acc = 1.0
[Validation] Batch ID = 37670, loss = 0.0153992, acc = 1.0
[Train] Batch ID = 37680, loss = 0.000975817, acc = 1.0
[Validation] Batch ID = 37680, loss = 0.0231079, acc = 0.98
[Train] Batch ID = 37690, loss = 0.000572098, acc = 1.0
[Validation] Batch ID = 37690, loss = 0.0255703, acc = 0.96
[Train] Batch ID = 37700, loss = 0.00079442, acc = 1.0
[Validation] Batch ID = 37700, loss = 0.0237417, acc = 0.98
[Train] Batch ID = 37710, loss = 0.000269621, acc = 1.0
[Validation] Batch ID = 37710, loss = 0.0269557, acc = 0.98
[Train] Batch ID = 37720, loss = 0.00203224, acc = 1.0
[Validation] Batch ID = 37720, loss = 0.0248781, acc = 0.98
[Train] Batch ID = 37730, loss = 0.00110009, acc = 1.0
[Validation] Batch ID = 37730, loss = 0.0469319, acc = 0.96
[Train] Batch ID = 37740, loss = 0.000753219, acc = 1.0
[Validation] Batch ID = 37740, loss = 0.0232629, acc = 1.0
[Train] Batch ID = 37750, loss = 0.000811752, acc = 1.0
[Validation] Batch ID = 37750, loss = 0.0154835, acc = 1.0
[Train] Batch ID = 37760, loss = 0.0011162, acc = 1.0
[Validation] Batch ID = 37760, loss = 0.0184545, acc = 1.0
[Train] Batch ID = 37770, loss = 0.00100909, acc = 1.0
[Validation] Batch ID = 37770, loss = 0.0357438, acc = 0.96
[Train] Batch ID = 37780, loss = 0.000712245, acc = 1.0
[Validation] Batch ID = 37780, loss = 0.0192121, acc = 0.98
[Train] Batch ID = 37790, loss = 0.00193588, acc = 1.0
[Validation] Batch ID = 37790, loss = 0.0311035, acc = 0.98
[Train] Batch ID = 37800, loss = 0.00257869, acc = 1.0
[Validation] Batch ID = 37800, loss = 0.0499938, acc = 0.94
[Train] Batch ID = 37810, loss = 0.00265965, acc = 1.0
[Validation] Batch ID = 37810, loss = 0.0277208, acc = 0.98
[Train] Batch ID = 37820, loss = 0.00157478, acc = 1.0
[Validation] Batch ID = 37820, loss = 0.00830829, acc = 1.0
[Train] Batch ID = 37830, loss = 0.00218248, acc = 1.0
[Validation] Batch ID = 37830, loss = 0.0103641, acc = 1.0
[Train] Batch ID = 37840, loss = 0.00132101, acc = 1.0
[Validation] Batch ID = 37840, loss = 0.00902896, acc = 0.98
[Train] Batch ID = 37850, loss = 0.000503887, acc = 1.0
[Validation] Batch ID = 37850, loss = 0.00674285, acc = 1.0
[Train] Batch ID = 37860, loss = 0.000996867, acc = 1.0
[Validation] Batch ID = 37860, loss = 0.019344, acc = 0.98
[Train] Batch ID = 37870, loss = 0.00140236, acc = 1.0
[Validation] Batch ID = 37870, loss = 0.022957, acc = 0.96
[Train] Batch ID = 37880, loss = 0.000615535, acc = 1.0
[Validation] Batch ID = 37880, loss = 0.0140036, acc = 1.0
[Train] Batch ID = 37890, loss = 0.000882416, acc = 1.0
[Validation] Batch ID = 37890, loss = 0.0489776, acc = 0.92
[Train] Batch ID = 37900, loss = 0.000691616, acc = 1.0
[Validation] Batch ID = 37900, loss = 0.0249626, acc = 0.98
[Train] Batch ID = 37910, loss = 0.000303196, acc = 1.0
[Validation] Batch ID = 37910, loss = 0.0137402, acc = 1.0
[Train] Batch ID = 37920, loss = 0.00179201, acc = 1.0
[Validation] Batch ID = 37920, loss = 0.0104005, acc = 1.0
[Train] Batch ID = 37930, loss = 0.00270238, acc = 1.0
[Validation] Batch ID = 37930, loss = 0.0384267, acc = 0.96
[Train] Batch ID = 37940, loss = 0.00164577, acc = 1.0
[Validation] Batch ID = 37940, loss = 0.00693579, acc = 1.0
[Train] Batch ID = 37950, loss = 0.0016245, acc = 1.0
[Validation] Batch ID = 37950, loss = 0.0170104, acc = 0.98
[Train] Batch ID = 37960, loss = 0.00103855, acc = 1.0
[Validation] Batch ID = 37960, loss = 0.0401362, acc = 0.96
[Train] Batch ID = 37970, loss = 0.00117575, acc = 1.0
[Validation] Batch ID = 37970, loss = 0.0317617, acc = 0.98
[Train] Batch ID = 37980, loss = 0.00131384, acc = 1.0
[Validation] Batch ID = 37980, loss = 0.0204108, acc = 0.98
[Train] Batch ID = 37990, loss = 0.000580951, acc = 1.0
[Validation] Batch ID = 37990, loss = 0.0288793, acc = 0.98
[Train] Batch ID = 38000, loss = 0.000873868, acc = 1.0
[Validation] Batch ID = 38000, loss = 0.0470329, acc = 0.96
Evaluate full validation dataset ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Saving model ...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Current loss: 0.0254155 Best loss: 0.0254414
[TOTAL Validation] Batch ID = 38000, loss = 0.0254155, acc = 0.978911564626
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>ModelBase::Model successfully saved here: outputs/checkpoints/c1s_9_c1n_256_c2s_6_c2n_64_c2d_0.7_c1vl_16_c1s_5_c1nf_16_c2vl_32_lr_0.0001_rs_1--TrafficSign--1510487290.423481
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Augmented Factor = 0.016258971235578068
[Train] Batch ID = 38010, loss = 0.00127426, acc = 1.0
[Validation] Batch ID = 38010, loss = 0.0350408, acc = 0.98
[Train] Batch ID = 38020, loss = 0.000956805, acc = 1.0
[Validation] Batch ID = 38020, loss = 0.0209388, acc = 1.0
[Train] Batch ID = 38030, loss = 0.000882704, acc = 1.0
[Validation] Batch ID = 38030, loss = 0.0118166, acc = 1.0
[Train] Batch ID = 38040, loss = 0.00107406, acc = 1.0
[Validation] Batch ID = 38040, loss = 0.0138267, acc = 1.0
[Train] Batch ID = 38050, loss = 0.000383219, acc = 1.0
[Validation] Batch ID = 38050, loss = 0.0214781, acc = 0.98
[Train] Batch ID = 38060, loss = 0.000667237, acc = 1.0
[Validation] Batch ID = 38060, loss = 0.0254197, acc = 0.98
[Train] Batch ID = 38070, loss = 0.000743433, acc = 1.0
[Validation] Batch ID = 38070, loss = 0.0095235, acc = 1.0
[Train] Batch ID = 38080, loss = 0.00136138, acc = 1.0
[Validation] Batch ID = 38080, loss = 0.00993024, acc = 1.0
[Train] Batch ID = 38090, loss = 0.00140649, acc = 1.0
[Validation] Batch ID = 38090, loss = 0.0568554, acc = 0.96
[Train] Batch ID = 38100, loss = 0.00168229, acc = 1.0
[Validation] Batch ID = 38100, loss = 0.0271529, acc = 0.96
[Train] Batch ID = 38110, loss = 0.000772352, acc = 1.0
[Validation] Batch ID = 38110, loss = 0.0375415, acc = 0.96
[Train] Batch ID = 38120, loss = 0.000371287, acc = 1.0
[Validation] Batch ID = 38120, loss = 0.0302386, acc = 0.98
[Train] Batch ID = 38130, loss = 0.00298079, acc = 1.0
[Validation] Batch ID = 38130, loss = 0.0287891, acc = 0.98
[Train] Batch ID = 38140, loss = 0.00128598, acc = 1.0
[Validation] Batch ID = 38140, loss = 0.0133479, acc = 1.0
[Train] Batch ID = 38150, loss = 0.00132046, acc = 1.0
[Validation] Batch ID = 38150, loss = 0.0395106, acc = 0.96
[Train] Batch ID = 38160, loss = 0.00397412, acc = 1.0
[Validation] Batch ID = 38160, loss = 0.024257, acc = 0.98
[Train] Batch ID = 38170, loss = 0.00158877, acc = 1.0
[Validation] Batch ID = 38170, loss = 0.0254606, acc = 0.98
[Train] Batch ID = 38180, loss = 0.00213705, acc = 1.0
[Validation] Batch ID = 38180, loss = 0.0851418, acc = 0.9
[Train] Batch ID = 38190, loss = 0.00227948, acc = 1.0
[Validation] Batch ID = 38190, loss = 0.0174252, acc = 1.0
[Train] Batch ID = 38200, loss = 0.00165916, acc = 1.0
[Validation] Batch ID = 38200, loss = 0.0300326, acc = 0.98
[Train] Batch ID = 38210, loss = 0.00104245, acc = 1.0
[Validation] Batch ID = 38210, loss = 0.0457456, acc = 0.96
[Train] Batch ID = 38220, loss = 0.00114705, acc = 1.0
[Validation] Batch ID = 38220, loss = 0.0443231, acc = 0.94
[Train] Batch ID = 38230, loss = 0.00210591, acc = 1.0
[Validation] Batch ID = 38230, loss = 0.0170409, acc = 1.0
[Train] Batch ID = 38240, loss = 0.00194562, acc = 1.0
[Validation] Batch ID = 38240, loss = 0.0133817, acc = 1.0
[Train] Batch ID = 38250, loss = 0.00147689, acc = 1.0
[Validation] Batch ID = 38250, loss = 0.0391976, acc = 0.98
[Train] Batch ID = 38260, loss = 0.00460597, acc = 1.0
[Validation] Batch ID = 38260, loss = 0.045498, acc = 0.94
[Train] Batch ID = 38270, loss = 0.00227097, acc = 1.0
[Validation] Batch ID = 38270, loss = 0.0355538, acc = 0.98
[Train] Batch ID = 38280, loss = 0.00272821, acc = 1.0
[Validation] Batch ID = 38280, loss = 0.038554, acc = 0.96
[Train] Batch ID = 38290, loss = 0.00169602, acc = 1.0
[Validation] Batch ID = 38290, loss = 0.0205616, acc = 1.0
[Train] Batch ID = 38300, loss = 0.00142095, acc = 1.0
[Validation] Batch ID = 38300, loss = 0.0200929, acc = 0.98
[Train] Batch ID = 38310, loss = 0.000980565, acc = 1.0
[Validation] Batch ID = 38310, loss = 0.0424986, acc = 0.96
[Train] Batch ID = 38320, loss = 0.00195072, acc = 1.0
[Validation] Batch ID = 38320, loss = 0.0197234, acc = 0.98
[Train] Batch ID = 38330, loss = 0.00137805, acc = 1.0
[Validation] Batch ID = 38330, loss = 0.0224008, acc = 0.98
[Train] Batch ID = 38340, loss = 0.00134311, acc = 1.0
[Validation] Batch ID = 38340, loss = 0.0258613, acc = 0.96
[Train] Batch ID = 38350, loss = 0.00150395, acc = 1.0
[Validation] Batch ID = 38350, loss = 0.0123743, acc = 0.98
[Train] Batch ID = 38360, loss = 0.000863326, acc = 1.0
[Validation] Batch ID = 38360, loss = 0.0206325, acc = 1.0
[Train] Batch ID = 38370, loss = 0.170731, acc = 0.86
[Validation] Batch ID = 38370, loss = 0.0391262, acc = 0.98
[Train] Batch ID = 38380, loss = 0.00186632, acc = 1.0
[Validation] Batch ID = 38380, loss = 0.0287267, acc = 0.98
[Train] Batch ID = 38390, loss = 0.00834115, acc = 1.0
[Validation] Batch ID = 38390, loss = 0.0340762, acc = 0.98
[Train] Batch ID = 38400, loss = 0.0040914, acc = 1.0
[Validation] Batch ID = 38400, loss = 0.0415357, acc = 0.98
[Train] Batch ID = 38410, loss = 0.0024918, acc = 1.0
[Validation] Batch ID = 38410, loss = 0.0222924, acc = 0.98
[Train] Batch ID = 38420, loss = 0.00105142, acc = 1.0
[Validation] Batch ID = 38420, loss = 0.0291319, acc = 0.96
[Train] Batch ID = 38430, loss = 0.000826551, acc = 1.0
[Validation] Batch ID = 38430, loss = 0.0463568, acc = 0.98
[Train] Batch ID = 38440, loss = 0.00068495, acc = 1.0
[Validation] Batch ID = 38440, loss = 0.0285424, acc = 0.98
[Train] Batch ID = 38450, loss = 0.00132063, acc = 1.0
[Validation] Batch ID = 38450, loss = 0.0299334, acc = 0.98
[Train] Batch ID = 38460, loss = 0.00162856, acc = 1.0
[Validation] Batch ID = 38460, loss = 0.0294329, acc = 0.96
[Train] Batch ID = 38470, loss = 0.00127725, acc = 1.0
[Validation] Batch ID = 38470, loss = 0.00872903, acc = 1.0
[Train] Batch ID = 38480, loss = 0.00107155, acc = 1.0
[Validation] Batch ID = 38480, loss = 0.0119642, acc = 1.0
[Train] Batch ID = 38490, loss = 0.000964883, acc = 1.0
[Validation] Batch ID = 38490, loss = 0.0553975, acc = 0.92
[Train] Batch ID = 38500, loss = 0.000534654, acc = 1.0
[Validation] Batch ID = 38500, loss = 0.033053, acc = 0.96
[Train] Batch ID = 38510, loss = 0.000696871, acc = 1.0
[Validation] Batch ID = 38510, loss = 0.0447776, acc = 0.96
[Train] Batch ID = 38520, loss = 0.00318911, acc = 1.0
[Validation] Batch ID = 38520, loss = 0.0406054, acc = 1.0
[Train] Batch ID = 38530, loss = 0.00239767, acc = 1.0
[Validation] Batch ID = 38530, loss = 0.024247, acc = 1.0
[Train] Batch ID = 38540, loss = 0.00116827, acc = 1.0
[Validation] Batch ID = 38540, loss = 0.0186592, acc = 0.98
[Train] Batch ID = 38550, loss = 0.00178877, acc = 1.0
[Validation] Batch ID = 38550, loss = 0.0257275, acc = 0.98
[Train] Batch ID = 38560, loss = 0.000771803, acc = 1.0
[Validation] Batch ID = 38560, loss = 0.0323878, acc = 0.98
[Train] Batch ID = 38570, loss = 0.00124786, acc = 1.0
[Validation] Batch ID = 38570, loss = 0.0100446, acc = 1.0
[Train] Batch ID = 38580, loss = 0.000618459, acc = 1.0
[Validation] Batch ID = 38580, loss = 0.0383244, acc = 0.96
[Train] Batch ID = 38590, loss = 0.000772228, acc = 1.0
[Validation] Batch ID = 38590, loss = 0.0308014, acc = 0.96
[Train] Batch ID = 38600, loss = 0.00165526, acc = 1.0
[Validation] Batch ID = 38600, loss = 0.0193809, acc = 0.98
[Train] Batch ID = 38610, loss = 0.00145715, acc = 1.0
[Validation] Batch ID = 38610, loss = 0.0145645, acc = 0.98
[Train] Batch ID = 38620, loss = 0.00219446, acc = 1.0
[Validation] Batch ID = 38620, loss = 0.0233388, acc = 1.0
[Train] Batch ID = 38630, loss = 0.000707247, acc = 1.0
[Validation] Batch ID = 38630, loss = 0.0558707, acc = 0.92
[Train] Batch ID = 38640, loss = 0.00153203, acc = 1.0
[Validation] Batch ID = 38640, loss = 0.0117385, acc = 1.0
[Train] Batch ID = 38650, loss = 0.0016247, acc = 1.0
[Validation] Batch ID = 38650, loss = 0.0172804, acc = 1.0
[Train] Batch ID = 38660, loss = 0.00301985, acc = 1.0
[Validation] Batch ID = 38660, loss = 0.00864521, acc = 1.0
[Train] Batch ID = 38670, loss = 0.000927912, acc = 1.0
[Validation] Batch ID = 38670, loss = 0.0233263, acc = 1.0
[Train] Batch ID = 38680, loss = 0.000736744, acc = 1.0
[Validation] Batch ID = 38680, loss = 0.0108782, acc = 1.0
[Train] Batch ID = 38690, loss = 0.0014492, acc = 1.0
[Validation] Batch ID = 38690, loss = 0.0358421, acc = 1.0
[Train] Batch ID = 38700, loss = 0.00154679, acc = 1.0
[Validation] Batch ID = 38700, loss = 0.0276107, acc = 0.96
[Train] Batch ID = 38710, loss = 0.00532646, acc = 1.0
[Validation] Batch ID = 38710, loss = 0.0140915, acc = 1.0
[Train] Batch ID = 38720, loss = 0.00223791, acc = 1.0
[Validation] Batch ID = 38720, loss = 0.0279973, acc = 1.0
[Train] Batch ID = 38730, loss = 0.00189701, acc = 1.0
[Validation] Batch ID = 38730, loss = 0.00645008, acc = 1.0
[Train] Batch ID = 38740, loss = 0.00230352, acc = 1.0
[Validation] Batch ID = 38740, loss = 0.0184136, acc = 0.98
[Train] Batch ID = 38750, loss = 0.00268211, acc = 1.0
[Validation] Batch ID = 38750, loss = 0.0215661, acc = 1.0
[Train] Batch ID = 38760, loss = 0.00457277, acc = 1.0
[Validation] Batch ID = 38760, loss = 0.0433518, acc = 0.96
[Train] Batch ID = 38770, loss = 0.00330429, acc = 1.0
[Validation] Batch ID = 38770, loss = 0.0198763, acc = 0.98
[Train] Batch ID = 38780, loss = 0.000720369, acc = 1.0
[Validation] Batch ID = 38780, loss = 0.0443286, acc = 0.96
[Train] Batch ID = 38790, loss = 0.0016142, acc = 1.0
[Validation] Batch ID = 38790, loss = 0.0578755, acc = 0.94
[Train] Batch ID = 38800, loss = 0.000302942, acc = 1.0
[Validation] Batch ID = 38800, loss = 0.0113212, acc = 1.0
[Train] Batch ID = 38810, loss = 0.00107272, acc = 1.0
[Validation] Batch ID = 38810, loss = 0.0258947, acc = 0.98
[Train] Batch ID = 38820, loss = 0.0010258, acc = 1.0
[Validation] Batch ID = 38820, loss = 0.0333209, acc = 0.98
[Train] Batch ID = 38830, loss = 0.00230507, acc = 1.0
[Validation] Batch ID = 38830, loss = 0.0237396, acc = 0.98
[Train] Batch ID = 38840, loss = 0.000935915, acc = 1.0
[Validation] Batch ID = 38840, loss = 0.0435639, acc = 0.94
[Train] Batch ID = 38850, loss = 0.00155814, acc = 1.0
[Validation] Batch ID = 38850, loss = 0.0352852, acc = 0.98
[Train] Batch ID = 38860, loss = 0.000889952, acc = 1.0
[Validation] Batch ID = 38860, loss = 0.0291988, acc = 0.98
[Train] Batch ID = 38870, loss = 0.00103695, acc = 1.0
[Validation] Batch ID = 38870, loss = 0.0199554, acc = 1.0
[Train] Batch ID = 38880, loss = 0.000765492, acc = 1.0
[Validation] Batch ID = 38880, loss = 0.0212793, acc = 0.98
[Train] Batch ID = 38890, loss = 0.00181694, acc = 1.0
[Validation] Batch ID = 38890, loss = 0.0295611, acc = 0.98
[Train] Batch ID = 38900, loss = 0.000546289, acc = 1.0
[Validation] Batch ID = 38900, loss = 0.0295596, acc = 0.98
[Train] Batch ID = 38910, loss = 0.00134746, acc = 1.0
[Validation] Batch ID = 38910, loss = 0.0110999, acc = 1.0
[Train] Batch ID = 38920, loss = 0.0015986, acc = 1.0
[Validation] Batch ID = 38920, loss = 0.0352543, acc = 0.96
[Train] Batch ID = 38930, loss = 0.000362096, acc = 1.0
[Validation] Batch ID = 38930, loss = 0.0383362, acc = 0.96
[Train] Batch ID = 38940, loss = 0.000596293, acc = 1.0
[Validation] Batch ID = 38940, loss = 0.0518469, acc = 0.94
[Train] Batch ID = 38950, loss = 0.00126123, acc = 1.0
[Validation] Batch ID = 38950, loss = 0.0224572, acc = 1.0
[Train] Batch ID = 38960, loss = 0.00118702, acc = 1.0
[Validation] Batch ID = 38960, loss = 0.0164987, acc = 0.98
[Train] Batch ID = 38970, loss = 0.000883441, acc = 1.0
[Validation] Batch ID = 38970, loss = 0.00711842, acc = 1.0
[Train] Batch ID = 38980, loss = 0.00201727, acc = 1.0
[Validation] Batch ID = 38980, loss = 0.0159498, acc = 1.0
[Train] Batch ID = 38990, loss = 0.00258629, acc = 1.0
[Validation] Batch ID = 38990, loss = 0.0398028, acc = 0.96
[Train] Batch ID = 39000, loss = 0.00189284, acc = 1.0
[Validation] Batch ID = 39000, loss = 0.0139362, acc = 1.0
Evaluate full validation dataset ...
Current loss: 0.0271079 Best loss: 0.0254155
[TOTAL Validation] Batch ID = 39000, loss = 0.0271079, acc = 0.97641723356
Augmented Factor = 0.014633074112020262
[Train] Batch ID = 39010, loss = 0.00176929, acc = 1.0
[Validation] Batch ID = 39010, loss = 0.0138865, acc = 0.98
[Train] Batch ID = 39020, loss = 0.0023623, acc = 1.0
[Validation] Batch ID = 39020, loss = 0.0130478, acc = 1.0
[Train] Batch ID = 39030, loss = 0.00309093, acc = 1.0
[Validation] Batch ID = 39030, loss = 0.00392264, acc = 1.0
[Train] Batch ID = 39040, loss = 0.0015213, acc = 1.0
[Validation] Batch ID = 39040, loss = 0.019257, acc = 0.98
[Train] Batch ID = 39050, loss = 0.000661352, acc = 1.0
[Validation] Batch ID = 39050, loss = 0.033629, acc = 0.98
[Train] Batch ID = 39060, loss = 0.000923142, acc = 1.0
[Validation] Batch ID = 39060, loss = 0.0239484, acc = 0.98
[Train] Batch ID = 39070, loss = 0.00057004, acc = 1.0
[Validation] Batch ID = 39070, loss = 0.0341158, acc = 1.0
[Train] Batch ID = 39080, loss = 0.00189745, acc = 1.0
[Validation] Batch ID = 39080, loss = 0.0163904, acc = 0.98
[Train] Batch ID = 39090, loss = 0.00148706, acc = 1.0
[Validation] Batch ID = 39090, loss = 0.0334534, acc = 0.98
[Train] Batch ID = 39100, loss = 0.00128108, acc = 1.0
[Validation] Batch ID = 39100, loss = 0.0245813, acc = 0.96
[Train] Batch ID = 39110, loss = 0.000524287, acc = 1.0
[Validation] Batch ID = 39110, loss = 0.0171096, acc = 0.98
[Train] Batch ID = 39120, loss = 0.000790245, acc = 1.0
[Validation] Batch ID = 39120, loss = 0.0288631, acc = 0.96
[Train] Batch ID = 39130, loss = 0.000615459, acc = 1.0
[Validation] Batch ID = 39130, loss = 0.0149825, acc = 1.0
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyboardInterrupt</span>                         Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-12-7df2cfe2a939&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">     26</span> 
<span class="ansi-green-intense-fg ansi-bold">     27</span>     <span class="ansi-red-fg">### Training</span>
<span class="ansi-green-fg">---&gt; 28</span><span class="ansi-red-fg">     </span>cost<span class="ansi-blue-fg">,</span> acc <span class="ansi-blue-fg">=</span> model<span class="ansi-blue-fg">.</span>optimize<span class="ansi-blue-fg">(</span>x_batch<span class="ansi-blue-fg">,</span> y_batch<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     29</span>     <span class="ansi-red-fg">### Validation</span>
<span class="ansi-green-intense-fg ansi-bold">     30</span>     x_batch<span class="ansi-blue-fg">,</span> y_batch <span class="ansi-blue-fg">=</span> next<span class="ansi-blue-fg">(</span>valid_batch<span class="ansi-blue-fg">,</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">&lt;ipython-input-8-ab059c574b09&gt;</span> in <span class="ansi-cyan-fg">optimize</span><span class="ansi-blue-fg">(self, images, labels, tb_save)</span>
<span class="ansi-green-intense-fg ansi-bold">    195</span>             self<span class="ansi-blue-fg">.</span>tf_images<span class="ansi-blue-fg">:</span> images<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    196</span>             self<span class="ansi-blue-fg">.</span>tf_labels<span class="ansi-blue-fg">:</span> labels<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">--&gt; 197</span><span class="ansi-red-fg">             </span>self<span class="ansi-blue-fg">.</span>tf_conv_2_dropout<span class="ansi-blue-fg">:</span> self<span class="ansi-blue-fg">.</span>h<span class="ansi-blue-fg">.</span>conv_2_dropout
<span class="ansi-green-intense-fg ansi-bold">    198</span>         })
<span class="ansi-green-intense-fg ansi-bold">    199</span> 

<span class="ansi-green-fg">~/anaconda3/envs/dl3-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py</span> in <span class="ansi-cyan-fg">run</span><span class="ansi-blue-fg">(self, fetches, feed_dict, options, run_metadata)</span>
<span class="ansi-green-intense-fg ansi-bold">    893</span>     <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    894</span>       result = self._run(None, fetches, feed_dict, options_ptr,
<span class="ansi-green-fg">--&gt; 895</span><span class="ansi-red-fg">                          run_metadata_ptr)
</span><span class="ansi-green-intense-fg ansi-bold">    896</span>       <span class="ansi-green-fg">if</span> run_metadata<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    897</span>         proto_data <span class="ansi-blue-fg">=</span> tf_session<span class="ansi-blue-fg">.</span>TF_GetBuffer<span class="ansi-blue-fg">(</span>run_metadata_ptr<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/anaconda3/envs/dl3-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py</span> in <span class="ansi-cyan-fg">_run</span><span class="ansi-blue-fg">(self, handle, fetches, feed_dict, options, run_metadata)</span>
<span class="ansi-green-intense-fg ansi-bold">   1122</span>     <span class="ansi-green-fg">if</span> final_fetches <span class="ansi-green-fg">or</span> final_targets <span class="ansi-green-fg">or</span> <span class="ansi-blue-fg">(</span>handle <span class="ansi-green-fg">and</span> feed_dict_tensor<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   1123</span>       results = self._do_run(handle, final_targets, final_fetches,
<span class="ansi-green-fg">-&gt; 1124</span><span class="ansi-red-fg">                              feed_dict_tensor, options, run_metadata)
</span><span class="ansi-green-intense-fg ansi-bold">   1125</span>     <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   1126</span>       results <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">]</span>

<span class="ansi-green-fg">~/anaconda3/envs/dl3-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py</span> in <span class="ansi-cyan-fg">_do_run</span><span class="ansi-blue-fg">(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)</span>
<span class="ansi-green-intense-fg ansi-bold">   1319</span>     <span class="ansi-green-fg">if</span> handle <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   1320</span>       return self._do_call(_run_fn, self._session, feeds, fetches, targets,
<span class="ansi-green-fg">-&gt; 1321</span><span class="ansi-red-fg">                            options, run_metadata)
</span><span class="ansi-green-intense-fg ansi-bold">   1322</span>     <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   1323</span>       <span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>_do_call<span class="ansi-blue-fg">(</span>_prun_fn<span class="ansi-blue-fg">,</span> self<span class="ansi-blue-fg">.</span>_session<span class="ansi-blue-fg">,</span> handle<span class="ansi-blue-fg">,</span> feeds<span class="ansi-blue-fg">,</span> fetches<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/anaconda3/envs/dl3-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py</span> in <span class="ansi-cyan-fg">_do_call</span><span class="ansi-blue-fg">(self, fn, *args)</span>
<span class="ansi-green-intense-fg ansi-bold">   1325</span>   <span class="ansi-green-fg">def</span> _do_call<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> fn<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   1326</span>     <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">-&gt; 1327</span><span class="ansi-red-fg">       </span><span class="ansi-green-fg">return</span> fn<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1328</span>     <span class="ansi-green-fg">except</span> errors<span class="ansi-blue-fg">.</span>OpError <span class="ansi-green-fg">as</span> e<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   1329</span>       message <span class="ansi-blue-fg">=</span> compat<span class="ansi-blue-fg">.</span>as_text<span class="ansi-blue-fg">(</span>e<span class="ansi-blue-fg">.</span>message<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/anaconda3/envs/dl3-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py</span> in <span class="ansi-cyan-fg">_run_fn</span><span class="ansi-blue-fg">(session, feed_dict, fetch_list, target_list, options, run_metadata)</span>
<span class="ansi-green-intense-fg ansi-bold">   1304</span>           return tf_session.TF_Run(session, options,
<span class="ansi-green-intense-fg ansi-bold">   1305</span>                                    feed_dict<span class="ansi-blue-fg">,</span> fetch_list<span class="ansi-blue-fg">,</span> target_list<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">-&gt; 1306</span><span class="ansi-red-fg">                                    status, run_metadata)
</span><span class="ansi-green-intense-fg ansi-bold">   1307</span> 
<span class="ansi-green-intense-fg ansi-bold">   1308</span>     <span class="ansi-green-fg">def</span> _prun_fn<span class="ansi-blue-fg">(</span>session<span class="ansi-blue-fg">,</span> handle<span class="ansi-blue-fg">,</span> feed_dict<span class="ansi-blue-fg">,</span> fetch_list<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-red-fg">KeyboardInterrupt</span>: </pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Test the model on the test set</span>

<span class="c1"># Evaluate all the dataset</span>
<span class="n">loss</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="n">predicted_class</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate_dataset</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test Accuracy = &quot;</span><span class="p">,</span> <span class="n">acc</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test Loss = &quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Test Accuracy =  0.976009501188
Test Loss =  0.0311028
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h2 id="Step-3:-Test-a-Model-on-New-Images">Step 3: Test a Model on New Images<a class="anchor-link" href="#Step-3:-Test-a-Model-on-New-Images">&#182;</a></h2><p>To give yourself more insight into how your model is working, download at least five pictures of German traffic signs from the web and use your model to predict the traffic sign type.</p>
<p>You may find <code>signnames.csv</code> useful as it contains mappings from the class id (integer) to the actual sign name.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Load-and-Output-the-Images">Load and Output the Images<a class="anchor-link" href="#Load-and-Output-the-Images">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">### Load the images and plot them here.</span>
<span class="c1">### Feel free to use as many code cells as needed.</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="n">images</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Read all image into the folder</span>
<span class="k">for</span> <span class="n">filename</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s2">&quot;from_web&quot;</span><span class="p">):</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;from_web&quot;</span><span class="p">,</span> <span class="n">filename</span><span class="p">))</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">img</span><span class="p">)</span> <span class="o">/</span> <span class="mi">255</span>
    <span class="n">images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
    
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Predict-the-Sign-Type-for-Each-Image">Predict the Sign Type for Each Image<a class="anchor-link" href="#Predict-the-Sign-Type-for-Each-Image">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">### Run the predictions here and use the model to output the prediction for each image.</span>
<span class="c1">### Make sure to pre-process the images with the same pre-processing pipeline used earlier.</span>
<span class="c1">### Feel free to use as many code cells as needed.</span>

<span class="c1"># Get the prediction</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Analyze-Performance">Analyze Performance<a class="anchor-link" href="#Analyze-Performance">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[18]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">### Calculate the accuracy for these 5 new images. </span>
<span class="c1">### For example, if the model predicted 1 out of 5 signs correctly, it&#39;s 20% accurate on these new images.</span>

<span class="c1"># Plot the result</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">25</span><span class="p">))</span>
<span class="n">axs</span> <span class="o">=</span> <span class="n">axs</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">i</span><span class="o">%</span><span class="k">2</span> == 0:
        <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">i</span> <span class="o">//</span> <span class="mi">2</span><span class="p">])</span>
        <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Prediction: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">id_to_name</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">[</span><span class="n">i</span> <span class="o">//</span> <span class="mi">2</span><span class="p">])])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">43</span><span class="p">),</span> <span class="n">predictions</span><span class="p">[</span><span class="n">i</span> <span class="o">//</span> <span class="mi">2</span><span class="p">])</span>
        <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Softmax&quot;</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Labels&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAlIAAAWMCAYAAADlTGiiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Output-Top-5-Softmax-Probabilities-For-Each-Image-Found-on-the-Web">Output Top 5 Softmax Probabilities For Each Image Found on the Web<a class="anchor-link" href="#Output-Top-5-Softmax-Probabilities-For-Each-Image-Found-on-the-Web">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For each of the new images, print out the model's softmax probabilities to show the <strong>certainty</strong> of the model's predictions (limit the output to the top 5 probabilities for each image). <a href="https://www.tensorflow.org/versions/r0.12/api_docs/python/nn.html#top_k"><code>tf.nn.top_k</code></a> could prove helpful here.</p>
<p>The example below demonstrates how tf.nn.top_k can be used to find the top k predictions for each image.</p>
<p><code>tf.nn.top_k</code> will return the values and indices (class ids) of the top k predictions. So if k=3, for each sign, it'll return the 3 largest probabilities (out of a possible 43) and the correspoding class ids.</p>
<p>Take this numpy array as an example. The values in the array represent predictions. The array contains softmax probabilities for five candidate images with six possible classes. <code>tf.nn.top_k</code> is used to choose the three classes with the highest probability:</p>

<pre><code># (5, 6) array
a = np.array([[ 0.24879643,  0.07032244,  0.12641572,  0.34763842,  0.07893497,
         0.12789202],
       [ 0.28086119,  0.27569815,  0.08594638,  0.0178669 ,  0.18063401,
         0.15899337],
       [ 0.26076848,  0.23664738,  0.08020603,  0.07001922,  0.1134371 ,
         0.23892179],
       [ 0.11943333,  0.29198961,  0.02605103,  0.26234032,  0.1351348 ,
         0.16505091],
       [ 0.09561176,  0.34396535,  0.0643941 ,  0.16240774,  0.24206137,
         0.09155967]])</code></pre>
<p>Running it through <code>sess.run(tf.nn.top_k(tf.constant(a), k=3))</code> produces:</p>

<pre><code>TopKV2(values=array([[ 0.34763842,  0.24879643,  0.12789202],
       [ 0.28086119,  0.27569815,  0.18063401],
       [ 0.26076848,  0.23892179,  0.23664738],
       [ 0.29198961,  0.26234032,  0.16505091],
       [ 0.34396535,  0.24206137,  0.16240774]]), indices=array([[3, 0, 5],
       [0, 1, 4],
       [0, 5, 1],
       [1, 3, 5],
       [1, 4, 3]], dtype=int32))</code></pre>
<p>Looking just at the first row we get <code>[ 0.34763842,  0.24879643,  0.12789202]</code>, you can confirm these are the 3 largest probabilities in <code>a</code>. You'll also notice <code>[3, 0, 5]</code> are the corresponding indices.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">### Print out the top five softmax probabilities for the predictions on the German traffic sign images found on the web. </span>
<span class="c1">### Feel free to use as many code cells as needed.</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Project-Writeup">Project Writeup<a class="anchor-link" href="#Project-Writeup">&#182;</a></h3><p>Once you have completed the code implementation, document your results in a project writeup using this <a href="https://github.com/udacity/CarND-Traffic-Sign-Classifier-Project/blob/master/writeup_template.md">template</a> as a guide. The writeup can be in a markdown or pdf file.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote><p><strong>Note</strong>: Once you have completed all of the code implementations and successfully answered each question above, you may finalize your work by exporting the iPython Notebook as an HTML document. You can do this by using the menu above and navigating to  \n",
    "<strong>File -&gt; Download as -&gt; HTML (.html)</strong>. Include the finished document along with this notebook as your submission.</p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h2 id="Step-4-(Optional):-Visualize-the-Neural-Network's-State-with-Test-Images">Step 4 (Optional): Visualize the Neural Network's State with Test Images<a class="anchor-link" href="#Step-4-(Optional):-Visualize-the-Neural-Network's-State-with-Test-Images">&#182;</a></h2><p>This Section is not required to complete but acts as an additional excersise for understaning the output of a neural network's weights. While neural networks can be a great learning device they are often referred to as a black box. We can understand what the weights of a neural network look like better by plotting their feature maps. After successfully training your neural network you can see what it's feature maps look like by plotting the output of the network's weight layers in response to a test stimuli image. From these plotted feature maps, it's possible to see what characteristics of an image the network finds interesting. For a sign, maybe the inner network feature maps react with high activation to the sign's boundary outline or to the contrast in the sign's painted symbol.</p>
<p>Provided for you below is the function code that allows you to get the visualization output of any tensorflow weight layer you want. The inputs to the function should be a stimuli image, one used during training or a new one you provided, and then the tensorflow variable name that represents the layer's state during the training process, for instance if you wanted to see what the <a href="https://classroom.udacity.com/nanodegrees/nd013/parts/fbf77062-5703-404e-b60c-95b78b2f3f9e/modules/6df7ae49-c61c-4bb2-a23e-6527e69209ec/lessons/601ae704-1035-4287-8b11-e2c2716217ad/concepts/d4aca031-508f-4e0b-b493-e7b706120f81">LeNet lab's</a> feature maps looked like for it's second convolutional layer you could enter conv2 as the tf_activation variable.</p>
<p>For an example of what feature map outputs look like, check out NVIDIA's results in their paper <a href="https://devblogs.nvidia.com/parallelforall/deep-learning-self-driving-cars/">End-to-End Deep Learning for Self-Driving Cars</a> in the section Visualization of internal CNN State. NVIDIA was able to show that their network's inner weights had high activations to road boundary lines by comparing feature maps from an image with a clear path to one without. Try experimenting with a similar test to show that your trained network's weights are looking for interesting features, whether it's looking at differences in feature maps from images with or without a sign, or even what feature maps look like in a trained network vs a completely untrained one on the same sign image.</p>
<p><figure>
 <img src="visualize_cnn.png" width="380" alt="Combined Image" />
 <figcaption>
 <p></p> 
 <p style="text-align: center;"> Your output should look something like this (above)</p> 
 </figcaption>
</figure>
 <p></p></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">### Visualize your network&#39;s feature maps here.</span>
<span class="c1">### Feel free to use as many code cells as needed.</span>

<span class="c1"># image_input: the test image being fed into the network to produce the feature maps</span>
<span class="c1"># tf_activation: should be a tf variable name used during your training procedure that represents the calculated state of a specific weight layer</span>
<span class="c1"># activation_min/max: can be used to view the activation contrast in more detail, by default matplot sets min and max to the actual min and max values of the output</span>
<span class="c1"># plt_num: used to plot out multiple different weight feature map sets on the same block, just extend the plt number for each new feature map entry</span>

<span class="k">def</span> <span class="nf">outputFeatureMap</span><span class="p">(</span><span class="n">image_input</span><span class="p">,</span> <span class="n">tf_activation</span><span class="p">,</span> <span class="n">activation_min</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation_max</span><span class="o">=-</span><span class="mi">1</span> <span class="p">,</span><span class="n">plt_num</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="c1"># Here make sure to preprocess your image_input in a way your network expects</span>
    <span class="c1"># with size, normalization, ect if needed</span>
    <span class="c1"># image_input =</span>
    <span class="c1"># Note: x should be the same name as your network&#39;s tensorflow data placeholder variable</span>
    <span class="c1"># If you get an error tf_activation is not defined it may be having trouble accessing the variable from inside a function</span>
    <span class="n">activation</span> <span class="o">=</span> <span class="n">tf_activation</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">session</span><span class="o">=</span><span class="n">sess</span><span class="p">,</span><span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">x</span> <span class="p">:</span> <span class="n">image_input</span><span class="p">})</span>
    <span class="n">featuremaps</span> <span class="o">=</span> <span class="n">activation</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">plt_num</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">15</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">featuremap</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">featuremaps</span><span class="p">):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span> <span class="n">featuremap</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># sets the number of feature maps to show on each row and column</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;FeatureMap &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">featuremap</span><span class="p">))</span> <span class="c1"># displays the feature map number</span>
        <span class="k">if</span> <span class="n">activation_min</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span> <span class="o">&amp;</span> <span class="n">activation_max</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">activation</span><span class="p">[</span><span class="mi">0</span><span class="p">,:,:,</span> <span class="n">featuremap</span><span class="p">],</span> <span class="n">interpolation</span><span class="o">=</span><span class="s2">&quot;nearest&quot;</span><span class="p">,</span> <span class="n">vmin</span> <span class="o">=</span><span class="n">activation_min</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">activation_max</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">activation_max</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">activation</span><span class="p">[</span><span class="mi">0</span><span class="p">,:,:,</span> <span class="n">featuremap</span><span class="p">],</span> <span class="n">interpolation</span><span class="o">=</span><span class="s2">&quot;nearest&quot;</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">activation_max</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">activation_min</span> <span class="o">!=-</span><span class="mi">1</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">activation</span><span class="p">[</span><span class="mi">0</span><span class="p">,:,:,</span> <span class="n">featuremap</span><span class="p">],</span> <span class="n">interpolation</span><span class="o">=</span><span class="s2">&quot;nearest&quot;</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">activation_min</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">activation</span><span class="p">[</span><span class="mi">0</span><span class="p">,:,:,</span> <span class="n">featuremap</span><span class="p">],</span> <span class="n">interpolation</span><span class="o">=</span><span class="s2">&quot;nearest&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
    </div>
  </div>
</body>

 


</html>
